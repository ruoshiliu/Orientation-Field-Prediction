{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import torch, torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_circular_mask(h, w, center=None, radius=None):\n",
    "\n",
    "    if center is None: # use the middle of the image\n",
    "        center = [int(w/2), int(h/2)]\n",
    "    if radius is None: # use the smallest distance between the center and image walls\n",
    "        radius = min(center[0], center[1], w-center[0], h-center[1])\n",
    "\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    mask = mask.astype(int)\n",
    "    return mask\n",
    "mask = create_circular_mask(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/rliu/ansim/data/data/JPEGImages/'\n",
    "img_list_csv = '/home/rliu/github/ansim/img_list.csv'\n",
    "train_csv = '/home/rliu/github/ansim/train.csv'\n",
    "test_csv = '/home/rliu/github/ansim/test.csv'\n",
    "img_list = pd.read_csv(img_list_csv)\n",
    "seq_list = pd.read_csv(train_csv)\n",
    "img_name = os.path.join(img_path, img_list.iloc[1, 0])\n",
    "image = Image.open(img_name)\n",
    "image = image.convert('L')\n",
    "angle = 360 * np.random.uniform(0, 1)\n",
    "image_resized = torchvision.transforms.functional.resize(image, (128,128), interpolation=2)\n",
    "image_resized = torchvision.transforms.functional.rotate(image_resized, angle, resample=False, expand=False, center=None)\n",
    "image_resized = image_resized * mask\n",
    "image_tensor = torch.from_numpy(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ansimDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self,img_list_csv, seq_csv, root_dir, step=20, random_rotate = True, mask = mask, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_csv (string): Path to the csv file with image path.\n",
    "            seq_csv (string): Path to the csv file with indices of heads of sequence.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.img_list = pd.read_csv(img_list_csv)\n",
    "        self.seq_list = pd.read_csv(seq_csv)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.step = step\n",
    "        self.random_rotate = random_rotate\n",
    "        self.mask = mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_head = self.seq_list.iloc[idx,0]\n",
    "        seq = torch.empty(self.step, 1, 128,128, dtype=torch.float)\n",
    "        angle = 360 * np.random.uniform(0, 1)\n",
    "        for i in np.arange(self.step):\n",
    "            img_idx = seq_head + i\n",
    "            img_name = os.path.join(self.root_dir, self.img_list.iloc[img_idx, 0])\n",
    "            image = Image.open(img_name)\n",
    "            image = image.convert('L')\n",
    "            image_resized = torchvision.transforms.functional.resize(image, (128,128), interpolation=2)\n",
    "            if self.random_rotate:\n",
    "                image_resized = torchvision.transforms.functional.rotate(image_resized, angle, resample=False, expand=False, center=None)\n",
    "            image_resized = image_resized * self.mask\n",
    "            image_tensor = torch.from_numpy(image_resized)\n",
    "            seq[i][0] = image_tensor\n",
    "        if self.transform:\n",
    "            seq = self.transform(seq)\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/rliu/ansim/data/data/JPEGImages/'\n",
    "img_list_csv = '/home/rliu/github/ansim/img_list.csv'\n",
    "train_csv = '/home/rliu/github/ansim/train.csv'\n",
    "test_csv = '/home/rliu/github/ansim/test.csv'\n",
    "ansim_dataset = ansimDataset(img_list_csv = img_list_csv, seq_csv = train_csv, root_dir = img_path, step=20, random_rotate = True, mask = mask, transform=data_transform)\n",
    "dataset_loader = torch.utils.data.DataLoader(ansim_dataset,\n",
    "                                             batch_size=8, shuffle=True,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-14-5fae8e3bce80>\", line 40, in __getitem__\n    seq = self.transform(seq)\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n    img = t(img)\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 143, in __call__\n    return F.normalize(tensor, self.mean, self.std)\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 165, in normalize\n    raise TypeError('tensor is not a torch image.')\nTypeError: tensor is not a torch image.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7833a74c142f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Traceback (most recent call last):\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-14-5fae8e3bce80>\", line 40, in __getitem__\n    seq = self.transform(seq)\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n    img = t(img)\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 143, in __call__\n    return F.normalize(tensor, self.mean, self.std)\n  File \"/home/rliu/.local/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 165, in normalize\n    raise TypeError('tensor is not a torch image.')\nTypeError: tensor is not a torch image.\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataset_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rliu/ansim/data/data/JPEGImages/sdf.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(img_path, 'sdf.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img * 0.1909 + 0.3019     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(dataset_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(8)))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.zeros(769)\n",
    "test  = np.zeros(249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(225):\n",
    "    train[i] = 1 + 30*i\n",
    "    \n",
    "for i in np.arange(166):\n",
    "    train[225+i] = 9001 + 30*i\n",
    "    \n",
    "for i in np.arange(80):\n",
    "    train[225+166+i] = 95001 + 30*i\n",
    "    \n",
    "for i in np.arange(66):\n",
    "    train[225+166+80+i] = 100001 + 30*i\n",
    "    \n",
    "for i in np.arange(33):\n",
    "    train[225+166+80+66+i] = 102001 + 30*i\n",
    "    \n",
    "for i in np.arange(133):\n",
    "    train[225+166+80+66+33+i] = 104001 + 30*i\n",
    "    \n",
    "for i in np.arange(66):\n",
    "    train[225+166+80+66+33+133+i] = 108001 + 30*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(70):\n",
    "    test[i] = 6901 + 30*i\n",
    "    \n",
    "for i in np.arange(80):\n",
    "    test[70+i] = 97601 + 30*i\n",
    "    \n",
    "for i in np.arange(33):\n",
    "    test[70+80+i] = 103011 + 30*i\n",
    "    \n",
    "for i in np.arange(66):\n",
    "    test[70+80+33+i] = 110021 + 30*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train)\n",
    "df_train = df_train.astype(int)\n",
    "df_test = pd.DataFrame(test)\n",
    "df_test = df_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[0].to_csv('train.csv',header=False,index=False)\n",
    "df_test.to_csv('test.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>109081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>109111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>109141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>109171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>109201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>109231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>109261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>109291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>109321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>109351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>109381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>109411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>109441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>109471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>109501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>109531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>109561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>109591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>109621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>109651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>109681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>109711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>109741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>109771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>109801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>109831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>109861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>109891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>109921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>109951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0         1\n",
       "1        31\n",
       "2        61\n",
       "3        91\n",
       "4       121\n",
       "5       151\n",
       "6       181\n",
       "7       211\n",
       "8       241\n",
       "9       271\n",
       "10      301\n",
       "11      331\n",
       "12      361\n",
       "13      391\n",
       "14      421\n",
       "15      451\n",
       "16      481\n",
       "17      511\n",
       "18      541\n",
       "19      571\n",
       "20      601\n",
       "21      631\n",
       "22      661\n",
       "23      691\n",
       "24      721\n",
       "25      751\n",
       "26      781\n",
       "27      811\n",
       "28      841\n",
       "29      871\n",
       "..      ...\n",
       "739  109081\n",
       "740  109111\n",
       "741  109141\n",
       "742  109171\n",
       "743  109201\n",
       "744  109231\n",
       "745  109261\n",
       "746  109291\n",
       "747  109321\n",
       "748  109351\n",
       "749  109381\n",
       "750  109411\n",
       "751  109441\n",
       "752  109471\n",
       "753  109501\n",
       "754  109531\n",
       "755  109561\n",
       "756  109591\n",
       "757  109621\n",
       "758  109651\n",
       "759  109681\n",
       "760  109711\n",
       "761  109741\n",
       "762  109771\n",
       "763  109801\n",
       "764  109831\n",
       "765  109861\n",
       "766  109891\n",
       "767  109921\n",
       "768  109951\n",
       "\n",
       "[769 rows x 1 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_list = pd.DataFrame([[\"%0.6d.jpg\" % (x+1)] for x in range(112000)], columns=['image path'])\n",
    "df_img_list.to_csv('img_list.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
