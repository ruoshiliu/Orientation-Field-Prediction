Script started on Tue 16 Apr 2019 12:32:42 AM EDT
krliu@dm:~/github/ansim\[rliu@dm ansim]$ exit[2Plsexit[Kp[Kexit[2Plsvim train.py ls[Kvim train.ls[Kcd ansim/ls[Kcd ..[3PlsCUDA_VISIBLE_DEVICES=1,2,3 python train.py[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[27P[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[6Pscreen -rnvidia-smils[KscreenCUDA_VISIBLE_DEVICES=1,2,3 python train.py[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cscreen[K[4Plsnvidia-smi[1Pscreen -rnvidia-smils[KscreenCUDA_VISIBLE_DEVICES=1,2,3 python train.py[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cnvidia-smi[KCUDA_VISIBLE_DEVICES=1,2,3 python train.py
GPU in use
Epoch 0/39
----------
trainloader ready!
testloader ready!
train Loss: 17.0336 batch_loss: 13081.775391
train Loss: 28.2660 batch_loss: 8626.482422
train Loss: 39.9454 batch_loss: 8969.801758
train Loss: 56.8721 batch_loss: 12999.677734
train Loss: 69.2907 batch_loss: 9537.513672
train Loss: 84.9496 batch_loss: 12026.052734
train Loss: 96.6014 batch_loss: 8948.570312
train Loss: 107.9607 batch_loss: 8723.919922
train Loss: 120.4647 batch_loss: 9603.081055
train Loss: 134.3474 batch_loss: 10661.962891
train Loss: 146.4434 batch_loss: 9289.669922
train Loss: 156.9437 batch_loss: 8064.231445
train Loss: 168.8321 batch_loss: 9130.314453
train Loss: 181.2880 batch_loss: 9566.142578
train Loss: 191.6663 batch_loss: 7970.493652
train Loss: 202.9983 batch_loss: 8702.986328
train Loss: 213.8279 batch_loss: 8317.148438
train Loss: 228.6623 batch_loss: 11392.796875
train Loss: 240.7597 batch_loss: 9290.792969
train Loss: 251.3773 batch_loss: 8154.325684
train Loss: 266.5222 batch_loss: 11631.326172
train Loss: 278.9315 batch_loss: 9530.349609
train Loss: 290.6864 batch_loss: 9027.729492
train Loss: 297.5682 batch_loss: 5285.219727
train Loss: 306.9519 batch_loss: 7206.716309
train Loss: 319.4236 batch_loss: 9578.223633
train Loss: 331.3468 batch_loss: 9157.012695
train Loss: 341.7139 batch_loss: 7961.991211
train Loss: 353.4776 batch_loss: 9034.498047
train Loss: 362.6793 batch_loss: 7066.895996
train Loss: 373.1555 batch_loss: 8045.731445
train Loss: 385.3262 batch_loss: 9347.093750
train Loss: 394.4374 batch_loss: 6997.359375
train Loss: 406.1382 batch_loss: 8986.238281
train Loss: 419.1434 batch_loss: 9987.990234
train Loss: 428.1653 batch_loss: 6928.851562
train Loss: 439.3873 batch_loss: 8618.500000
train Loss: 448.4959 batch_loss: 6995.360840
train Loss: 458.4312 batch_loss: 7630.325195
train Loss: 467.2103 batch_loss: 6742.325684
train Loss: 478.7098 batch_loss: 8831.668945
train Loss: 490.8616 batch_loss: 9332.531250
train Loss: 501.1592 batch_loss: 7908.553711
train Loss: 510.6931 batch_loss: 7322.063477
train Loss: 519.0333 batch_loss: 6405.299316
train Loss: 525.7531 batch_loss: 5160.753906
train Loss: 533.5314 batch_loss: 5973.735840
train Loss: 544.0813 batch_loss: 8102.373535
train Loss: 552.4471 batch_loss: 6424.905762
train Loss: 563.8913 batch_loss: 8789.134766
train Loss: 570.5538 batch_loss: 5116.853027
train Loss: 582.3482 batch_loss: 9058.031250
train Loss: 589.5315 batch_loss: 5516.810547
train Loss: 599.9464 batch_loss: 7998.670410
train Loss: 608.6757 batch_loss: 6704.096680
train Loss: 619.6434 batch_loss: 8423.144531
train Loss: 628.3378 batch_loss: 6677.295410
train Loss: 637.9277 batch_loss: 7365.088379
train Loss: 646.8904 batch_loss: 6883.335938
train Loss: 654.1664 batch_loss: 5587.960449
train Loss: 663.9539 batch_loss: 7516.798340
train Loss: 674.6967 batch_loss: 8250.458008
train Loss: 681.7659 batch_loss: 5429.185547
train Loss: 690.4412 batch_loss: 6662.587402
train Loss: 701.5234 batch_loss: 8511.117188
train Loss: 708.0687 batch_loss: 5026.834961
train Loss: 714.4267 batch_loss: 4882.926758
train Loss: 725.9564 batch_loss: 8854.806641
train Loss: 735.6634 batch_loss: 7455.013184
train Loss: 744.6258 batch_loss: 6883.084961
train Loss: 752.6467 batch_loss: 6160.079102
train Loss: 759.4133 batch_loss: 5196.737305
train Loss: 772.1964 batch_loss: 9817.439453
train Loss: 782.0184 batch_loss: 7543.313965
train Loss: 790.9569 batch_loss: 6864.767090
train Loss: 795.8325 batch_loss: 3744.389160
train Loss: 804.4927 batch_loss: 6651.040039
train Loss: 813.4461 batch_loss: 6876.221191
train Loss: 820.7810 batch_loss: 5633.193848
train Loss: 829.7242 batch_loss: 6868.379883
train Loss: 837.0939 batch_loss: 5659.948242
train Loss: 842.2879 batch_loss: 3988.961426
train Loss: 848.5814 batch_loss: 4833.454102
train Loss: 854.1623 batch_loss: 4286.140137
train Loss: 861.6968 batch_loss: 5786.474121
train Loss: 871.0572 batch_loss: 7188.783691
train Loss: 878.2416 batch_loss: 5517.655273
train Loss: 886.0026 batch_loss: 5960.439941
train Loss: 895.2302 batch_loss: 7086.750000
train Loss: 902.0392 batch_loss: 5229.341797
train Loss: 912.8113 batch_loss: 8272.960938
train Loss: 921.4439 batch_loss: 6629.846680
train Loss: 931.8299 batch_loss: 7976.421875
train Loss: 937.0310 batch_loss: 3994.439941
train Loss: 944.9276 batch_loss: 6064.604492
train Loss: 954.8813 batch_loss: 7644.422852
train Loss: 964.9143 batch_loss: 7705.384277
train Loss: 971.4046 batch_loss: 4984.523438
train Loss: 977.3088 batch_loss: 4534.418457
train Loss: 985.0399 batch_loss: 5937.532227
train Loss: 991.1700 batch_loss: 4707.924805
train Loss: 996.1984 batch_loss: 3861.798340
train Loss: 1004.9938 batch_loss: 6754.842285
train Loss: 1012.4776 batch_loss: 5747.599609
train Loss: 1017.9762 batch_loss: 4222.868164
train Loss: 1023.9610 batch_loss: 4596.383789
train Loss: 1030.4269 batch_loss: 4965.756348
train Loss: 1038.6412 batch_loss: 6308.620605
train Loss: 1044.7490 batch_loss: 4690.735352
train Loss: 1051.2386 batch_loss: 4984.025391
train Loss: 1058.9906 batch_loss: 5953.559082
train Loss: 1064.4694 batch_loss: 4207.733398
train Loss: 1071.2455 batch_loss: 5204.063477
train Loss: 1076.7556 batch_loss: 4231.696777
train Loss: 1084.7332 batch_loss: 6126.854980
train Loss: 1093.6479 batch_loss: 6846.468750
train Loss: 1098.1131 batch_loss: 3429.228516
train Loss: 1105.2933 batch_loss: 5514.420898
train Loss: 1110.1754 batch_loss: 3749.493652
train Loss: 1114.9956 batch_loss: 3701.873047
train Loss: 1121.8624 batch_loss: 5273.729004
train Loss: 1129.5571 batch_loss: 5909.549316
train Loss: 1134.7292 batch_loss: 3972.153809
train Loss: 1140.1631 batch_loss: 4173.221680
train Loss: 1147.6881 batch_loss: 5779.174805
train Loss: 1154.8576 batch_loss: 5506.164062
train Loss: 1160.8927 batch_loss: 4634.964844
train Loss: 1166.6924 batch_loss: 4454.158691
train Loss: 1174.1543 batch_loss: 5730.808594
train Loss: 1180.1891 batch_loss: 4634.672852
train Loss: 1185.3549 batch_loss: 3967.362549
train Loss: 1192.1260 batch_loss: 5200.161621
train Loss: 1196.3886 batch_loss: 3273.721436
train Loss: 1201.5572 batch_loss: 3969.459473
train Loss: 1206.5260 batch_loss: 3816.047607
train Loss: 1212.7042 batch_loss: 4744.857910
train Loss: 1218.9651 batch_loss: 4808.364258
train Loss: 1224.9909 batch_loss: 4627.856934
train Loss: 1231.1133 batch_loss: 4701.973633
train Loss: 1236.1344 batch_loss: 3856.211426
train Loss: 1240.8581 batch_loss: 3627.814941
train Loss: 1245.0541 batch_loss: 3222.518066
train Loss: 1249.7228 batch_loss: 3585.585449
train Loss: 1257.0802 batch_loss: 5650.459473
train Loss: 1265.1587 batch_loss: 6204.243164
train Loss: 1271.1732 batch_loss: 4619.170898
train Loss: 1276.9440 batch_loss: 4431.974121
train Loss: 1284.3092 batch_loss: 5656.502930
train Loss: 1289.0207 batch_loss: 3618.438965
train Loss: 1295.5739 batch_loss: 5032.798340
train Loss: 1301.0561 batch_loss: 4210.325195
train Loss: 1308.0552 batch_loss: 5375.361816
train Loss: 1313.1753 batch_loss: 3932.183594
train Loss: 1319.5458 batch_loss: 4892.588379
train Loss: 1326.2209 batch_loss: 5126.497070
train Loss: 1335.0254 batch_loss: 6761.782227
train Loss: 1341.3091 batch_loss: 4825.940430
train Loss: 1347.3151 batch_loss: 4612.563477
train Loss: 1354.7661 batch_loss: 5722.388184
train Loss: 1360.8434 batch_loss: 4667.342773
train Loss: 1366.1876 batch_loss: 4104.352539
train Loss: 1370.6606 batch_loss: 3435.286621
train Loss: 1374.2978 batch_loss: 2793.372070
train Loss: 1381.2569 batch_loss: 5344.597168
train Loss: 1387.2427 batch_loss: 4597.049316
train Loss: 1392.8932 batch_loss: 4339.593750
train Loss: 1397.7943 batch_loss: 3764.100098
train Loss: 1402.1656 batch_loss: 3357.153809
train Loss: 1407.5583 batch_loss: 4141.554688
train Loss: 1410.6534 batch_loss: 2377.034424
train Loss: 1416.8626 batch_loss: 4768.680664
train Loss: 1421.0538 batch_loss: 3218.835938
train Loss: 1426.6934 batch_loss: 4331.239746
train Loss: 1429.3084 batch_loss: 2008.322876
train Loss: 1435.6146 batch_loss: 4843.165527
train Loss: 1440.4459 batch_loss: 3710.429688
train Loss: 1447.6959 batch_loss: 5567.988281
train Loss: 1451.8924 batch_loss: 3222.875000
train Loss: 1457.2102 batch_loss: 4084.074219
train Loss: 1460.8608 batch_loss: 2803.681885
train Loss: 1465.6356 batch_loss: 3667.072266
train Loss: 1469.2770 batch_loss: 2796.574219
train Loss: 1472.5191 batch_loss: 2489.958984
train Loss: 1476.1949 batch_loss: 2822.994873
train Loss: 1481.3502 batch_loss: 3959.262939
train Loss: 1486.6169 batch_loss: 4044.824219
train Loss: 1490.9146 batch_loss: 3300.616455
train Loss: 1497.0507 batch_loss: 4712.540039
train Loss: 1501.4508 batch_loss: 3379.250732
train Loss: 1505.6748 batch_loss: 3244.026855
train Loss: 1508.9894 batch_loss: 2545.659424
train Loss: 1512.8526 batch_loss: 2966.887207
Loss on the test images: 863.02503 
Epoch 1/39
----------
trainloader ready!
testloader ready!
train Loss: 4.4203 batch_loss: 3394.774902
train Loss: 8.5528 batch_loss: 3173.766113
train Loss: 11.8994 batch_loss: 2570.228271
train Loss: 16.3587 batch_loss: 3424.685059
train Loss: 19.2613 batch_loss: 2229.230469
train Loss: 22.8240 batch_loss: 2736.122314
train Loss: 27.7441 batch_loss: 3778.667236
train Loss: 31.7403 batch_loss: 3069.047119
train Loss: 36.9922 batch_loss: 4033.478516
train Loss: 40.2338 batch_loss: 2489.533691
train Loss: 45.1892 batch_loss: 3805.737061
train Loss: 49.5711 batch_loss: 3365.317627
train Loss: 53.8056 batch_loss: 3252.115723
train Loss: 58.6145 batch_loss: 3693.264404
train Loss: 62.4586 batch_loss: 2952.253906
train Loss: 66.2810 batch_loss: 2935.617676
train Loss: 69.9641 batch_loss: 2828.625488
train Loss: 75.4636 batch_loss: 4223.596680
train Loss: 79.1082 batch_loss: 2799.062012
train Loss: 83.3966 batch_loss: 3293.449951
train Loss: 87.1527 batch_loss: 2884.704102
train Loss: 91.1689 batch_loss: 3084.426025
train Loss: 94.2895 batch_loss: 2396.654785
train Loss: 99.9568 batch_loss: 4352.446777
train Loss: 105.7537 batch_loss: 4452.045410
train Loss: 109.5152 batch_loss: 2888.852783
train Loss: 113.2423 batch_loss: 2862.400879
train Loss: 118.3876 batch_loss: 3951.539062
train Loss: 122.7256 batch_loss: 3331.639893
train Loss: 127.7257 batch_loss: 3840.088623
train Loss: 130.2888 batch_loss: 1968.459595
train Loss: 134.1919 batch_loss: 2997.520996
train Loss: 137.8967 batch_loss: 2845.293701
train Loss: 141.3602 batch_loss: 2659.987793
train Loss: 143.1444 batch_loss: 1370.289673
train Loss: 146.0778 batch_loss: 2252.826904
train Loss: 150.0391 batch_loss: 3042.286621
train Loss: 153.0811 batch_loss: 2336.281494
train Loss: 157.2313 batch_loss: 3187.351074
train Loss: 161.7642 batch_loss: 3481.197998
train Loss: 164.5908 batch_loss: 2170.891602
train Loss: 168.0149 batch_loss: 2629.650391
train Loss: 172.3265 batch_loss: 3311.322266
train Loss: 174.7635 batch_loss: 1871.639404
train Loss: 178.8457 batch_loss: 3135.120850
train Loss: 181.4421 batch_loss: 1994.042236
train Loss: 183.2821 batch_loss: 1413.140503
train Loss: 187.7868 batch_loss: 3459.566895
train Loss: 190.0165 batch_loss: 1712.438110
train Loss: 192.4601 batch_loss: 1876.708374
train Loss: 195.4999 batch_loss: 2334.509033
train Loss: 197.8429 batch_loss: 1799.476807
train Loss: 201.1902 batch_loss: 2570.699219
train Loss: 203.3335 batch_loss: 1646.066162
train Loss: 207.0626 batch_loss: 2863.953369
train Loss: 210.1029 batch_loss: 2334.916504
train Loss: 212.3886 batch_loss: 1755.449829
train Loss: 214.8358 batch_loss: 1879.465576
train Loss: 218.1739 batch_loss: 2563.601074
train Loss: 220.6438 batch_loss: 1896.927490
train Loss: 222.2862 batch_loss: 1261.385010
train Loss: 224.5762 batch_loss: 1758.666016
train Loss: 227.7483 batch_loss: 2436.216064
train Loss: 231.4339 batch_loss: 2830.534180
train Loss: 234.9158 batch_loss: 2674.115479
train Loss: 238.2608 batch_loss: 2568.959717
train Loss: 241.8717 batch_loss: 2773.149902
train Loss: 244.9201 batch_loss: 2341.133301
train Loss: 246.9989 batch_loss: 1596.522949
train Loss: 251.6601 batch_loss: 3579.828857
train Loss: 253.8888 batch_loss: 1711.603149
train Loss: 255.2244 batch_loss: 1025.761963
train Loss: 258.1784 batch_loss: 2268.715332
train Loss: 260.7778 batch_loss: 1996.293945
train Loss: 263.6719 batch_loss: 2222.696289
train Loss: 267.8396 batch_loss: 3200.769531
train Loss: 270.6305 batch_loss: 2143.421387
train Loss: 274.4260 batch_loss: 2914.937744
train Loss: 277.5798 batch_loss: 2422.089844
train Loss: 282.2258 batch_loss: 3568.186279
train Loss: 286.4967 batch_loss: 3279.989746
train Loss: 288.9140 batch_loss: 1856.550049
train Loss: 292.4035 batch_loss: 2679.909424
train Loss: 294.8250 batch_loss: 1859.675781
train Loss: 297.0184 batch_loss: 1684.577393
train Loss: 298.7664 batch_loss: 1342.466064
train Loss: 299.8220 batch_loss: 810.669067
train Loss: 301.3308 batch_loss: 1158.783203
train Loss: 304.5182 batch_loss: 2447.898682
^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[Atrain Loss: 306.5905 batch_loss: 1591.559570
^[[A^[[A^[[A^[[A^[[Atrain Loss: 308.6175 batch_loss: 1556.741455
train Loss: 310.5430 batch_loss: 1478.799561
train Loss: 312.8731 batch_loss: 1789.486328
train Loss: 314.6701 batch_loss: 1380.103760
train Loss: 317.2715 batch_loss: 1997.860718
train Loss: 321.0958 batch_loss: 2937.080078
train Loss: 323.0729 batch_loss: 1518.360962
train Loss: 324.7282 batch_loss: 1271.289307
train Loss: 328.8346 batch_loss: 3153.756836
train Loss: 331.7116 batch_loss: 2209.529541
train Loss: 334.8895 batch_loss: 2440.605713
train Loss: 337.8758 batch_loss: 2293.459717
train Loss: 340.6976 batch_loss: 2167.143066
train Loss: 343.6318 batch_loss: 2253.494873
train Loss: 346.4452 batch_loss: 2160.680908
train Loss: 348.9078 batch_loss: 1891.270264
train Loss: 351.5996 batch_loss: 2067.330566
train Loss: 352.6508 batch_loss: 807.297913
train Loss: 355.4468 batch_loss: 2147.348877
train Loss: 358.5207 batch_loss: 2360.725098
train Loss: 360.3994 batch_loss: 1442.845337
train Loss: 362.9217 batch_loss: 1937.122070
train Loss: 366.1470 batch_loss: 2477.065430
train Loss: 368.1284 batch_loss: 1521.676514
train Loss: 372.0276 batch_loss: 2994.608643
train Loss: 374.7436 batch_loss: 2085.906738
train Loss: 376.7968 batch_loss: 1576.800659
train Loss: 378.3944 batch_loss: 1226.973633
train Loss: 381.1901 batch_loss: 2147.107422
train Loss: 384.6952 batch_loss: 2691.910889
train Loss: 386.7603 batch_loss: 1585.973389
train Loss: 388.1764 batch_loss: 1087.612183
train Loss: 389.6449 batch_loss: 1127.767090
train Loss: 390.9243 batch_loss: 982.631653
train Loss: 394.6748 batch_loss: 2880.382080
train Loss: 396.4578 batch_loss: 1369.333252
train Loss: 397.6266 batch_loss: 897.592896
train Loss: 400.4383 batch_loss: 2159.451904
train Loss: 402.9330 batch_loss: 1915.861328
train Loss: 405.2717 batch_loss: 1796.184814
train Loss: 407.3578 batch_loss: 1602.077271
train Loss: 409.2261 batch_loss: 1434.905273
train Loss: 412.0997 batch_loss: 2206.874756
train Loss: 414.3452 batch_loss: 1724.596680
train Loss: 417.0847 batch_loss: 2103.933594
train Loss: 419.4427 batch_loss: 1810.908447
train Loss: 422.7102 batch_loss: 2509.469971
train Loss: 424.7840 batch_loss: 1592.620239
train Loss: 425.8230 batch_loss: 798.015259
train Loss: 428.7843 batch_loss: 2274.235107
train Loss: 430.3923 batch_loss: 1234.975830
train Loss: 431.8396 batch_loss: 1111.493896
train Loss: 433.4174 batch_loss: 1211.746704
train Loss: 435.5202 batch_loss: 1614.957764
train Loss: 437.4279 batch_loss: 1465.151733
train Loss: 439.6276 batch_loss: 1689.361694
train Loss: 441.2782 batch_loss: 1267.651123
train Loss: 443.5941 batch_loss: 1778.603760
train Loss: 445.0544 batch_loss: 1121.514282
train Loss: 447.4045 batch_loss: 1804.871460
train Loss: 449.8264 batch_loss: 1860.024780
train Loss: 451.0800 batch_loss: 962.719727
train Loss: 453.0589 batch_loss: 1519.803467
train Loss: 455.2556 batch_loss: 1687.099976
train Loss: 457.3125 batch_loss: 1579.696045
train Loss: 458.8241 batch_loss: 1160.901245
train Loss: 461.0026 batch_loss: 1673.106079
train Loss: 462.4927 batch_loss: 1144.353638
train Loss: 464.9725 batch_loss: 1904.519165
train Loss: 467.0750 batch_loss: 1614.755737
train Loss: 468.9311 batch_loss: 1425.426392
train Loss: 470.4952 batch_loss: 1201.272705
train Loss: 471.3089 batch_loss: 624.884521
train Loss: 472.9871 batch_loss: 1288.885620
train Loss: 474.3066 batch_loss: 1013.341003
train Loss: 475.0859 batch_loss: 598.499512
train Loss: 476.4566 batch_loss: 1052.695557
train Loss: 477.9405 batch_loss: 1139.634521
train Loss: 479.7515 batch_loss: 1390.885010
train Loss: 482.0076 batch_loss: 1732.694702
train Loss: 483.6728 batch_loss: 1278.861328
train Loss: 485.7340 batch_loss: 1582.962891
train Loss: 486.8203 batch_loss: 834.343262
train Loss: 489.8787 batch_loss: 2348.836914
train Loss: 492.0238 batch_loss: 1647.433838
train Loss: 493.8510 batch_loss: 1403.264038
train Loss: 494.4511 batch_loss: 460.847748
train Loss: 495.6883 batch_loss: 950.168640
train Loss: 496.4585 batch_loss: 591.520386
train Loss: 497.2015 batch_loss: 570.667603
train Loss: 497.8322 batch_loss: 484.399109
train Loss: 499.4391 batch_loss: 1234.075562
train Loss: 500.8348 batch_loss: 1071.855103
train Loss: 503.9480 batch_loss: 2390.949219
train Loss: 505.6545 batch_loss: 1310.624878
train Loss: 506.1753 batch_loss: 399.951080
train Loss: 508.0958 batch_loss: 1474.932007
train Loss: 509.6580 batch_loss: 1199.811279
train Loss: 511.9855 batch_loss: 1787.469116
train Loss: 513.6026 batch_loss: 1241.931396
train Loss: 516.0840 batch_loss: 1905.764038
train Loss: 517.2835 batch_loss: 921.206360
Loss on the test images: 307.84209 
Epoch 2/39
----------
trainloader ready!
testloader ready!
train Loss: 2.7367 batch_loss: 2101.811279
train Loss: 3.8733 batch_loss: 872.861816
train Loss: 5.3728 batch_loss: 1151.615967
train Loss: 6.4662 batch_loss: 839.776489
train Loss: 8.0040 batch_loss: 1181.001709
train Loss: 9.3101 batch_loss: 1003.082703
train Loss: 11.0561 batch_loss: 1340.947266
train Loss: 12.7120 batch_loss: 1271.727539
train Loss: 13.4831 batch_loss: 592.169128
train Loss: 14.8434 batch_loss: 1044.733643
train Loss: 15.5625 batch_loss: 552.295410
train Loss: 15.9696 batch_loss: 312.619202
train Loss: 18.0317 batch_loss: 1583.700928
train Loss: 20.0679 batch_loss: 1563.814087
train Loss: 20.6542 batch_loss: 450.248535
train Loss: 21.8564 batch_loss: 923.333679
train Loss: 23.0717 batch_loss: 933.361511
train Loss: 24.4753 batch_loss: 1077.895264
train Loss: 25.5763 batch_loss: 845.605286
train Loss: 26.5748 batch_loss: 766.853638
train Loss: 28.2271 batch_loss: 1268.961304
train Loss: 28.9036 batch_loss: 519.573669
train Loss: 32.1229 batch_loss: 2472.364746
train Loss: 33.6779 batch_loss: 1194.298828
train Loss: 34.7514 batch_loss: 824.407410
train Loss: 36.2770 batch_loss: 1171.642334
train Loss: 37.5020 batch_loss: 940.855164
train Loss: 38.2927 batch_loss: 607.225220
train Loss: 40.4759 batch_loss: 1676.679077
train Loss: 42.1661 batch_loss: 1298.120850
train Loss: 43.2332 batch_loss: 819.518555
train Loss: 44.4099 batch_loss: 903.688293
train Loss: 45.8386 batch_loss: 1097.260620
train Loss: 47.8020 batch_loss: 1507.902344
train Loss: 48.9903 batch_loss: 912.570312
train Loss: 49.9957 batch_loss: 772.185425
train Loss: 50.7227 batch_loss: 558.306274
train Loss: 51.4609 batch_loss: 566.992798
train Loss: 53.1749 batch_loss: 1316.337646
train Loss: 54.0167 batch_loss: 646.446960
train Loss: 55.7680 batch_loss: 1345.060059
train Loss: 56.6939 batch_loss: 711.079956
train Loss: 57.1437 batch_loss: 345.416107
train Loss: 59.1705 batch_loss: 1556.629395
train Loss: 60.7260 batch_loss: 1194.590210
train Loss: 62.3653 batch_loss: 1259.005249
train Loss: 63.8664 batch_loss: 1152.819824
train Loss: 64.6833 batch_loss: 627.398315
train Loss: 65.5648 batch_loss: 677.001160
train Loss: 67.5986 batch_loss: 1561.916626
train Loss: 69.2293 batch_loss: 1252.423584
train Loss: 70.8483 batch_loss: 1243.327637
train Loss: 71.9070 batch_loss: 813.130249
train Loss: 73.6302 batch_loss: 1323.379150
train Loss: 75.3129 batch_loss: 1292.310425
train Loss: 75.7819 batch_loss: 360.212311
train Loss: 76.7976 batch_loss: 780.057007
train Loss: 77.9665 batch_loss: 897.691895
train Loss: 79.1069 batch_loss: 875.845093
train Loss: 80.6260 batch_loss: 1166.643677
train Loss: 81.9605 batch_loss: 1024.935669
train Loss: 82.6669 batch_loss: 542.502502
train Loss: 84.1847 batch_loss: 1165.661743
train Loss: 85.3963 batch_loss: 930.534363
train Loss: 86.0320 batch_loss: 488.201569
train Loss: 87.3654 batch_loss: 1024.050781
train Loss: 88.1915 batch_loss: 634.468811
train Loss: 89.3495 batch_loss: 889.350403
train Loss: 90.2630 batch_loss: 701.518921
train Loss: 92.6039 batch_loss: 1797.827881
train Loss: 93.7236 batch_loss: 859.936829
train Loss: 95.1010 batch_loss: 1057.870361
train Loss: 95.9243 batch_loss: 632.297729
train Loss: 96.7683 batch_loss: 648.195435
train Loss: 97.8147 batch_loss: 803.633850
train Loss: 98.9537 batch_loss: 874.755005
train Loss: 99.9958 batch_loss: 800.322632
train Loss: 101.2461 batch_loss: 960.243286
train Loss: 102.9061 batch_loss: 1274.864624
train Loss: 103.6025 batch_loss: 534.832581
train Loss: 104.6896 batch_loss: 834.911011
train Loss: 105.6165 batch_loss: 711.834045
train Loss: 107.4072 batch_loss: 1375.243408
train Loss: 108.7525 batch_loss: 1033.183838
train Loss: 109.5263 batch_loss: 594.254272
train Loss: 110.7750 batch_loss: 958.999329
train Loss: 111.9406 batch_loss: 895.194519
train Loss: 113.3228 batch_loss: 1061.577515
train Loss: 114.9827 batch_loss: 1274.811279
train Loss: 116.6278 batch_loss: 1263.381714
train Loss: 117.6971 batch_loss: 821.214172
train Loss: 118.5781 batch_loss: 676.673706
train Loss: 119.8960 batch_loss: 1012.084351
train Loss: 120.7236 batch_loss: 635.636353
train Loss: 121.7961 batch_loss: 823.696777
train Loss: 122.8803 batch_loss: 832.612000
train Loss: 123.7048 batch_loss: 633.256470
train Loss: 125.5390 batch_loss: 1408.642212
train Loss: 126.8510 batch_loss: 1007.602539
train Loss: 127.8088 batch_loss: 735.597168
train Loss: 129.1509 batch_loss: 1030.734619
train Loss: 130.6073 batch_loss: 1118.550781
train Loss: 131.6952 batch_loss: 835.500854
train Loss: 133.2007 batch_loss: 1156.193237
train Loss: 134.5897 batch_loss: 1066.753418
train Loss: 135.0491 batch_loss: 352.866425
train Loss: 137.1580 batch_loss: 1619.598389
train Loss: 138.4443 batch_loss: 987.876770
train Loss: 139.3051 batch_loss: 661.096375
train Loss: 140.2237 batch_loss: 705.450317
train Loss: 140.8272 batch_loss: 463.519348
train Loss: 142.1053 batch_loss: 981.569519
train Loss: 143.0953 batch_loss: 760.349243
train Loss: 144.8208 batch_loss: 1325.177734
train Loss: 146.1832 batch_loss: 1046.286743
train Loss: 146.6134 batch_loss: 330.390625
train Loss: 147.9910 batch_loss: 1058.039795
train Loss: 148.6934 batch_loss: 539.446899
train Loss: 149.5469 batch_loss: 655.462280
train Loss: 150.5166 batch_loss: 744.769897
train Loss: 151.6912 batch_loss: 902.087036
train Loss: 153.1031 batch_loss: 1084.296265
train Loss: 154.4249 batch_loss: 1015.142883
train Loss: 155.2684 batch_loss: 647.807251
train Loss: 155.7546 batch_loss: 373.429504
train Loss: 156.3090 batch_loss: 425.783447
train Loss: 157.0685 batch_loss: 583.316833
train Loss: 158.2832 batch_loss: 932.853210
train Loss: 159.2884 batch_loss: 772.029846
train Loss: 159.7168 batch_loss: 328.980713
train Loss: 160.1694 batch_loss: 347.606262
train Loss: 161.7746 batch_loss: 1232.811768
train Loss: 162.5907 batch_loss: 626.721680
train Loss: 163.4980 batch_loss: 696.845398
train Loss: 164.6417 batch_loss: 878.373352
train Loss: 164.9334 batch_loss: 224.001923
train Loss: 165.7756 batch_loss: 646.814148
train Loss: 166.6493 batch_loss: 670.952759
train Loss: 167.7964 batch_loss: 881.018372
train Loss: 168.9389 batch_loss: 877.454773
train Loss: 169.6322 batch_loss: 532.420227
train Loss: 169.9948 batch_loss: 278.473053
train Loss: 171.0908 batch_loss: 841.768921
train Loss: 172.2374 batch_loss: 880.589050
train Loss: 173.1764 batch_loss: 721.101196
train Loss: 174.4577 batch_loss: 984.089233
train Loss: 175.3602 batch_loss: 693.050476
train Loss: 176.0275 batch_loss: 512.499451
train Loss: 176.7868 batch_loss: 583.201538
train Loss: 177.4748 batch_loss: 528.329224
train Loss: 179.0366 batch_loss: 1199.494141
train Loss: 179.3873 batch_loss: 269.333130
train Loss: 180.1094 batch_loss: 554.559143
train Loss: 181.2531 batch_loss: 878.332642
train Loss: 182.1131 batch_loss: 660.494751
train Loss: 183.0976 batch_loss: 756.111816
train Loss: 183.6413 batch_loss: 417.580750
train Loss: 183.9577 batch_loss: 242.961395
train Loss: 185.4228 batch_loss: 1125.202881
train Loss: 186.5767 batch_loss: 886.244324
train Loss: 187.8725 batch_loss: 995.152954
train Loss: 188.9957 batch_loss: 862.615906
train Loss: 189.7354 batch_loss: 568.068237
train Loss: 191.0812 batch_loss: 1033.570068
train Loss: 191.6732 batch_loss: 454.662506
train Loss: 193.2327 batch_loss: 1197.712646
train Loss: 194.9048 batch_loss: 1284.129150
train Loss: 195.8790 batch_loss: 748.196411
train Loss: 196.2340 batch_loss: 272.637543
train Loss: 196.8935 batch_loss: 506.485840
train Loss: 197.6441 batch_loss: 576.520264
train Loss: 198.1015 batch_loss: 351.245667
train Loss: 198.3861 batch_loss: 218.609329
train Loss: 199.7222 batch_loss: 1026.103638
train Loss: 200.1435 batch_loss: 323.591309
train Loss: 200.5276 batch_loss: 294.988800
train Loss: 201.3563 batch_loss: 636.437073
train Loss: 202.2947 batch_loss: 720.644958
train Loss: 203.1373 batch_loss: 647.167603
train Loss: 205.0042 batch_loss: 1433.743652
train Loss: 205.6622 batch_loss: 505.352539
train Loss: 206.3540 batch_loss: 531.279602
train Loss: 207.2888 batch_loss: 717.975952
train Loss: 208.5082 batch_loss: 936.480469
train Loss: 209.7954 batch_loss: 988.527954
train Loss: 210.3651 batch_loss: 437.591400
train Loss: 210.6940 batch_loss: 252.555496
train Loss: 211.1745 batch_loss: 369.055878
train Loss: 211.9998 batch_loss: 633.773987
train Loss: 213.4625 batch_loss: 1123.377563
train Loss: 214.1096 batch_loss: 496.944427
train Loss: 214.6745 batch_loss: 433.910492
Loss on the test images: 162.62401 
Epoch 3/39
----------
trainloader ready!
testloader ready!
train Loss: 0.8069 batch_loss: 619.682190
train Loss: 1.6580 batch_loss: 653.682800
train Loss: 2.5778 batch_loss: 706.355042
train Loss: 3.0487 batch_loss: 361.653137
train Loss: 4.0730 batch_loss: 786.664001
train Loss: 5.3979 batch_loss: 1017.577942
train Loss: 5.8792 batch_loss: 369.644348
train Loss: 6.7463 batch_loss: 665.923584
train Loss: 7.6786 batch_loss: 715.988464
train Loss: 7.9906 batch_loss: 239.617462
train Loss: 8.9301 batch_loss: 721.523499
train Loss: 9.7062 batch_loss: 596.058777
train Loss: 10.2604 batch_loss: 425.622314
train Loss: 11.1243 batch_loss: 663.479370
train Loss: 12.1794 batch_loss: 810.282227
train Loss: 12.9713 batch_loss: 608.199341
train Loss: 13.4027 batch_loss: 331.351501
train Loss: 13.8371 batch_loss: 333.569763
train Loss: 14.6239 batch_loss: 604.302917
train Loss: 15.4121 batch_loss: 605.314331
train Loss: 16.1853 batch_loss: 593.848022
train Loss: 16.6482 batch_loss: 355.441956
train Loss: 17.7565 batch_loss: 851.201355
train Loss: 18.4636 batch_loss: 543.090210
train Loss: 19.3668 batch_loss: 693.659363
train Loss: 20.2415 batch_loss: 671.725281
train Loss: 20.8846 batch_loss: 493.913910
train Loss: 21.3889 batch_loss: 387.305206
train Loss: 22.5475 batch_loss: 889.838501
train Loss: 23.5210 batch_loss: 747.609253
train Loss: 24.5690 batch_loss: 804.864624
train Loss: 25.4123 batch_loss: 647.629517
train Loss: 26.2426 batch_loss: 637.676697
train Loss: 27.1629 batch_loss: 706.788635
train Loss: 28.1611 batch_loss: 766.615540
train Loss: 28.8627 batch_loss: 538.817627
train Loss: 29.4679 batch_loss: 464.802155
train Loss: 30.1834 batch_loss: 549.530457
train Loss: 30.8637 batch_loss: 522.508484
train Loss: 31.6078 batch_loss: 571.407043
train Loss: 31.9290 batch_loss: 246.718872
train Loss: 32.9094 batch_loss: 752.951233
train Loss: 33.9200 batch_loss: 776.132507
train Loss: 35.0890 batch_loss: 897.809570
train Loss: 35.6388 batch_loss: 422.182465
train Loss: 36.5198 batch_loss: 676.637024
train Loss: 37.1521 batch_loss: 485.631775
train Loss: 37.6357 batch_loss: 371.363068
train Loss: 38.6660 batch_loss: 791.268433
train Loss: 39.2662 batch_loss: 460.954193
train Loss: 40.3725 batch_loss: 849.702148
train Loss: 41.0120 batch_loss: 491.129211
train Loss: 41.3482 batch_loss: 258.203583
train Loss: 41.5772 batch_loss: 175.800751
train Loss: 42.4999 batch_loss: 708.655334
train Loss: 43.4442 batch_loss: 725.209778
train Loss: 44.0347 batch_loss: 453.547058
train Loss: 44.9209 batch_loss: 680.567200
train Loss: 46.0285 batch_loss: 850.673828
train Loss: 47.2578 batch_loss: 944.099487
train Loss: 48.0425 batch_loss: 602.628906
train Loss: 48.8382 batch_loss: 611.116516
train Loss: 49.8263 batch_loss: 758.844055
train Loss: 50.4449 batch_loss: 475.077209
train Loss: 51.2962 batch_loss: 653.828613
train Loss: 51.7430 batch_loss: 343.126068
train Loss: 52.7283 batch_loss: 756.687012
train Loss: 53.2690 batch_loss: 415.296783
train Loss: 53.8426 batch_loss: 440.483337
train Loss: 54.4385 batch_loss: 457.702698
train Loss: 55.0388 batch_loss: 460.997711
train Loss: 55.7175 batch_loss: 521.239624
train Loss: 55.9521 batch_loss: 180.164841
train Loss: 56.4384 batch_loss: 373.479706
train Loss: 57.2980 batch_loss: 660.207214
train Loss: 57.8051 batch_loss: 389.463043
train Loss: 58.3695 batch_loss: 433.452728
train Loss: 59.2710 batch_loss: 692.313354
train Loss: 60.4672 batch_loss: 918.715332
train Loss: 61.2532 batch_loss: 603.643188
train Loss: 62.1256 batch_loss: 669.998047
train Loss: 62.9047 batch_loss: 598.338989
train Loss: 63.9845 batch_loss: 829.283386
train Loss: 64.4338 batch_loss: 345.052612
train Loss: 64.9436 batch_loss: 391.516357
train Loss: 65.6983 batch_loss: 579.664062
train Loss: 66.4299 batch_loss: 561.812317
train Loss: 67.1677 batch_loss: 566.662964
train Loss: 68.2304 batch_loss: 816.176636
train Loss: 68.7702 batch_loss: 414.558655
train Loss: 69.9286 batch_loss: 889.629700
train Loss: 70.6537 batch_loss: 556.876831
train Loss: 71.2410 batch_loss: 451.033752
train Loss: 71.5543 batch_loss: 240.608078
train Loss: 71.9655 batch_loss: 315.818604
train Loss: 72.4419 batch_loss: 365.872467
train Loss: 72.9038 batch_loss: 354.764984
train Loss: 73.6776 batch_loss: 594.271484
train Loss: 74.6716 batch_loss: 763.382812
train Loss: 74.9685 batch_loss: 228.009201
train Loss: 75.8827 batch_loss: 702.081055
train Loss: 76.9587 batch_loss: 826.376465
train Loss: 77.5069 batch_loss: 421.049622
train Loss: 78.1465 batch_loss: 491.229156
train Loss: 78.5577 batch_loss: 315.789215
train Loss: 78.8477 batch_loss: 222.733932
train Loss: 79.3195 batch_loss: 362.311127
train Loss: 80.4114 batch_loss: 838.582214
train Loss: 81.2438 batch_loss: 639.262512
train Loss: 82.1036 batch_loss: 660.360901
train Loss: 82.9958 batch_loss: 685.184509
train Loss: 83.5896 batch_loss: 456.085449
train Loss: 83.8497 batch_loss: 199.682526
train Loss: 84.5503 batch_loss: 538.081421
train Loss: 85.0913 batch_loss: 415.466156
train Loss: 85.7607 batch_loss: 514.131775
train Loss: 86.5191 batch_loss: 582.461060
train Loss: 87.1804 batch_loss: 507.893738
train Loss: 87.9246 batch_loss: 571.488220
train Loss: 88.4888 batch_loss: 433.357910
train Loss: 89.1574 batch_loss: 513.444580
train Loss: 89.8728 batch_loss: 549.446655
train Loss: 90.3562 batch_loss: 371.279358
train Loss: 90.8827 batch_loss: 404.323181
train Loss: 91.2608 batch_loss: 290.369354
train Loss: 92.0287 batch_loss: 589.755920
train Loss: 92.4827 batch_loss: 348.680389
train Loss: 93.3964 batch_loss: 701.719727
train Loss: 93.8572 batch_loss: 353.909760
train Loss: 94.5376 batch_loss: 522.516235
train Loss: 95.5556 batch_loss: 781.814636
train Loss: 96.5287 batch_loss: 747.343018
train Loss: 97.4372 batch_loss: 697.757324
train Loss: 98.2077 batch_loss: 591.762146
train Loss: 98.9441 batch_loss: 565.529114
train Loss: 99.7413 batch_loss: 612.241516
train Loss: 100.1774 batch_loss: 334.940521
train Loss: 100.4978 batch_loss: 246.073166
train Loss: 100.9417 batch_loss: 340.916229
train Loss: 101.2162 batch_loss: 210.799515
train Loss: 101.6777 batch_loss: 354.446228
train Loss: 102.1582 batch_loss: 369.035950
train Loss: 102.5052 batch_loss: 266.463531
train Loss: 103.5208 batch_loss: 779.989136
train Loss: 104.2145 batch_loss: 532.771423
train Loss: 104.8105 batch_loss: 457.718597
train Loss: 105.2891 batch_loss: 367.577637
train Loss: 105.8926 batch_loss: 463.464783
train Loss: 106.3741 batch_loss: 369.836121
train Loss: 106.8395 batch_loss: 357.426758
train Loss: 107.8677 batch_loss: 789.651001
train Loss: 108.3321 batch_loss: 356.606689
train Loss: 108.9236 batch_loss: 454.281647
train Loss: 109.5717 batch_loss: 497.737244
train Loss: 110.2156 batch_loss: 494.531891
train Loss: 110.7300 batch_loss: 395.092682
train Loss: 111.2431 batch_loss: 394.001801
train Loss: 111.9313 batch_loss: 528.570435
train Loss: 112.8524 batch_loss: 707.413574
train Loss: 113.8243 batch_loss: 746.391602
train Loss: 114.3345 batch_loss: 391.846008
train Loss: 114.6491 batch_loss: 241.595795
train Loss: 115.3258 batch_loss: 519.733704
train Loss: 115.5637 batch_loss: 182.700500
train Loss: 116.2805 batch_loss: 550.488586
train Loss: 116.7093 batch_loss: 329.370911
train Loss: 117.4494 batch_loss: 568.334717
train Loss: 118.1567 batch_loss: 543.218872
train Loss: 118.8020 batch_loss: 495.565582
train Loss: 119.5138 batch_loss: 546.680542
train Loss: 119.9287 batch_loss: 318.696442
train Loss: 120.3371 batch_loss: 313.618439
train Loss: 120.9149 batch_loss: 443.739990
train Loss: 121.4595 batch_loss: 418.226471
train Loss: 121.9684 batch_loss: 390.873779
train Loss: 122.4056 batch_loss: 335.795258
train Loss: 123.1241 batch_loss: 551.757690
train Loss: 123.8992 batch_loss: 595.303833
train Loss: 124.6194 batch_loss: 553.144348
train Loss: 125.1861 batch_loss: 435.168060
train Loss: 125.5299 batch_loss: 264.049652
train Loss: 126.4175 batch_loss: 681.676636
train Loss: 126.9327 batch_loss: 395.651428
train Loss: 127.4231 batch_loss: 376.689697
train Loss: 128.2255 batch_loss: 616.182068
train Loss: 128.5837 batch_loss: 275.110779
train Loss: 129.1581 batch_loss: 441.142090
train Loss: 129.9031 batch_loss: 572.188843
train Loss: 130.4762 batch_loss: 440.090271
train Loss: 131.0344 batch_loss: 428.700592
train Loss: 131.4933 batch_loss: 352.460419
train Loss: 131.9515 batch_loss: 351.904785
Loss on the test images: 125.32356 
Epoch 4/39
----------
trainloader ready!
testloader ready!
train Loss: 0.5252 batch_loss: 403.348450
train Loss: 1.3791 batch_loss: 655.816711
train Loss: 2.2984 batch_loss: 706.021851
train Loss: 2.9067 batch_loss: 467.130310
train Loss: 3.4850 batch_loss: 444.173981
train Loss: 4.0389 batch_loss: 425.376160
train Loss: 4.8890 batch_loss: 652.875305
train Loss: 5.4645 batch_loss: 441.972076
train Loss: 5.8265 batch_loss: 278.050507
train Loss: 6.5240 batch_loss: 535.689087
train Loss: 7.1295 batch_loss: 464.988708
train Loss: 7.8240 batch_loss: 533.405579
train Loss: 8.2331 batch_loss: 314.190247
train Loss: 8.7723 batch_loss: 414.089172
train Loss: 9.3098 batch_loss: 412.785400
train Loss: 9.6548 batch_loss: 264.971375
train Loss: 10.2472 batch_loss: 454.987457
train Loss: 10.9149 batch_loss: 512.748657
train Loss: 11.3882 batch_loss: 363.543823
train Loss: 11.9605 batch_loss: 439.494080
train Loss: 12.6914 batch_loss: 561.315308
train Loss: 13.4351 batch_loss: 571.171997
train Loss: 14.1370 batch_loss: 539.053528
train Loss: 14.7643 batch_loss: 481.810059
train Loss: 15.5109 batch_loss: 573.347046
train Loss: 16.1698 batch_loss: 506.057922
train Loss: 16.6151 batch_loss: 341.954407
train Loss: 16.9319 batch_loss: 243.324539
train Loss: 17.8217 batch_loss: 683.401794
train Loss: 18.6724 batch_loss: 653.301147
train Loss: 19.2102 batch_loss: 413.030945
train Loss: 19.8929 batch_loss: 524.308899
train Loss: 20.2829 batch_loss: 299.535156
train Loss: 21.3247 batch_loss: 800.117249
train Loss: 22.3662 batch_loss: 799.843567
train Loss: 22.8729 batch_loss: 389.147064
train Loss: 23.2823 batch_loss: 314.419495
train Loss: 23.8409 batch_loss: 429.023346
train Loss: 24.3881 batch_loss: 420.246155
train Loss: 25.0147 batch_loss: 481.203918
train Loss: 25.9089 batch_loss: 686.799683
train Loss: 26.3325 batch_loss: 325.299561
train Loss: 26.8637 batch_loss: 407.912628
train Loss: 27.7028 batch_loss: 644.477112
train Loss: 28.3451 batch_loss: 493.282318
train Loss: 28.6024 batch_loss: 197.623428
train Loss: 29.1823 batch_loss: 445.324219
train Loss: 29.9125 batch_loss: 560.775818
train Loss: 30.3216 batch_loss: 314.259705
train Loss: 30.8948 batch_loss: 440.158203
train Loss: 31.8162 batch_loss: 707.689270
^CTraceback (most recent call last):
  File "/home/rliu/anaconda2/lib/python2.7/multiprocessing/queues.py", line 268, in _feed
Traceback (most recent call last):
  File "/home/rliu/anaconda2/lib/python2.7/multiprocessing/queues.py", line 268, in _feed
Traceback (most recent call last):
    send(obj)
  File "/home/rliu/anaconda2/lib/python2.7/multiprocessing/queues.py", line 268, in _feed
  File "/home/rliu/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py", line 18, in send
    send(obj)
  File "/home/rliu/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py", line 18, in send
Traceback (most recent call last):
    self.send_bytes(buf.getvalue())
    send(obj)
  File "train.py", line 191, in <module>
IOError: [Errno 32] Broken pipe
    self.send_bytes(buf.getvalue())
  File "/home/rliu/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py", line 18, in send
IOError: [Errno 32] Broken pipe
    self.send_bytes(buf.getvalue())
    IOError: [Errno 32] Broken pipe
model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, batch_size = 4, step_size = 20, num_epochs=40)
  File "train.py", line 108, in train_model
    loss.backward()
  File "/home/rliu/anaconda2/lib/python2.7/site-packages/torch/tensor.py", line 102, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/rliu/anaconda2/lib/python2.7/site-packages/torch/autograd/__init__.py", line 90, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
krliu@dm:~/github/ansim\[rliu@dm ansim]$ exit
exit

Script done on Tue 16 Apr 2019 12:45:01 AM EDT
