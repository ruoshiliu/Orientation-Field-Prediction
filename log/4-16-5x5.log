Script started on Tue 16 Apr 2019 05:47:50 PM EDT
krliu@dm:~/github/ansim\[rliu@dm ansim]$ exitscreen -rls[Kclearpip2 install --upgrade scipy --user[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cls[Kmkdir resultsls[Kcd ..[3Plscd. .[3Plscd ..[3Plsmkdir resultsls[Kpip2 install --upgrade scipy --user[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cclear[K[3Plsscreen -r[5Pexit[KCUDA_VISIBLE_DEVICES=2 python3.6 train.py
GPU in use
Epoch 0/299
----------
trainloader ready!
testloader ready!
Traceback (most recent call last):
  File "train.py", line 214, in <module>
    image_size = 128)
  File "train.py", line 102, in train_model
    _, _, predicted = model(inputs)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 141, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/rliu/github/ansim/ConvLSTM.py", line 150, in forward
    cur_state=[h, c])
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/rliu/github/ansim/ConvLSTM.py", line 56, in forward
    c_next = f * c_cur + i * g
RuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 11.91 GiB total capacity; 11.28 GiB already allocated; 43.06 MiB free; 825.00 KiB cached)
krliu@dm:~/github/ansim\[rliu@dm ansim]$ CUDA_VISIBLE_DEVICES=2 python3.6 train.py
GPU in use
^CTraceback (most recent call last):
  File "train.py", line 193, in <module>
    model = torch.nn.DataParallel(model)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 134, in __init__
    self.module.cuda(device_ids[0])
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 260, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 187, in _apply
    module._apply(fn)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 193, in _apply
    param.data = fn(param.data)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 260, in <lambda>
    return self._apply(lambda t: t.cuda(device))
KeyboardInterrupt
krliu@dm:~/github/ansim\[rliu@dm ansim]$ CUDA_VISIBLE_DEVICES=2 python3.6 train.py[1@,[1@2[1P[1@3[1@1[1@,
GPU in use
Epoch 0/299
----------
trainloader ready!
testloader ready!
train Loss: 13.8831 batch_loss: 10662.204102
Traceback (most recent call last):
  File "train.py", line 214, in <module>
    image_size = 128)
  File "train.py", line 102, in train_model
    _, _, predicted = model(inputs)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 144, in forward
    return self.gather(outputs, self.output_device)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py", line 156, in gather
    return gather(outputs, output_device, dim=self.dim)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py", line 67, in gather
    return gather_map(outputs)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py", line 62, in gather_map
    return type(out)(map(gather_map, zip(*outputs)))
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py", line 62, in gather_map
    return type(out)(map(gather_map, zip(*outputs)))
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py", line 54, in gather_map
    return Gather.apply(target_device, dim, *outputs)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/nn/parallel/_functions.py", line 68, in forward
    return comm.gather(inputs, ctx.dim, ctx.target_device)
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/cuda/comm.py", line 166, in gather
    return torch._C._gather(tensors, dim, destination)
RuntimeError: CUDA out of memory. Tried to allocate 480.00 MiB (GPU 0; 11.91 GiB total capacity; 8.66 GiB already allocated; 326.06 MiB free; 790.16 MiB cached) (malloc at /pytorch/aten/src/THC/THCCachingAllocator.cpp:231)
frame #0: std::function<std::string ()>::operator()() const + 0x11 (0x7f699ff95fe1 in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x2a (0x7f699ff95dfa in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0x13cf9c5 (0x7f694a1529c5 in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)
frame #3: <unknown function> + 0x13d077a (0x7f694a15377a in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, at::TensorOptions const&) + 0x443 (0x7f694b2e5a43 in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)
frame #5: at::CUDAFloatType::empty(c10::ArrayRef<long>, at::TensorOptions const&) const + 0x161 (0x7f694a06c531 in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)
frame #6: torch::autograd::VariableType::empty(c10::ArrayRef<long>, at::TensorOptions const&) const + 0x179 (0x7f693edbedf9 in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libtorch.so.1)
frame #7: torch::cuda::gather(c10::ArrayRef<at::Tensor>, long, c10::optional<int>) + 0x28b (0x7f6979b2851b in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #8: <unknown function> + 0x4f501c (0x7f6979b2b01c in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #9: <unknown function> + 0x116fac (0x7f697974cfac in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #10: _PyCFunction_FastCallKeywords + 0x307 (0x4aa207 in python3.6)
frame #11: python3.6() [0x541094]
frame #12: _PyEval_EvalFrameDefault + 0x3584 (0x545604 in python3.6)
frame #13: python3.6() [0x540cb1]
frame #14: python3.6() [0x540faf]
frame #15: _PyEval_EvalFrameDefault + 0x3584 (0x545604 in python3.6)
frame #16: python3.6() [0x540cb1]
frame #17: PyEval_EvalCodeEx + 0x6d (0x541bad in python3.6)
frame #18: python3.6() [0x481edc]
frame #19: PyObject_Call + 0x60 (0x451f00 in python3.6)
frame #20: THPFunction_apply(_object*, _object*) + 0x581 (0x7f697994a4d1 in /home/rliu/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #21: PyCFunction_Call + 0xc1 (0x4a9e41 in python3.6)
frame #22: _PyEval_EvalFrameDefault + 0x786c (0x5498ec in python3.6)
frame #23: python3.6() [0x540cb1]
frame #24: _PyFunction_FastCallDict + 0x156 (0x549df6 in python3.6)
frame #25: _PyObject_FastCallDict + 0x1ef (0x45222f in python3.6)
frame #26: python3.6() [0x53c001]
frame #27: python3.6() [0x484ea5]
frame #28: python3.6() [0x485405]
frame #29: python3.6() [0x4bf82a]
frame #30: _PyObject_FastCallDict + 0xa2 (0x4520e2 in python3.6)
frame #31: python3.6() [0x540e05]
frame #32: _PyEval_EvalFrameDefault + 0x3584 (0x545604 in python3.6)
frame #33: python3.6() [0x540cb1]
frame #34: _PyFunction_FastCallDict + 0x156 (0x549df6 in python3.6)
frame #35: _PyObject_FastCallDict + 0x1ef (0x45222f in python3.6)
frame #36: python3.6() [0x53c001]
frame #37: PySequence_Tuple + 0xc9 (0x454259 in python3.6)
frame #38: python3.6() [0x4ba9b9]
frame #39: python3.6() [0x4bf793]
frame #40: _PyObject_FastCallDict + 0xa2 (0x4520e2 in python3.6)
frame #41: python3.6() [0x540e05]
frame #42: _PyEval_EvalFrameDefault + 0x3584 (0x545604 in python3.6)
frame #43: python3.6() [0x540cb1]
frame #44: python3.6() [0x540faf]
frame #45: _PyEval_EvalFrameDefault + 0x3584 (0x545604 in python3.6)
frame #46: python3.6() [0x540cb1]
frame #47: python3.6() [0x540faf]
frame #48: _PyEval_EvalFrameDefault + 0x435b (0x5463db in python3.6)
frame #49: python3.6() [0x53ffa1]
frame #50: python3.6() [0x5411d7]
frame #51: _PyEval_EvalFrameDefault + 0x3584 (0x545604 in python3.6)
frame #52: python3.6() [0x540cb1]
frame #53: _PyFunction_FastCallDict + 0x156 (0x549df6 in python3.6)
frame #54: _PyObject_FastCallDict + 0x1ef (0x45222f in python3.6)
frame #55: _PyObject_Call_Prepend + 0xcb (0x45232b in python3.6)
frame #56: PyObject_Call + 0x60 (0x451f00 in python3.6)
frame #57: _PyEval_EvalFrameDefault + 0x4262 (0x5462e2 in python3.6)
frame #58: python3.6() [0x540cb1]
frame #59: _PyFunction_FastCallDict + 0x156 (0x549df6 in python3.6)
frame #60: _PyObject_FastCallDict + 0x1ef (0x45222f in python3.6)
frame #61: _PyObject_Call_Prepend + 0xcb (0x45232b in python3.6)
frame #62: PyObject_Call + 0x60 (0x451f00 in python3.6)
frame #63: python3.6() [0x4c5463]

krliu@dm:~/github/ansim\[rliu@dm ansim]$ CUDA_VISIBLE_DEVICES=1,2,3 python3.6 train.py[1P[1P[1P[1P[1P[1@2[1@,[1@1[1@,[1@3
GPU in use
Epoch 0/299
----------
trainloader ready!
testloader ready!
train Loss: 9.7050 batch_loss: 7453.416016
train Loss: 26.8044 batch_loss: 13132.393555
train Loss: 42.1373 batch_loss: 11775.656250
train Loss: 53.1724 batch_loss: 8474.970703
train Loss: 63.6811 batch_loss: 8070.634277
train Loss: 75.7604 batch_loss: 9276.950195
train Loss: 87.9955 batch_loss: 9396.501953
train Loss: 101.8586 batch_loss: 10646.900391
train Loss: 113.6578 batch_loss: 9061.785156
train Loss: 125.4069 batch_loss: 9023.253906
train Loss: 139.6999 batch_loss: 10977.035156
train Loss: 152.6810 batch_loss: 9969.488281
train Loss: 164.1052 batch_loss: 8773.775391
train Loss: 173.7223 batch_loss: 7385.955078
train Loss: 183.8794 batch_loss: 7800.645996
train Loss: 198.6107 batch_loss: 11313.680664
train Loss: 210.5068 batch_loss: 9136.191406
train Loss: 223.9546 batch_loss: 10327.906250
train Loss: 232.2972 batch_loss: 6407.123535
train Loss: 245.5351 batch_loss: 10166.657227
train Loss: 253.3385 batch_loss: 5993.029785
train Loss: 264.3206 batch_loss: 8434.282227
train Loss: 275.5469 batch_loss: 8621.792969
train Loss: 289.0051 batch_loss: 10335.864258
train Loss: 298.6515 batch_loss: 7408.499023
train Loss: 311.1572 batch_loss: 9604.313477
train Loss: 325.0947 batch_loss: 10704.000000
train Loss: 335.3607 batch_loss: 7884.338379
train Loss: 345.9493 batch_loss: 8132.023438
train Loss: 359.0678 batch_loss: 10075.025391
train Loss: 372.1428 batch_loss: 10041.612305
train Loss: 382.1553 batch_loss: 7689.572266
train Loss: 390.1638 batch_loss: 6150.491699
train Loss: 399.8704 batch_loss: 7454.716309
train Loss: 409.9509 batch_loss: 7741.844727
train Loss: 416.7050 batch_loss: 5187.101562
train Loss: 427.3074 batch_loss: 8142.688477
train Loss: 438.8312 batch_loss: 8850.229492
train Loss: 450.4325 batch_loss: 8909.818359
train Loss: 461.6468 batch_loss: 8612.613281
train Loss: 474.1866 batch_loss: 9630.525391
train Loss: 487.1661 batch_loss: 9968.244141
train Loss: 493.9279 batch_loss: 5193.045898
train Loss: 503.5656 batch_loss: 7401.814453
train Loss: 514.9374 batch_loss: 8733.482422
train Loss: 526.2715 batch_loss: 8704.617188
train Loss: 540.7894 batch_loss: 11149.714844
train Loss: 549.6567 batch_loss: 6810.158203
train Loss: 560.4868 batch_loss: 8317.480469
train Loss: 573.1868 batch_loss: 9753.612305
train Loss: 583.3336 batch_loss: 7792.727051
train Loss: 593.3376 batch_loss: 7683.095703
train Loss: 601.7972 batch_loss: 6496.945801
train Loss: 613.4348 batch_loss: 8937.690430
train Loss: 625.3909 batch_loss: 9182.276367
train Loss: 634.5863 batch_loss: 7062.083496
train Loss: 642.3602 batch_loss: 5970.333496
train Loss: 650.9753 batch_loss: 6616.419922
train Loss: 659.2861 batch_loss: 6382.673340
train Loss: 664.7004 batch_loss: 4158.158691
train Loss: 672.3492 batch_loss: 5874.343750
train Loss: 681.2033 batch_loss: 6799.929199
train Loss: 692.2402 batch_loss: 8476.295898
train Loss: 703.2161 batch_loss: 8429.540039
train Loss: 710.1008 batch_loss: 5287.456055
train Loss: 719.1569 batch_loss: 6955.023926
train Loss: 730.2867 batch_loss: 8547.700195
train Loss: 739.5022 batch_loss: 7077.541016
train Loss: 747.2080 batch_loss: 5918.012695
train Loss: 753.5502 batch_loss: 4870.843750
train Loss: 762.7099 batch_loss: 7034.615723
train Loss: 773.2758 batch_loss: 8114.636230
train Loss: 781.2911 batch_loss: 6155.713379
train Loss: 790.1284 batch_loss: 6787.068848
train Loss: 798.3531 batch_loss: 6316.544922
train Loss: 806.4394 batch_loss: 6210.320801
train Loss: 816.8894 batch_loss: 8025.622070
train Loss: 824.5377 batch_loss: 5873.850098
train Loss: 832.3885 batch_loss: 6029.413574
train Loss: 840.8396 batch_loss: 6490.482910
train Loss: 847.0007 batch_loss: 4731.700195
train Loss: 855.6812 batch_loss: 6666.602539
train Loss: 863.4334 batch_loss: 5953.725098
train Loss: 871.2888 batch_loss: 6032.964355
train Loss: 878.1286 batch_loss: 5252.930664
train Loss: 888.1774 batch_loss: 7717.478027
train Loss: 894.0986 batch_loss: 4547.520508
train Loss: 900.0912 batch_loss: 4602.321777
train Loss: 907.5232 batch_loss: 5707.745117
train Loss: 916.0973 batch_loss: 6584.919922
train Loss: 922.7165 batch_loss: 5083.517090
train Loss: 930.1764 batch_loss: 5729.247070
train Loss: 935.6006 batch_loss: 4165.755371
train Loss: 942.5012 batch_loss: 5299.677246
train Loss: 947.3269 batch_loss: 3706.144287
train Loss: 952.1484 batch_loss: 3702.880371
train Loss: 961.7693 batch_loss: 7388.821777
train Loss: 968.5423 batch_loss: 5201.717285
train Loss: 975.6413 batch_loss: 5452.040527
train Loss: 981.1015 batch_loss: 4193.419434
train Loss: 986.0113 batch_loss: 3770.715332
train Loss: 991.8312 batch_loss: 4469.718750
train Loss: 997.1970 batch_loss: 4120.918945
train Loss: 1002.6452 batch_loss: 4184.170410
train Loss: 1012.8303 batch_loss: 7822.158691
train Loss: 1019.9519 batch_loss: 5469.388672
train Loss: 1027.2737 batch_loss: 5623.193848
train Loss: 1032.1987 batch_loss: 3782.356934
train Loss: 1038.2556 batch_loss: 4651.705566
train Loss: 1041.9542 batch_loss: 2840.531738
train Loss: 1045.6880 batch_loss: 2867.588135
train Loss: 1054.9095 batch_loss: 7082.064941
train Loss: 1061.8105 batch_loss: 5299.965820
train Loss: 1069.1885 batch_loss: 5666.327637
train Loss: 1078.2385 batch_loss: 6950.435547
train Loss: 1084.0842 batch_loss: 4489.435547
train Loss: 1091.6648 batch_loss: 5821.892578
train Loss: 1097.6200 batch_loss: 4573.654297
train Loss: 1105.1978 batch_loss: 5819.719727
train Loss: 1113.1219 batch_loss: 6085.684082
train Loss: 1121.1170 batch_loss: 6140.290039
train Loss: 1127.5863 batch_loss: 4968.392090
train Loss: 1133.7329 batch_loss: 4720.580566
train Loss: 1141.7244 batch_loss: 6137.456543
train Loss: 1145.6982 batch_loss: 3051.897461
train Loss: 1153.8375 batch_loss: 6250.957520
train Loss: 1160.2071 batch_loss: 4891.882324
train Loss: 1166.1292 batch_loss: 4548.178223
train Loss: 1174.3990 batch_loss: 6351.186523
train Loss: 1180.4499 batch_loss: 4647.131836
train Loss: 1188.5417 batch_loss: 6214.484375
train Loss: 1193.6397 batch_loss: 3915.234375
train Loss: 1203.2263 batch_loss: 7362.500977
train Loss: 1208.4866 batch_loss: 4039.922363
train Loss: 1214.7722 batch_loss: 4827.387695
train Loss: 1219.4906 batch_loss: 3623.693115
train Loss: 1228.4488 batch_loss: 6879.947266
train Loss: 1232.5954 batch_loss: 3184.590088
train Loss: 1237.8964 batch_loss: 4071.113525
train Loss: 1242.8309 batch_loss: 3789.750488
train Loss: 1247.6339 batch_loss: 3688.700684
train Loss: 1253.6204 batch_loss: 4597.568848
train Loss: 1257.0848 batch_loss: 2660.682373
train Loss: 1264.0599 batch_loss: 5356.914551
train Loss: 1268.1136 batch_loss: 3113.194824
train Loss: 1273.5882 batch_loss: 4204.514160
train Loss: 1281.2192 batch_loss: 5860.625000
train Loss: 1287.6027 batch_loss: 4902.534180
train Loss: 1294.2104 batch_loss: 5074.675293
train Loss: 1297.6777 batch_loss: 2662.891113
train Loss: 1305.9815 batch_loss: 6377.330078
train Loss: 1311.4536 batch_loss: 4202.604004
train Loss: 1317.7318 batch_loss: 4821.592773
train Loss: 1324.4139 batch_loss: 5131.891602
train Loss: 1326.6451 batch_loss: 1713.556641
train Loss: 1329.2864 batch_loss: 2028.527588
train Loss: 1331.7237 batch_loss: 1871.849976
train Loss: 1337.0183 batch_loss: 4066.250488
train Loss: 1344.2795 batch_loss: 5576.600098
train Loss: 1349.2382 batch_loss: 3808.269287
train Loss: 1356.0277 batch_loss: 5214.327637
train Loss: 1362.5511 batch_loss: 5009.961426
train Loss: 1367.8240 batch_loss: 4049.637451
train Loss: 1370.7674 batch_loss: 2260.506836
train Loss: 1373.2277 batch_loss: 1889.508545
train Loss: 1377.8816 batch_loss: 3574.192871
train Loss: 1383.0174 batch_loss: 3944.284668
train Loss: 1385.3929 batch_loss: 1824.353638
train Loss: 1391.9887 batch_loss: 5065.622559
train Loss: 1397.7535 batch_loss: 4427.354980
train Loss: 1402.7022 batch_loss: 3800.564941
train Loss: 1405.8568 batch_loss: 2422.731201
train Loss: 1409.9941 batch_loss: 3177.450928
train Loss: 1413.5204 batch_loss: 2708.227051
train Loss: 1416.2915 batch_loss: 2128.232178
train Loss: 1421.9717 batch_loss: 4362.335449
train Loss: 1426.4540 batch_loss: 3442.445312
train Loss: 1433.1462 batch_loss: 5139.626465
train Loss: 1437.8517 batch_loss: 3613.813965
train Loss: 1442.6521 batch_loss: 3686.720215
train Loss: 1447.7644 batch_loss: 3926.219238
train Loss: 1450.6414 batch_loss: 2209.574707
train Loss: 1455.8383 batch_loss: 3991.211426
train Loss: 1459.9581 batch_loss: 3163.983643
train Loss: 1463.5036 batch_loss: 2722.902100
train Loss: 1466.0213 batch_loss: 1933.619019
train Loss: 1470.1892 batch_loss: 3200.946289
train Loss: 1472.3114 batch_loss: 1629.838257
train Loss: 1477.1961 batch_loss: 3751.449951
train Loss: 1479.5606 batch_loss: 1815.971069
train Loss: 1483.8775 batch_loss: 3315.387451
train Loss: 1488.2024 batch_loss: 3321.521729
train Loss: 1490.7124 batch_loss: 1927.665649
train Loss: 1493.9727 batch_loss: 2503.899414
train Loss: 1498.6954 batch_loss: 3627.072998
train Loss: 1501.0544 batch_loss: 1811.697876
train Loss: 1504.5219 batch_loss: 2663.023926
train Loss: 1509.4350 batch_loss: 3773.288574
train Loss: 1513.4081 batch_loss: 3051.312988
train Loss: 1515.8929 batch_loss: 1908.308594
train Loss: 1519.0766 batch_loss: 2445.133057
train Loss: 1521.6382 batch_loss: 1967.297607
train Loss: 1524.6949 batch_loss: 2347.518311
train Loss: 1527.9000 batch_loss: 2461.522949
train Loss: 1533.5749 batch_loss: 4358.337402
train Loss: 1536.3704 batch_loss: 2146.927490
train Loss: 1538.4470 batch_loss: 1594.812622
train Loss: 1542.3488 batch_loss: 2996.597900
train Loss: 1546.8946 batch_loss: 3491.187012
train Loss: 1551.0465 batch_loss: 3188.638184
train Loss: 1556.3225 batch_loss: 4051.948486
train Loss: 1560.3044 batch_loss: 3058.123291
train Loss: 1563.4052 batch_loss: 2381.442139
train Loss: 1567.1775 batch_loss: 2897.096924
train Loss: 1571.4639 batch_loss: 3291.964355
train Loss: 1575.3107 batch_loss: 2954.360840
train Loss: 1577.9184 batch_loss: 2002.676514
train Loss: 1580.7824 batch_loss: 2199.531250
train Loss: 1583.2237 batch_loss: 1874.921143
train Loss: 1586.2595 batch_loss: 2331.553711
train Loss: 1591.3906 batch_loss: 3940.642334
train Loss: 1594.7890 batch_loss: 2609.999268
train Loss: 1597.5386 batch_loss: 2111.664795
train Loss: 1602.3496 batch_loss: 3694.880127
train Loss: 1605.3431 batch_loss: 2298.987061
train Loss: 1609.8366 batch_loss: 3451.031982
train Loss: 1611.8535 batch_loss: 1548.969604
train Loss: 1614.9815 batch_loss: 2402.324951
train Loss: 1618.6099 batch_loss: 2786.590820
train Loss: 1623.5063 batch_loss: 3760.417969
train Loss: 1625.2473 batch_loss: 1337.092163
train Loss: 1628.0061 batch_loss: 2118.734863
train Loss: 1632.6921 batch_loss: 3598.870117
train Loss: 1635.9280 batch_loss: 2485.143311
train Loss: 1638.7573 batch_loss: 2172.956543
train Loss: 1642.8748 batch_loss: 3162.223389
train Loss: 1645.7343 batch_loss: 2196.083252
train Loss: 1647.7693 batch_loss: 1562.889038
train Loss: 1653.2181 batch_loss: 4184.702637
train Loss: 1656.3633 batch_loss: 2415.502930
train Loss: 1658.5970 batch_loss: 1715.437378
train Loss: 1662.0276 batch_loss: 2634.694824
train Loss: 1666.6654 batch_loss: 3561.875000
train Loss: 1669.4597 batch_loss: 2146.018555
train Loss: 1670.7997 batch_loss: 1029.079346
train Loss: 1673.3984 batch_loss: 1995.815308
train Loss: 1675.7296 batch_loss: 1790.405151
train Loss: 1677.9268 batch_loss: 1687.449707
train Loss: 1679.0574 batch_loss: 868.263672
train Loss: 1681.8893 batch_loss: 2174.948730
train Loss: 1683.5559 batch_loss: 1279.940918
train Loss: 1685.7855 batch_loss: 1712.339600
train Loss: 1688.5624 batch_loss: 2132.639648
train Loss: 1691.0686 batch_loss: 1924.739380
train Loss: 1693.0351 batch_loss: 1510.264526
train Loss: 1695.4684 batch_loss: 1868.778442
Loss on the test images: 2012.40196 
Epoch 1/299
----------
trainloader ready!
testloader ready!
train Loss: 2.9014 batch_loss: 2228.250244
train Loss: 5.5018 batch_loss: 1997.095093
train Loss: 8.0486 batch_loss: 1955.988525
train Loss: 12.7802 batch_loss: 3633.833252
train Loss: 15.0949 batch_loss: 1777.732300
train Loss: 16.0930 batch_loss: 766.532104
train Loss: 17.9495 batch_loss: 1425.784668
train Loss: 19.7495 batch_loss: 1382.435303
train Loss: 21.8068 batch_loss: 1579.995972
train Loss: 23.1266 batch_loss: 1013.607422
train Loss: 25.3292 batch_loss: 1691.599487
train Loss: 27.6482 batch_loss: 1780.937134
train Loss: 29.5563 batch_loss: 1465.458130
train Loss: 32.4315 batch_loss: 2208.134277
train Loss: 35.6820 batch_loss: 2496.382812
train Loss: 38.0418 batch_loss: 1812.371094
train Loss: 41.1179 batch_loss: 2362.433350
train Loss: 44.2788 batch_loss: 2427.557373
train Loss: 46.6450 batch_loss: 1817.261719
train Loss: 50.0713 batch_loss: 2631.347656
train Loss: 52.8272 batch_loss: 2116.567871
train Loss: 55.0330 batch_loss: 1694.011475
train Loss: 57.2251 batch_loss: 1683.583984
train Loss: 60.5140 batch_loss: 2525.871338
train Loss: 63.7078 batch_loss: 2452.798340
train Loss: 66.7235 batch_loss: 2316.046875
train Loss: 70.2505 batch_loss: 2708.769775
train Loss: 72.7460 batch_loss: 1916.547974
train Loss: 75.8638 batch_loss: 2394.472412
train Loss: 77.0814 batch_loss: 935.083862
train Loss: 78.8933 batch_loss: 1391.546143
train Loss: 80.1492 batch_loss: 964.576721
train Loss: 82.8144 batch_loss: 2046.824219
train Loss: 83.2594 batch_loss: 341.761353
train Loss: 85.8712 batch_loss: 2005.864380
train Loss: 88.2383 batch_loss: 1817.944824
train Loss: 89.1340 batch_loss: 687.915833
train Loss: 91.8701 batch_loss: 2101.319336
train Loss: 93.0599 batch_loss: 913.759766
train Loss: 95.1703 batch_loss: 1620.815796
train Loss: 96.9778 batch_loss: 1388.124878
train Loss: 99.6052 batch_loss: 2017.867676
train Loss: 101.4622 batch_loss: 1426.170288
train Loss: 102.9367 batch_loss: 1132.372192
train Loss: 104.6886 batch_loss: 1345.456909
train Loss: 106.5868 batch_loss: 1457.834106
train Loss: 110.0365 batch_loss: 2649.358887
train Loss: 111.1834 batch_loss: 880.812561
train Loss: 113.7872 batch_loss: 1999.736206
train Loss: 116.5117 batch_loss: 2092.454102
train Loss: 117.7746 batch_loss: 969.863342
train Loss: 119.7768 batch_loss: 1537.731689
train Loss: 122.2397 batch_loss: 1891.471802
train Loss: 123.0626 batch_loss: 632.013550
train Loss: 125.3381 batch_loss: 1747.551025
train Loss: 126.0948 batch_loss: 581.200806
train Loss: 128.0477 batch_loss: 1499.766479
train Loss: 130.7461 batch_loss: 2072.398926
train Loss: 131.3587 batch_loss: 470.476685
train Loss: 131.8981 batch_loss: 414.259247
train Loss: 133.5277 batch_loss: 1251.504395
train Loss: 134.1884 batch_loss: 507.446686
train Loss: 135.2190 batch_loss: 791.461182
train Loss: 136.2365 batch_loss: 781.445679
train Loss: 136.8395 batch_loss: 463.144196
train Loss: 139.0944 batch_loss: 1731.737183
train Loss: 142.0313 batch_loss: 2255.522461
train Loss: 144.6785 batch_loss: 2033.102295
train Loss: 146.1536 batch_loss: 1132.866699
train Loss: 147.5524 batch_loss: 1074.254272
train Loss: 148.8693 batch_loss: 1011.363403
train Loss: 151.3909 batch_loss: 1936.658081
train Loss: 153.5742 batch_loss: 1676.705078
train Loss: 155.1045 batch_loss: 1175.309448
train Loss: 155.9153 batch_loss: 622.651062
train Loss: 157.3816 batch_loss: 1126.176270
train Loss: 159.2189 batch_loss: 1411.030396
train Loss: 160.2850 batch_loss: 818.793518
train Loss: 161.9897 batch_loss: 1309.182251
train Loss: 163.7163 batch_loss: 1326.024536
train Loss: 164.5096 batch_loss: 609.229553
train Loss: 167.0751 batch_loss: 1970.357056
train Loss: 169.7912 batch_loss: 2085.919678
train Loss: 172.4602 batch_loss: 2049.811768
train Loss: 174.6479 batch_loss: 1680.156250
train Loss: 175.6122 batch_loss: 740.580872
train Loss: 176.4446 batch_loss: 639.288330
train Loss: 177.4750 batch_loss: 791.322510
train Loss: 179.2931 batch_loss: 1396.295776
train Loss: 180.8284 batch_loss: 1179.114990
train Loss: 183.0143 batch_loss: 1678.793213
train Loss: 184.0841 batch_loss: 821.577881
train Loss: 187.0138 batch_loss: 2250.003418
train Loss: 188.7738 batch_loss: 1351.703369
train Loss: 190.2758 batch_loss: 1153.543457
train Loss: 191.7343 batch_loss: 1120.123291
train Loss: 193.2493 batch_loss: 1163.523682
train Loss: 195.4176 batch_loss: 1665.257690
train Loss: 198.5729 batch_loss: 2423.255615
train Loss: 199.9278 batch_loss: 1040.553955
train Loss: 201.9478 batch_loss: 1551.345825
train Loss: 203.3279 batch_loss: 1059.911011
train Loss: 204.7314 batch_loss: 1077.908203
train Loss: 206.2989 batch_loss: 1203.855103
train Loss: 206.8737 batch_loss: 441.463562
train Loss: 208.3965 batch_loss: 1169.486328
train Loss: 210.4068 batch_loss: 1543.957642
train Loss: 212.1674 batch_loss: 1352.116699
train Loss: 213.4914 batch_loss: 1016.821838
train Loss: 214.2320 batch_loss: 568.802979
train Loss: 215.6738 batch_loss: 1107.237915
train Loss: 216.4603 batch_loss: 604.103394
train Loss: 218.0592 batch_loss: 1227.942139
train Loss: 219.2711 batch_loss: 930.705688
train Loss: 219.7261 batch_loss: 349.440887
train Loss: 221.0513 batch_loss: 1017.787659
train Loss: 221.3845 batch_loss: 255.903320
train Loss: 222.2470 batch_loss: 662.392151
train Loss: 222.9129 batch_loss: 511.358673
train Loss: 224.9051 batch_loss: 1530.021851
train Loss: 226.2656 batch_loss: 1044.874390
train Loss: 228.4431 batch_loss: 1672.368408
train Loss: 229.1436 batch_loss: 537.973389
train Loss: 230.2108 batch_loss: 819.571411
train Loss: 232.1771 batch_loss: 1510.139771
train Loss: 232.8158 batch_loss: 490.529572
train Loss: 234.0957 batch_loss: 982.967896
train Loss: 235.3444 batch_loss: 958.962585
train Loss: 237.5963 batch_loss: 1729.468384
train Loss: 238.5901 batch_loss: 763.219788
train Loss: 239.6445 batch_loss: 809.804810
train Loss: 241.3790 batch_loss: 1332.064819
train Loss: 242.7647 batch_loss: 1064.277222
train Loss: 244.5794 batch_loss: 1393.669556
train Loss: 245.5707 batch_loss: 761.347290
train Loss: 246.3912 batch_loss: 630.137085
train Loss: 247.4364 batch_loss: 802.678528
train Loss: 248.5941 batch_loss: 889.115601
train Loss: 250.3148 batch_loss: 1321.498169
train Loss: 252.3546 batch_loss: 1566.565063
train Loss: 253.4300 batch_loss: 825.900208
train Loss: 255.4504 batch_loss: 1551.661865
train Loss: 256.4594 batch_loss: 774.903320
train Loss: 257.9737 batch_loss: 1162.986328
train Loss: 258.6877 batch_loss: 548.338074
train Loss: 260.4160 batch_loss: 1327.377808
train Loss: 261.6170 batch_loss: 922.387939
train Loss: 262.6504 batch_loss: 793.613525
train Loss: 264.0151 batch_loss: 1048.065186
train Loss: 265.0977 batch_loss: 831.451538
train Loss: 266.4574 batch_loss: 1044.265625
train Loss: 267.4495 batch_loss: 761.961243
train Loss: 267.7478 batch_loss: 229.032532
train Loss: 268.2605 batch_loss: 393.783691
train Loss: 268.7145 batch_loss: 348.707458
train Loss: 269.9833 batch_loss: 974.372620
train Loss: 270.5811 batch_loss: 459.129761
train Loss: 271.1283 batch_loss: 420.239563
train Loss: 272.3477 batch_loss: 936.537659
train Loss: 274.8427 batch_loss: 1916.184937
train Loss: 276.1035 batch_loss: 968.231018
train Loss: 276.5395 batch_loss: 334.888550
train Loss: 277.7627 batch_loss: 939.365662
train Loss: 278.7008 batch_loss: 720.473267
train Loss: 279.3614 batch_loss: 507.392303
train Loss: 280.0566 batch_loss: 533.860596
train Loss: 281.1134 batch_loss: 811.650269
train Loss: 281.6855 batch_loss: 439.372223
train Loss: 282.6892 batch_loss: 770.824158
train Loss: 283.2642 batch_loss: 441.626312
train Loss: 284.9356 batch_loss: 1283.653442
train Loss: 285.9683 batch_loss: 793.101013
train Loss: 287.7164 batch_loss: 1342.518677
train Loss: 288.8139 batch_loss: 842.913757
train Loss: 289.3576 batch_loss: 417.515808
train Loss: 290.4847 batch_loss: 865.632263
train Loss: 291.0645 batch_loss: 445.275665
train Loss: 291.9332 batch_loss: 667.183411
train Loss: 292.8346 batch_loss: 692.297424
train Loss: 294.1162 batch_loss: 984.230164
train Loss: 294.7120 batch_loss: 457.609650
train Loss: 296.1766 batch_loss: 1124.803345
train Loss: 297.1554 batch_loss: 751.725159
train Loss: 299.1485 batch_loss: 1530.644043
train Loss: 300.3454 batch_loss: 919.217346
train Loss: 301.4195 batch_loss: 824.974670
train Loss: 302.0994 batch_loss: 522.108765
train Loss: 302.5724 batch_loss: 363.316864
train Loss: 303.2999 batch_loss: 558.692993
train Loss: 304.2662 batch_loss: 742.133179
train Loss: 305.3142 batch_loss: 804.866943
train Loss: 306.1352 batch_loss: 630.466553
train Loss: 306.7805 batch_loss: 495.607605
train Loss: 308.2138 batch_loss: 1100.820801
train Loss: 308.6172 batch_loss: 309.781830
train Loss: 309.1565 batch_loss: 414.156677
train Loss: 309.6777 batch_loss: 400.318665
train Loss: 310.2902 batch_loss: 470.404297
train Loss: 311.8529 batch_loss: 1200.112061
train Loss: 313.0971 batch_loss: 955.591614
train Loss: 313.4285 batch_loss: 254.472000
train Loss: 314.5537 batch_loss: 864.180298
train Loss: 315.8389 batch_loss: 986.999878
train Loss: 316.9970 batch_loss: 889.422607
train Loss: 317.6343 batch_loss: 489.501526
train Loss: 318.0966 batch_loss: 355.002228
train Loss: 318.4778 batch_loss: 292.771301
train Loss: 319.6203 batch_loss: 877.476196
train Loss: 320.8995 batch_loss: 982.371155
train Loss: 321.9121 batch_loss: 777.708984
train Loss: 323.0363 batch_loss: 863.362244
train Loss: 323.7384 batch_loss: 539.261780
train Loss: 324.7857 batch_loss: 804.268799
train Loss: 325.9553 batch_loss: 898.265869
train Loss: 326.9937 batch_loss: 797.526672
train Loss: 327.3707 batch_loss: 289.487183
train Loss: 328.4235 batch_loss: 808.616028
train Loss: 329.2706 batch_loss: 650.504700
train Loss: 329.7740 batch_loss: 386.668243
train Loss: 330.6203 batch_loss: 649.929932
train Loss: 331.1130 batch_loss: 378.382721
train Loss: 331.5191 batch_loss: 311.932953
train Loss: 332.3871 batch_loss: 666.581787
train Loss: 332.7762 batch_loss: 298.823639
train Loss: 333.4275 batch_loss: 500.241791
train Loss: 334.6472 batch_loss: 936.695496
train Loss: 335.0965 batch_loss: 345.084320
train Loss: 336.5895 batch_loss: 1146.602905
train Loss: 337.4661 batch_loss: 673.262756
train Loss: 338.5251 batch_loss: 813.315857
train Loss: 339.2498 batch_loss: 556.557434
train Loss: 340.2159 batch_loss: 741.941467
train Loss: 340.9545 batch_loss: 567.257690
train Loss: 342.1585 batch_loss: 924.669373
train Loss: 343.4183 batch_loss: 967.508972
train Loss: 344.3856 batch_loss: 742.856384
train Loss: 344.7889 batch_loss: 309.793488
train Loss: 346.0236 batch_loss: 948.199341
train Loss: 346.9703 batch_loss: 727.125000
train Loss: 347.3383 batch_loss: 282.630554
train Loss: 348.1562 batch_loss: 628.080444
train Loss: 349.1314 batch_loss: 748.954895
train Loss: 349.9828 batch_loss: 653.932678
train Loss: 350.6251 batch_loss: 493.235291
train Loss: 351.4938 batch_loss: 667.174622
train Loss: 352.3846 batch_loss: 684.159912
train Loss: 352.8909 batch_loss: 388.842316
train Loss: 353.5949 batch_loss: 540.664062
train Loss: 354.1719 batch_loss: 443.092834
train Loss: 354.8772 batch_loss: 541.689575
train Loss: 355.9720 batch_loss: 840.783142
train Loss: 357.1774 batch_loss: 925.811096
train Loss: 357.4196 batch_loss: 186.013504
train Loss: 358.0094 batch_loss: 452.919312
train Loss: 359.0526 batch_loss: 801.218628
train Loss: 359.4224 batch_loss: 283.948944
Loss on the test images: 623.59463 
Epoch 2/299
----------
trainloader ready!
testloader ready!
train Loss: 0.9457 batch_loss: 726.306641
train Loss: 1.2948 batch_loss: 268.109070
train Loss: 2.1188 batch_loss: 632.838867
train Loss: 2.8494 batch_loss: 561.078552
train Loss: 3.4099 batch_loss: 430.443420
train Loss: 4.3143 batch_loss: 694.604919
train Loss: 5.1494 batch_loss: 641.366577
train Loss: 6.0518 batch_loss: 693.060547
train Loss: 7.1840 batch_loss: 869.519897
train Loss: 8.3372 batch_loss: 885.606262
train Loss: 9.2377 batch_loss: 691.589294
train Loss: 9.8865 batch_loss: 498.324493
train Loss: 11.1801 batch_loss: 993.437378
train Loss: 11.6745 batch_loss: 379.706390
train Loss: 12.4309 batch_loss: 580.961731
train Loss: 12.8640 batch_loss: 332.564728
train Loss: 13.6254 batch_loss: 584.807800
train Loss: 14.1359 batch_loss: 392.022980
train Loss: 14.9363 batch_loss: 614.720337
train Loss: 15.5365 batch_loss: 460.986542
train Loss: 16.0079 batch_loss: 362.040466
train Loss: 16.6977 batch_loss: 529.770386
train Loss: 17.5554 batch_loss: 658.705139
train Loss: 18.0968 batch_loss: 415.765045
train Loss: 18.8914 batch_loss: 610.291748
train Loss: 19.1457 batch_loss: 195.269073
train Loss: 20.1941 batch_loss: 805.197144
train Loss: 20.5538 batch_loss: 276.224762
train Loss: 21.0702 batch_loss: 396.556000
train Loss: 22.4555 batch_loss: 1063.921753
train Loss: 23.2134 batch_loss: 582.124939
train Loss: 23.9473 batch_loss: 563.573181
train Loss: 25.1099 batch_loss: 892.911926
train Loss: 26.2257 batch_loss: 856.891357
train Loss: 26.6903 batch_loss: 356.866852
train Loss: 27.6243 batch_loss: 717.267578
train Loss: 28.3038 batch_loss: 521.913147
train Loss: 29.0957 batch_loss: 608.125916
train Loss: 29.6895 batch_loss: 456.033539
train Loss: 30.3892 batch_loss: 537.384766
train Loss: 31.4021 batch_loss: 777.935852
train Loss: 31.7817 batch_loss: 291.504700
train Loss: 32.3952 batch_loss: 471.173492
train Loss: 32.9537 batch_loss: 428.916809
train Loss: 33.4810 batch_loss: 404.992035
train Loss: 34.3071 batch_loss: 634.425354
train Loss: 34.8928 batch_loss: 449.868805
train Loss: 35.4036 batch_loss: 392.285492
train Loss: 36.2629 batch_loss: 659.946899
train Loss: 36.9967 batch_loss: 563.555664
train Loss: 37.9021 batch_loss: 695.315002
train Loss: 38.7391 batch_loss: 642.806702
train Loss: 39.3911 batch_loss: 500.779694
train Loss: 39.9571 batch_loss: 434.629944
train Loss: 40.5928 batch_loss: 488.223419
train Loss: 40.8721 batch_loss: 214.516113
train Loss: 41.9378 batch_loss: 818.464478
train Loss: 42.7906 batch_loss: 654.941772
train Loss: 43.5581 batch_loss: 589.439087
train Loss: 43.7146 batch_loss: 120.203026
train Loss: 44.5722 batch_loss: 658.635132
train Loss: 45.2055 batch_loss: 486.404633
train Loss: 45.9058 batch_loss: 537.778259
train Loss: 46.5015 batch_loss: 457.493256
train Loss: 47.0913 batch_loss: 452.969086
train Loss: 48.0883 batch_loss: 765.754944
train Loss: 48.4788 batch_loss: 299.861908
train Loss: 49.0589 batch_loss: 445.544342
train Loss: 50.0034 batch_loss: 725.323914
train Loss: 50.8283 batch_loss: 633.546692
train Loss: 51.4621 batch_loss: 486.779510
train Loss: 52.0159 batch_loss: 425.302795
train Loss: 52.4446 batch_loss: 329.206940
train Loss: 52.6778 batch_loss: 179.140320
train Loss: 52.8397 batch_loss: 124.305061
train Loss: 53.2862 batch_loss: 342.958069
train Loss: 53.8703 batch_loss: 448.600311
train Loss: 54.6244 batch_loss: 579.081238
train Loss: 55.3111 batch_loss: 527.391052
train Loss: 56.2019 batch_loss: 684.179565
train Loss: 56.8525 batch_loss: 499.678162
train Loss: 57.4471 batch_loss: 456.599609
train Loss: 58.0903 batch_loss: 494.033783
train Loss: 58.7264 batch_loss: 488.501404
train Loss: 59.1186 batch_loss: 301.214661
train Loss: 59.6585 batch_loss: 414.654114
train Loss: 60.1605 batch_loss: 385.530731
train Loss: 60.7636 batch_loss: 463.137817
train Loss: 61.3662 batch_loss: 462.832947
train Loss: 61.7870 batch_loss: 323.166718
train Loss: 62.5925 batch_loss: 618.605225
train Loss: 63.7961 batch_loss: 924.384644
train Loss: 64.8163 batch_loss: 783.481140
train Loss: 65.2934 batch_loss: 366.454041
train Loss: 66.1280 batch_loss: 640.949097
train Loss: 66.7542 batch_loss: 480.924042
train Loss: 67.6869 batch_loss: 716.333618
train Loss: 68.4473 batch_loss: 583.984680
train Loss: 68.7871 batch_loss: 260.974670
train Loss: 69.4516 batch_loss: 510.308990
train Loss: 70.1810 batch_loss: 560.221313
train Loss: 70.6667 batch_loss: 373.011658
train Loss: 71.4106 batch_loss: 571.259521
train Loss: 72.0433 batch_loss: 485.948639
train Loss: 72.6829 batch_loss: 491.177032
train Loss: 73.2782 batch_loss: 457.211395
train Loss: 73.9059 batch_loss: 482.114197
train Loss: 74.8292 batch_loss: 709.058594
train Loss: 75.6910 batch_loss: 661.853333
train Loss: 76.2901 batch_loss: 460.126312
train Loss: 77.0781 batch_loss: 605.147217
train Loss: 77.5344 batch_loss: 350.463806
train Loss: 78.1443 batch_loss: 468.396454
train Loss: 78.8093 batch_loss: 510.728973
train Loss: 79.2306 batch_loss: 323.581879
train Loss: 79.6258 batch_loss: 303.471680
train Loss: 80.2788 batch_loss: 501.490509
train Loss: 81.0765 batch_loss: 612.628784
train Loss: 81.9114 batch_loss: 641.236206
train Loss: 82.5709 batch_loss: 506.473663
train Loss: 83.2580 batch_loss: 527.732605
train Loss: 83.7274 batch_loss: 360.509583
train Loss: 84.1170 batch_loss: 299.184601
train Loss: 84.6452 batch_loss: 405.626160
train Loss: 85.1961 batch_loss: 423.145844
train Loss: 85.8892 batch_loss: 532.313782
train Loss: 86.3307 batch_loss: 339.064972
train Loss: 87.0336 batch_loss: 539.803406
train Loss: 87.5567 batch_loss: 401.755463
train Loss: 88.4148 batch_loss: 658.985657
train Loss: 89.1544 batch_loss: 567.999878
train Loss: 89.6980 batch_loss: 417.509125
train Loss: 90.1239 batch_loss: 327.099426
train Loss: 90.6524 batch_loss: 405.858521
train Loss: 91.4462 batch_loss: 609.674011
train Loss: 91.8424 batch_loss: 304.238464
train Loss: 92.4949 batch_loss: 501.168762
train Loss: 93.0415 batch_loss: 419.783966
train Loss: 93.5244 batch_loss: 370.889313
train Loss: 94.5386 batch_loss: 778.898682
train Loss: 94.8739 batch_loss: 257.464111
train Loss: 95.3029 batch_loss: 329.499359
train Loss: 95.8479 batch_loss: 418.546875
train Loss: 96.5627 batch_loss: 549.010132
train Loss: 97.0459 batch_loss: 371.082306
train Loss: 97.6465 batch_loss: 461.225708
train Loss: 97.9472 batch_loss: 230.966995
train Loss: 98.2393 batch_loss: 224.289658
train Loss: 98.5763 batch_loss: 258.828156
train Loss: 99.0531 batch_loss: 366.181580
train Loss: 99.5460 batch_loss: 378.540741
train Loss: 99.8631 batch_loss: 243.527313
train Loss: 100.5298 batch_loss: 512.056030
train Loss: 101.4346 batch_loss: 694.851318
train Loss: 101.8810 batch_loss: 342.902435
train Loss: 102.2136 batch_loss: 255.424454
train Loss: 102.5807 batch_loss: 281.927032
train Loss: 103.3157 batch_loss: 564.434387
train Loss: 103.7511 batch_loss: 334.425385
train Loss: 104.2862 batch_loss: 410.940582
train Loss: 104.4513 batch_loss: 126.800552
train Loss: 104.9633 batch_loss: 393.188416
train Loss: 105.2826 batch_loss: 245.223602
train Loss: 105.7969 batch_loss: 395.034058
train Loss: 106.6835 batch_loss: 680.875366
train Loss: 107.0573 batch_loss: 287.100006
train Loss: 107.6049 batch_loss: 420.585938
train Loss: 107.8641 batch_loss: 199.060379
train Loss: 108.6073 batch_loss: 570.755066
train Loss: 108.8772 batch_loss: 207.266754
train Loss: 109.5146 batch_loss: 489.495392
train Loss: 110.3568 batch_loss: 646.812622
train Loss: 110.7784 batch_loss: 323.805786
train Loss: 111.1980 batch_loss: 322.287140
train Loss: 111.5652 batch_loss: 281.991608
train Loss: 112.1441 batch_loss: 444.600250
train Loss: 112.6073 batch_loss: 355.702484
train Loss: 113.0909 batch_loss: 371.433319
train Loss: 113.8335 batch_loss: 570.296265
train Loss: 114.4916 batch_loss: 505.443848
train Loss: 115.3824 batch_loss: 684.105469
train Loss: 115.7087 batch_loss: 250.598862
train Loss: 116.3919 batch_loss: 524.689697
train Loss: 116.9015 batch_loss: 391.385437
train Loss: 117.3206 batch_loss: 321.858459
train Loss: 117.7145 batch_loss: 302.520844
train Loss: 118.6172 batch_loss: 693.278381
train Loss: 119.5695 batch_loss: 731.375916
train Loss: 120.1577 batch_loss: 451.765045
train Loss: 120.5309 batch_loss: 286.606873
train Loss: 121.0655 batch_loss: 410.542969
train Loss: 121.8379 batch_loss: 593.264771
train Loss: 122.2359 batch_loss: 305.635376
train Loss: 122.8457 batch_loss: 468.295319
train Loss: 123.3806 batch_loss: 410.801086
train Loss: 123.9919 batch_loss: 469.485687
train Loss: 124.4315 batch_loss: 337.646088
train Loss: 124.9309 batch_loss: 383.537933
train Loss: 125.3881 batch_loss: 351.084259
train Loss: 125.9316 batch_loss: 417.403839
train Loss: 126.5191 batch_loss: 451.269928
train Loss: 127.1258 batch_loss: 465.879883
train Loss: 127.3327 batch_loss: 158.926712
train Loss: 127.9799 batch_loss: 497.087952
train Loss: 128.4144 batch_loss: 333.690369
train Loss: 128.8902 batch_loss: 365.406311
train Loss: 129.7019 batch_loss: 623.343689
train Loss: 130.4389 batch_loss: 566.051392
train Loss: 130.9574 batch_loss: 398.185028
train Loss: 131.6065 batch_loss: 498.509796
train Loss: 132.2426 batch_loss: 488.515564
train Loss: 132.8798 batch_loss: 489.405792
train Loss: 133.3914 batch_loss: 392.910950
train Loss: 133.7360 batch_loss: 264.644318
train Loss: 134.7358 batch_loss: 767.869019
train Loss: 135.2309 batch_loss: 380.180969
train Loss: 135.5874 batch_loss: 273.791779
train Loss: 135.9461 batch_loss: 275.485748
train Loss: 136.6732 batch_loss: 558.443726
train Loss: 137.4659 batch_loss: 608.747070
train Loss: 137.9994 batch_loss: 409.744995
train Loss: 138.4948 batch_loss: 380.474457
train Loss: 138.9371 batch_loss: 339.667328
train Loss: 139.3447 batch_loss: 313.091339
train Loss: 139.8808 batch_loss: 411.681549
train Loss: 140.4640 batch_loss: 447.924347
train Loss: 140.8181 batch_loss: 271.939758
train Loss: 141.1995 batch_loss: 292.930328
train Loss: 141.6899 batch_loss: 376.611755
train Loss: 142.2644 batch_loss: 441.198761
train Loss: 142.9125 batch_loss: 497.766510
train Loss: 143.3372 batch_loss: 326.135315
train Loss: 143.8914 batch_loss: 425.660248
train Loss: 144.8996 batch_loss: 774.267334
train Loss: 145.3960 batch_loss: 381.272308
train Loss: 145.7280 batch_loss: 254.943878
train Loss: 146.1845 batch_loss: 350.580658
train Loss: 146.7636 batch_loss: 444.738800
train Loss: 147.1151 batch_loss: 269.988220
train Loss: 147.4223 batch_loss: 235.903381
train Loss: 148.4475 batch_loss: 787.414062
train Loss: 149.3292 batch_loss: 677.109680
train Loss: 149.9145 batch_loss: 449.487885
train Loss: 150.4936 batch_loss: 444.793091
train Loss: 151.2042 batch_loss: 545.727539
train Loss: 151.7986 batch_loss: 456.528992
train Loss: 152.3217 batch_loss: 401.733521
train Loss: 152.6163 batch_loss: 226.225494
train Loss: 152.9072 batch_loss: 223.438873
train Loss: 153.7842 batch_loss: 673.538757
train Loss: 154.4171 batch_loss: 486.062561
train Loss: 155.0011 batch_loss: 448.480408
train Loss: 155.7171 batch_loss: 549.923950
train Loss: 156.3293 batch_loss: 470.148224
train Loss: 157.1380 batch_loss: 621.107666
train Loss: 157.4449 batch_loss: 235.666641
Loss on the test images: 471.29572 
Epoch 3/299
----------
trainloader ready!
testloader ready!
train Loss: 0.4038 batch_loss: 310.124939
train Loss: 1.0265 batch_loss: 478.226227
train Loss: 1.6258 batch_loss: 460.271118
train Loss: 2.3906 batch_loss: 587.350464
train Loss: 3.0556 batch_loss: 510.736511
train Loss: 3.5305 batch_loss: 364.747894
train Loss: 4.1844 batch_loss: 502.192780
train Loss: 4.7189 batch_loss: 410.446564
train Loss: 5.1134 batch_loss: 303.017120
train Loss: 5.4799 batch_loss: 281.418579
train Loss: 5.8928 batch_loss: 317.164917
train Loss: 6.4638 batch_loss: 438.469025
train Loss: 7.3520 batch_loss: 682.155823
train Loss: 7.9346 batch_loss: 447.419891
train Loss: 8.3805 batch_loss: 342.479553
train Loss: 9.0199 batch_loss: 491.055542
train Loss: 9.6096 batch_loss: 452.924805
train Loss: 10.1893 batch_loss: 445.187927
train Loss: 11.0169 batch_loss: 635.615417
train Loss: 11.7898 batch_loss: 593.594543
train Loss: 12.2093 batch_loss: 322.166138
train Loss: 12.4147 batch_loss: 157.692886
train Loss: 13.1468 batch_loss: 562.307983
train Loss: 13.7797 batch_loss: 486.043091
train Loss: 14.6594 batch_loss: 675.646240
train Loss: 15.0863 batch_loss: 327.823151
train Loss: 15.4363 batch_loss: 268.811523
train Loss: 16.2577 batch_loss: 630.829651
train Loss: 16.7463 batch_loss: 375.208588
train Loss: 17.1838 batch_loss: 336.000519
train Loss: 17.6702 batch_loss: 373.597260
train Loss: 18.3298 batch_loss: 506.536530
train Loss: 18.5845 batch_loss: 195.661591
train Loss: 19.1777 batch_loss: 455.569794
train Loss: 19.7478 batch_loss: 437.834503
train Loss: 20.2118 batch_loss: 356.359253
train Loss: 20.3683 batch_loss: 120.132202
train Loss: 20.8758 batch_loss: 389.810822
train Loss: 21.1658 batch_loss: 222.679260
train Loss: 21.6418 batch_loss: 365.572296
train Loss: 22.0396 batch_loss: 305.558044
train Loss: 22.7762 batch_loss: 565.644470
train Loss: 23.2885 batch_loss: 393.515625
train Loss: 23.7276 batch_loss: 337.223694
train Loss: 24.1910 batch_loss: 355.870728
train Loss: 24.8414 batch_loss: 499.477509
train Loss: 25.6056 batch_loss: 586.900146
train Loss: 25.8703 batch_loss: 203.289200
train Loss: 26.3498 batch_loss: 368.300446
train Loss: 26.6843 batch_loss: 256.916504
train Loss: 27.1047 batch_loss: 322.865509
train Loss: 27.4656 batch_loss: 277.113281
train Loss: 28.2811 batch_loss: 626.343201
train Loss: 28.7383 batch_loss: 351.138397
train Loss: 29.4234 batch_loss: 526.128540
train Loss: 29.8484 batch_loss: 326.370056
train Loss: 30.4250 batch_loss: 442.856018
train Loss: 30.7124 batch_loss: 220.693588
train Loss: 31.3065 batch_loss: 456.328400
train Loss: 31.7934 batch_loss: 373.890594
train Loss: 32.2526 batch_loss: 352.698639
train Loss: 32.3731 batch_loss: 92.503944
train Loss: 32.9689 batch_loss: 457.622650
train Loss: 33.2798 batch_loss: 238.788025
train Loss: 33.5778 batch_loss: 228.840897
train Loss: 34.2751 batch_loss: 535.518860
train Loss: 34.6691 batch_loss: 302.605499
train Loss: 35.4268 batch_loss: 581.899109
train Loss: 35.8715 batch_loss: 341.529083
train Loss: 36.4766 batch_loss: 464.699005
train Loss: 36.9206 batch_loss: 341.013550
train Loss: 37.2013 batch_loss: 215.609116
train Loss: 37.7605 batch_loss: 429.451691
train Loss: 38.1855 batch_loss: 326.355560
train Loss: 38.5850 batch_loss: 306.852966
train Loss: 39.1414 batch_loss: 427.317719
train Loss: 39.5865 batch_loss: 341.818390
train Loss: 40.0415 batch_loss: 349.406952
train Loss: 40.5687 batch_loss: 404.895844
train Loss: 41.1453 batch_loss: 442.882111
train Loss: 41.6307 batch_loss: 372.758881
train Loss: 42.0878 batch_loss: 351.081848
train Loss: 42.3859 batch_loss: 228.942078
train Loss: 42.9823 batch_loss: 457.984711
train Loss: 43.6466 batch_loss: 510.190765
train Loss: 44.1119 batch_loss: 357.328583
train Loss: 44.4236 batch_loss: 239.391403
train Loss: 44.9048 batch_loss: 369.564972
train Loss: 45.5454 batch_loss: 492.034454
train Loss: 45.9151 batch_loss: 283.917694
train Loss: 46.4491 batch_loss: 410.089905
train Loss: 47.1130 batch_loss: 509.895081
train Loss: 47.4630 batch_loss: 268.776825
train Loss: 47.9745 batch_loss: 392.833527
train Loss: 48.5818 batch_loss: 466.434509
train Loss: 49.1507 batch_loss: 436.921021
train Loss: 49.5694 batch_loss: 321.542511
train Loss: 50.0218 batch_loss: 347.400513
train Loss: 50.4855 batch_loss: 356.136536
train Loss: 50.9594 batch_loss: 363.975952
train Loss: 51.5274 batch_loss: 436.243744
train Loss: 52.0138 batch_loss: 373.553009
train Loss: 52.4936 batch_loss: 368.438354
train Loss: 52.9156 batch_loss: 324.120941
train Loss: 53.2803 batch_loss: 280.076843
train Loss: 53.7718 batch_loss: 377.485870
train Loss: 53.9153 batch_loss: 110.224228
train Loss: 54.1824 batch_loss: 205.153458
train Loss: 54.4759 batch_loss: 225.396271
train Loss: 55.1046 batch_loss: 482.796997
train Loss: 55.5569 batch_loss: 347.401794
train Loss: 56.0394 batch_loss: 370.536316
train Loss: 56.5177 batch_loss: 367.338348
train Loss: 56.9849 batch_loss: 358.799133
train Loss: 57.4886 batch_loss: 386.887512
train Loss: 57.8501 batch_loss: 277.614075
train Loss: 58.2298 batch_loss: 291.571014
train Loss: 58.8092 batch_loss: 445.034180
train Loss: 59.2027 batch_loss: 302.213043
train Loss: 59.8214 batch_loss: 475.128387
train Loss: 60.2189 batch_loss: 305.250580
train Loss: 60.6336 batch_loss: 318.514496
train Loss: 61.0191 batch_loss: 296.065582
train Loss: 61.6203 batch_loss: 461.693359
train Loss: 62.0318 batch_loss: 316.040833
train Loss: 62.6173 batch_loss: 449.689331
train Loss: 62.8601 batch_loss: 186.442795
train Loss: 63.3447 batch_loss: 372.224670
train Loss: 63.6912 batch_loss: 266.092072
train Loss: 64.0468 batch_loss: 273.128601
train Loss: 64.6415 batch_loss: 456.683960
train Loss: 65.0231 batch_loss: 293.046356
train Loss: 65.5464 batch_loss: 401.955292
train Loss: 66.3069 batch_loss: 584.011047
train Loss: 66.8769 batch_loss: 437.797668
train Loss: 67.1496 batch_loss: 209.388031
train Loss: 67.5811 batch_loss: 331.446411
train Loss: 67.9175 batch_loss: 258.301880
train Loss: 68.2352 batch_loss: 244.009445
train Loss: 68.5120 batch_loss: 212.631668
train Loss: 68.7371 batch_loss: 172.812668
train Loss: 69.2133 batch_loss: 365.742767
train Loss: 69.6082 batch_loss: 303.330994
train Loss: 70.1955 batch_loss: 451.000793
train Loss: 70.4364 batch_loss: 184.997635
train Loss: 71.1158 batch_loss: 521.771301
train Loss: 71.4078 batch_loss: 224.299423
train Loss: 71.9550 batch_loss: 420.209778
train Loss: 72.3710 batch_loss: 319.541534
train Loss: 72.8893 batch_loss: 398.059082
train Loss: 73.1724 batch_loss: 217.407867
train Loss: 73.7745 batch_loss: 462.391724
train Loss: 74.1924 batch_loss: 320.921112
train Loss: 74.8380 batch_loss: 495.832825
train Loss: 75.3953 batch_loss: 428.030426
train Loss: 75.6634 batch_loss: 205.914322
train Loss: 75.9769 batch_loss: 240.768539
train Loss: 76.5195 batch_loss: 416.690002
train Loss: 76.8822 batch_loss: 278.542664
train Loss: 77.3715 batch_loss: 375.820099
train Loss: 77.9069 batch_loss: 411.166016
train Loss: 78.3974 batch_loss: 376.715027
train Loss: 78.7828 batch_loss: 295.999786
train Loss: 79.1878 batch_loss: 310.979980
train Loss: 79.4639 batch_loss: 212.052200
train Loss: 79.9788 batch_loss: 395.461456
train Loss: 80.5525 batch_loss: 440.644806
train Loss: 81.2911 batch_loss: 567.178772
train Loss: 81.7460 batch_loss: 349.364563
train Loss: 82.2603 batch_loss: 394.978455
train Loss: 82.8100 batch_loss: 422.177429
train Loss: 83.3489 batch_loss: 413.912872
train Loss: 83.6359 batch_loss: 220.406998
train Loss: 83.8999 batch_loss: 202.728806
train Loss: 84.3302 batch_loss: 330.490936
train Loss: 84.5195 batch_loss: 145.373245
train Loss: 84.8072 batch_loss: 221.004608
train Loss: 85.5651 batch_loss: 582.039734
train Loss: 86.0917 batch_loss: 404.397583
train Loss: 86.6109 batch_loss: 398.786530
train Loss: 87.0535 batch_loss: 339.887085
train Loss: 87.5202 batch_loss: 358.419708
train Loss: 87.9153 batch_loss: 303.450836
train Loss: 88.4659 batch_loss: 422.837067
train Loss: 88.7285 batch_loss: 201.725693
train Loss: 89.1721 batch_loss: 340.662689
train Loss: 89.4857 batch_loss: 240.838577
train Loss: 89.9215 batch_loss: 334.679077
train Loss: 90.5091 batch_loss: 451.273529
train Loss: 90.9088 batch_loss: 307.026306
train Loss: 91.3463 batch_loss: 335.958221
train Loss: 91.8542 batch_loss: 390.077698
train Loss: 92.4436 batch_loss: 452.660278
train Loss: 92.8349 batch_loss: 300.506958
train Loss: 93.5487 batch_loss: 548.229309
train Loss: 94.0535 batch_loss: 387.652161
train Loss: 94.3216 batch_loss: 205.916611
train Loss: 94.6220 batch_loss: 230.738922
train Loss: 95.0288 batch_loss: 312.384003
train Loss: 95.5962 batch_loss: 435.769592
train Loss: 96.0202 batch_loss: 325.626129
train Loss: 96.6658 batch_loss: 495.814301
train Loss: 96.9111 batch_loss: 188.419876
train Loss: 97.4053 batch_loss: 379.513092
train Loss: 97.9526 batch_loss: 420.344025
train Loss: 98.3981 batch_loss: 342.148346
train Loss: 99.0117 batch_loss: 471.263031
train Loss: 99.3718 batch_loss: 276.520294
train Loss: 99.9549 batch_loss: 447.813812
train Loss: 100.3961 batch_loss: 338.842560
train Loss: 100.7769 batch_loss: 292.465820
train Loss: 101.0168 batch_loss: 184.266022
train Loss: 101.5274 batch_loss: 392.154266
train Loss: 102.1795 batch_loss: 500.815918
train Loss: 102.6726 batch_loss: 378.639313
train Loss: 102.8690 batch_loss: 150.871582
train Loss: 103.4238 batch_loss: 426.072479
train Loss: 104.0439 batch_loss: 476.217957
train Loss: 104.4385 batch_loss: 303.094635
train Loss: 104.8766 batch_loss: 336.426758
train Loss: 105.3603 batch_loss: 371.486786
train Loss: 105.7584 batch_loss: 305.743744
train Loss: 106.0739 batch_loss: 242.344208
train Loss: 106.5201 batch_loss: 342.673645
train Loss: 107.0937 batch_loss: 440.519012
train Loss: 107.5792 batch_loss: 372.820587
train Loss: 107.9486 batch_loss: 283.729279
train Loss: 108.3002 batch_loss: 270.035889
train Loss: 108.7424 batch_loss: 339.600250
train Loss: 109.1991 batch_loss: 350.704681
train Loss: 109.6357 batch_loss: 335.320648
train Loss: 109.7595 batch_loss: 95.081444
train Loss: 109.9909 batch_loss: 177.758209
train Loss: 110.5229 batch_loss: 408.517303
train Loss: 110.9988 batch_loss: 365.563477
train Loss: 111.5178 batch_loss: 398.564850
train Loss: 111.8643 batch_loss: 266.082733
train Loss: 112.3963 batch_loss: 408.608978
train Loss: 112.7924 batch_loss: 304.170563
train Loss: 113.2671 batch_loss: 364.574310
train Loss: 113.5367 batch_loss: 207.105972
train Loss: 113.8456 batch_loss: 237.233932
train Loss: 114.3963 batch_loss: 422.907898
train Loss: 114.7908 batch_loss: 302.961365
train Loss: 115.1660 batch_loss: 288.163086
train Loss: 115.6836 batch_loss: 397.522644
train Loss: 116.0696 batch_loss: 296.428253
train Loss: 116.4369 batch_loss: 282.082916
train Loss: 116.7997 batch_loss: 278.653870
train Loss: 117.3828 batch_loss: 447.852142
train Loss: 117.7644 batch_loss: 293.004425
train Loss: 118.0674 batch_loss: 232.714386
train Loss: 118.6566 batch_loss: 452.542603
train Loss: 119.0724 batch_loss: 319.346619
train Loss: 119.5835 batch_loss: 392.513000
train Loss: 119.9811 batch_loss: 305.361328
Loss on the test images: 406.16887 
Epoch 4/299
----------
trainloader ready!
testloader ready!
train Loss: 0.5325 batch_loss: 408.924622
train Loss: 0.9954 batch_loss: 355.532562
train Loss: 1.2915 batch_loss: 227.425583
train Loss: 1.7149 batch_loss: 325.136902
train Loss: 2.2091 batch_loss: 379.532623
train Loss: 2.7093 batch_loss: 384.181122
train Loss: 3.1960 batch_loss: 373.816986
train Loss: 3.4780 batch_loss: 216.548126
train Loss: 3.8166 batch_loss: 260.084991
train Loss: 4.2042 batch_loss: 297.676331
train Loss: 4.5608 batch_loss: 273.857544
train Loss: 4.9073 batch_loss: 266.114075
train Loss: 5.3939 batch_loss: 373.714050
train Loss: 5.7993 batch_loss: 311.280396
train Loss: 6.4347 batch_loss: 488.032806
train Loss: 6.7830 batch_loss: 267.467804
train Loss: 7.1875 batch_loss: 310.636719
train Loss: 7.6569 batch_loss: 360.573700
train Loss: 8.2151 batch_loss: 428.694214
train Loss: 8.6031 batch_loss: 297.925934
train Loss: 8.9965 batch_loss: 302.157715
train Loss: 9.3410 batch_loss: 264.561920
train Loss: 9.9018 batch_loss: 430.705261
train Loss: 10.4259 batch_loss: 402.513611
train Loss: 10.6988 batch_loss: 209.578094
train Loss: 11.1102 batch_loss: 315.947449
train Loss: 11.6394 batch_loss: 406.427887
train Loss: 12.0848 batch_loss: 342.055084
train Loss: 12.5536 batch_loss: 360.093872
train Loss: 13.1112 batch_loss: 428.237701
train Loss: 13.4885 batch_loss: 289.697540
train Loss: 13.9293 batch_loss: 338.593353
train Loss: 14.2367 batch_loss: 236.081558
train Loss: 14.4300 batch_loss: 148.431091
train Loss: 14.7283 batch_loss: 229.088806
train Loss: 15.3018 batch_loss: 440.430023
train Loss: 15.4797 batch_loss: 136.617218
train Loss: 15.8378 batch_loss: 275.088318
train Loss: 16.3764 batch_loss: 413.614716
train Loss: 16.7399 batch_loss: 279.181580
train Loss: 17.4498 batch_loss: 545.173279
train Loss: 17.8583 batch_loss: 313.733398
train Loss: 18.1540 batch_loss: 227.129196
train Loss: 18.6882 batch_loss: 410.257355
train Loss: 19.2332 batch_loss: 418.542114
train Loss: 19.7369 batch_loss: 386.817535
train Loss: 20.1197 batch_loss: 294.016083
train Loss: 20.6534 batch_loss: 409.873077
train Loss: 20.8945 batch_loss: 185.161530
train Loss: 21.4312 batch_loss: 412.216919
train Loss: 21.7893 batch_loss: 274.991211
train Loss: 22.1624 batch_loss: 286.563049
train Loss: 22.7026 batch_loss: 414.853821
train Loss: 23.0923 batch_loss: 299.321472
train Loss: 23.4934 batch_loss: 308.023163
train Loss: 24.0378 batch_loss: 418.093048
train Loss: 24.5707 batch_loss: 409.248444
train Loss: 24.9891 batch_loss: 321.363983
train Loss: 25.3062 batch_loss: 243.549530
train Loss: 25.9965 batch_loss: 530.121216
train Loss: 26.4485 batch_loss: 347.167206
train Loss: 26.7915 batch_loss: 263.427094
train Loss: 27.2074 batch_loss: 319.393707
train Loss: 27.6260 batch_loss: 321.509064
train Loss: 27.8976 batch_loss: 208.549179
train Loss: 28.5086 batch_loss: 469.276855
train Loss: 28.7889 batch_loss: 215.267548
train Loss: 29.0442 batch_loss: 196.058670
train Loss: 29.2557 batch_loss: 162.453262
train Loss: 29.7034 batch_loss: 343.809509
train Loss: 30.2490 batch_loss: 419.028442
train Loss: 30.6248 batch_loss: 288.625977
train Loss: 30.8374 batch_loss: 163.282928
train Loss: 31.3818 batch_loss: 418.049652
train Loss: 31.9128 batch_loss: 407.790710
train Loss: 32.3736 batch_loss: 353.928711
train Loss: 32.7709 batch_loss: 305.131866
train Loss: 33.2083 batch_loss: 335.941956
train Loss: 33.5844 batch_loss: 288.815460
train Loss: 33.7965 batch_loss: 162.923340
train Loss: 34.2140 batch_loss: 320.633850
train Loss: 34.6894 batch_loss: 365.083344
train Loss: 35.3590 batch_loss: 514.261475
train Loss: 35.7104 batch_loss: 269.867493
train Loss: 36.0919 batch_loss: 292.966888
train Loss: 36.5465 batch_loss: 349.164917
train Loss: 36.9369 batch_loss: 299.814453
train Loss: 37.4058 batch_loss: 360.114441
train Loss: 37.8616 batch_loss: 350.041595
train Loss: 38.1773 batch_loss: 242.496643
train Loss: 38.8736 batch_loss: 534.714050
train Loss: 39.1193 batch_loss: 188.693939
train Loss: 39.7094 batch_loss: 453.190735
train Loss: 39.9578 batch_loss: 190.838547
train Loss: 40.4760 batch_loss: 397.945312
train Loss: 40.8990 batch_loss: 324.840179
train Loss: 41.3621 batch_loss: 355.715240
train Loss: 41.7468 batch_loss: 295.413208
train Loss: 42.0985 batch_loss: 270.127228
train Loss: 42.5155 batch_loss: 320.228394
train Loss: 43.0528 batch_loss: 412.683716
train Loss: 43.4791 batch_loss: 327.364197
train Loss: 44.0511 batch_loss: 439.323120
train Loss: 44.5546 batch_loss: 386.662811
train Loss: 45.1536 batch_loss: 460.023102
train Loss: 45.5848 batch_loss: 331.203247
train Loss: 45.8541 batch_loss: 206.810364
train Loss: 46.5332 batch_loss: 521.538818
train Loss: 46.9531 batch_loss: 322.495667
train Loss: 47.1644 batch_loss: 162.283966
train Loss: 47.3633 batch_loss: 152.696487
train Loss: 47.9127 batch_loss: 421.948364
train Loss: 48.2883 batch_loss: 288.477356
train Loss: 48.7318 batch_loss: 340.594666
train Loss: 49.3589 batch_loss: 481.628265
train Loss: 49.6185 batch_loss: 199.348938
train Loss: 50.3951 batch_loss: 596.486206
train Loss: 50.9962 batch_loss: 461.643738
train Loss: 51.4804 batch_loss: 371.867401
train Loss: 51.7020 batch_loss: 170.137360
train Loss: 52.1176 batch_loss: 319.236328
train Loss: 52.6047 batch_loss: 374.053741
train Loss: 52.9999 batch_loss: 303.507935
train Loss: 53.4449 batch_loss: 341.777313
train Loss: 53.8031 batch_loss: 275.115265
train Loss: 54.4468 batch_loss: 494.350403
train Loss: 55.1050 batch_loss: 505.505219
train Loss: 55.5302 batch_loss: 326.559357
train Loss: 55.7457 batch_loss: 165.507858
train Loss: 56.2686 batch_loss: 401.526794
train Loss: 56.7331 batch_loss: 356.795258
train Loss: 56.8454 batch_loss: 86.222366
train Loss: 57.2102 batch_loss: 280.152679
train Loss: 57.6591 batch_loss: 344.791504
train Loss: 58.1276 batch_loss: 359.813416
train Loss: 58.3686 batch_loss: 185.057312
train Loss: 58.5902 batch_loss: 170.229004
train Loss: 59.0974 batch_loss: 389.485229
train Loss: 59.4093 batch_loss: 239.534470
train Loss: 59.7519 batch_loss: 263.091064
train Loss: 60.2862 batch_loss: 410.407806
train Loss: 60.7869 batch_loss: 384.532318
train Loss: 61.3229 batch_loss: 411.613342
train Loss: 61.7277 batch_loss: 310.889008
train Loss: 61.8501 batch_loss: 94.034454
train Loss: 62.2217 batch_loss: 285.374329
train Loss: 62.7132 batch_loss: 377.447632
train Loss: 63.0736 batch_loss: 276.791809
train Loss: 63.3265 batch_loss: 194.242157
train Loss: 63.8782 batch_loss: 423.727661
train Loss: 64.4674 batch_loss: 452.499390
train Loss: 64.9183 batch_loss: 346.267914
train Loss: 65.1677 batch_loss: 191.530365
train Loss: 65.2447 batch_loss: 59.112255
train Loss: 65.4157 batch_loss: 131.350845
train Loss: 65.7861 batch_loss: 284.482727
train Loss: 66.3677 batch_loss: 446.639679
train Loss: 66.8645 batch_loss: 381.553619
train Loss: 67.3373 batch_loss: 363.156708
train Loss: 67.6670 batch_loss: 253.213852
train Loss: 68.0758 batch_loss: 313.906891
train Loss: 68.2931 batch_loss: 166.909729
train Loss: 68.7149 batch_loss: 323.956451
train Loss: 69.1461 batch_loss: 331.137970
train Loss: 69.5054 batch_loss: 275.952850
train Loss: 70.0469 batch_loss: 415.847931
train Loss: 70.6048 batch_loss: 428.493347
train Loss: 70.9464 batch_loss: 262.369995
train Loss: 71.4710 batch_loss: 402.824554
train Loss: 72.0954 batch_loss: 479.548828
train Loss: 72.4956 batch_loss: 307.345184
train Loss: 72.7465 batch_loss: 192.749481
train Loss: 73.2573 batch_loss: 392.268616
train Loss: 73.5803 batch_loss: 248.055893
train Loss: 74.1035 batch_loss: 401.855652
train Loss: 74.8085 batch_loss: 541.438110
train Loss: 75.1949 batch_loss: 296.692780
train Loss: 75.6728 batch_loss: 367.043243
train Loss: 76.1249 batch_loss: 347.261597
train Loss: 76.4061 batch_loss: 215.910736
train Loss: 76.8498 batch_loss: 340.815399
train Loss: 77.2301 batch_loss: 292.043518
train Loss: 77.7381 batch_loss: 390.175964
train Loss: 78.2167 batch_loss: 367.539581
train Loss: 78.5347 batch_loss: 244.186264
train Loss: 78.9973 batch_loss: 355.318848
train Loss: 79.6797 batch_loss: 524.096985
train Loss: 80.0155 batch_loss: 257.885925
train Loss: 80.5186 batch_loss: 386.350861
train Loss: 81.0243 batch_loss: 388.382477
train Loss: 81.1521 batch_loss: 98.133614
train Loss: 81.4633 batch_loss: 239.018295
train Loss: 82.0922 batch_loss: 483.010559
train Loss: 82.6018 batch_loss: 391.347687
train Loss: 83.0421 batch_loss: 338.191833
train Loss: 83.4559 batch_loss: 317.780792
train Loss: 83.8534 batch_loss: 305.238678
train Loss: 84.1109 batch_loss: 197.787811
train Loss: 84.4784 batch_loss: 282.273926
train Loss: 84.6228 batch_loss: 110.894768
train Loss: 84.9504 batch_loss: 251.537369
train Loss: 85.3629 batch_loss: 316.826508
train Loss: 85.7534 batch_loss: 299.943085
train Loss: 86.2035 batch_loss: 345.660492
train Loss: 86.6285 batch_loss: 326.390625
train Loss: 86.7239 batch_loss: 73.228218
train Loss: 87.1577 batch_loss: 333.229950
train Loss: 87.6290 batch_loss: 361.885223
train Loss: 87.9788 batch_loss: 268.674530
train Loss: 88.4282 batch_loss: 345.112091
train Loss: 88.8972 batch_loss: 360.241516
train Loss: 89.3420 batch_loss: 341.558044
train Loss: 89.7704 batch_loss: 329.074707
train Loss: 90.2738 batch_loss: 386.579315
train Loss: 90.6247 batch_loss: 269.507965
train Loss: 91.1109 batch_loss: 373.384186
train Loss: 91.7068 batch_loss: 457.663910
train Loss: 92.1037 batch_loss: 304.781921
train Loss: 92.5699 batch_loss: 358.092896
train Loss: 92.9317 batch_loss: 277.866425
train Loss: 93.1112 batch_loss: 137.841095
train Loss: 93.5426 batch_loss: 331.332611
train Loss: 93.8622 batch_loss: 245.435349
train Loss: 94.3959 batch_loss: 409.889679
train Loss: 94.8117 batch_loss: 319.312103
train Loss: 95.1442 batch_loss: 255.387924
train Loss: 95.5269 batch_loss: 293.910034
train Loss: 95.8524 batch_loss: 249.958984
train Loss: 96.2844 batch_loss: 331.782990
train Loss: 96.3972 batch_loss: 86.659698
train Loss: 96.8842 batch_loss: 374.008514
train Loss: 97.2181 batch_loss: 256.392029
train Loss: 97.7955 batch_loss: 443.437103
train Loss: 98.1302 batch_loss: 257.105316
train Loss: 98.4585 batch_loss: 252.097137
train Loss: 98.9216 batch_loss: 355.672089
train Loss: 99.2696 batch_loss: 267.243988
train Loss: 99.9769 batch_loss: 543.218384
train Loss: 100.2955 batch_loss: 244.653580
train Loss: 100.5429 batch_loss: 190.052963
train Loss: 100.9959 batch_loss: 347.914673
train Loss: 101.2508 batch_loss: 195.726913
train Loss: 101.6766 batch_loss: 327.007660
train Loss: 102.2137 batch_loss: 412.537506
train Loss: 102.4928 batch_loss: 214.332352
train Loss: 102.7976 batch_loss: 234.098724
train Loss: 103.1616 batch_loss: 279.524017
train Loss: 103.5278 batch_loss: 281.246765
train Loss: 103.9502 batch_loss: 324.433441
train Loss: 104.2144 batch_loss: 202.839874
train Loss: 104.7208 batch_loss: 388.922791
train Loss: 105.2563 batch_loss: 411.292389
train Loss: 105.7569 batch_loss: 384.475372
train Loss: 106.1406 batch_loss: 294.644958
train Loss: 106.4002 batch_loss: 199.412201
train Loss: 106.9258 batch_loss: 403.602020
Loss on the test images: 379.95791 
saving wiehgts...
Epoch 5/299
----------
trainloader ready!
testloader ready!
train Loss: 0.2815 batch_loss: 216.198761
train Loss: 0.6605 batch_loss: 291.049683
train Loss: 1.0435 batch_loss: 294.187347
train Loss: 1.5118 batch_loss: 359.661102
train Loss: 1.7600 batch_loss: 190.585526
train Loss: 2.1653 batch_loss: 311.233398
train Loss: 2.6205 batch_loss: 349.606842
train Loss: 3.0038 batch_loss: 294.430206
train Loss: 3.4172 batch_loss: 317.467102
train Loss: 3.9036 batch_loss: 373.525269
train Loss: 4.2336 batch_loss: 253.460800
train Loss: 4.4467 batch_loss: 163.631592
train Loss: 4.9173 batch_loss: 361.422729
train Loss: 5.3250 batch_loss: 313.114075
train Loss: 5.5205 batch_loss: 150.138931
train Loss: 5.8675 batch_loss: 266.551147
train Loss: 6.1588 batch_loss: 223.710968
train Loss: 6.5410 batch_loss: 293.487854
train Loss: 7.2468 batch_loss: 542.077576
train Loss: 7.6502 batch_loss: 309.788269
train Loss: 8.2384 batch_loss: 451.796753
train Loss: 8.5753 batch_loss: 258.728394
train Loss: 8.7983 batch_loss: 171.210526
train Loss: 9.3578 batch_loss: 429.694977
train Loss: 9.9155 batch_loss: 428.319977
train Loss: 10.3702 batch_loss: 349.260681
train Loss: 10.8786 batch_loss: 390.396362
train Loss: 11.4573 batch_loss: 444.440552
train Loss: 11.5523 batch_loss: 72.993561
train Loss: 11.9774 batch_loss: 326.463104
train Loss: 12.5335 batch_loss: 427.078400
train Loss: 12.7455 batch_loss: 162.828552
train Loss: 13.1297 batch_loss: 295.102356
train Loss: 13.6331 batch_loss: 386.566711
train Loss: 13.8500 batch_loss: 166.568909
train Loss: 14.2360 batch_loss: 296.433014
train Loss: 14.6773 batch_loss: 338.947418
train Loss: 14.9947 batch_loss: 243.745209
train Loss: 15.2175 batch_loss: 171.162079
train Loss: 15.4911 batch_loss: 210.075302
train Loss: 15.8804 batch_loss: 299.033325
train Loss: 16.3839 batch_loss: 386.645966
train Loss: 16.5811 batch_loss: 151.442322
train Loss: 17.0840 batch_loss: 386.260223
train Loss: 17.4907 batch_loss: 312.319946
train Loss: 17.6920 batch_loss: 154.634918
train Loss: 18.0666 batch_loss: 287.670807
train Loss: 18.5609 batch_loss: 379.621124
train Loss: 18.9550 batch_loss: 302.631287
train Loss: 19.3726 batch_loss: 320.752747
train Loss: 19.8180 batch_loss: 342.071472
train Loss: 20.4008 batch_loss: 447.589722
train Loss: 20.7925 batch_loss: 300.806519
train Loss: 21.2126 batch_loss: 322.683777
train Loss: 21.7668 batch_loss: 425.607300
train Loss: 22.2846 batch_loss: 397.681244
train Loss: 22.6679 batch_loss: 294.353455
train Loss: 23.0659 batch_loss: 305.630981
train Loss: 23.4114 batch_loss: 265.357819
train Loss: 23.6969 batch_loss: 219.287704
train Loss: 24.2341 batch_loss: 412.559235
train Loss: 24.6286 batch_loss: 303.017883
train Loss: 25.2235 batch_loss: 456.865845
train Loss: 25.7548 batch_loss: 408.032379
train Loss: 26.2318 batch_loss: 366.288422
train Loss: 26.6422 batch_loss: 315.222076
train Loss: 27.0185 batch_loss: 288.996246
train Loss: 27.3230 batch_loss: 233.871307
train Loss: 27.8255 batch_loss: 385.928131
train Loss: 28.1376 batch_loss: 239.694824
train Loss: 28.6935 batch_loss: 426.898560
train Loss: 29.1034 batch_loss: 314.831757
train Loss: 29.3495 batch_loss: 188.984467
train Loss: 29.8230 batch_loss: 363.619629
train Loss: 30.3797 batch_loss: 427.607483
train Loss: 30.6941 batch_loss: 241.411072
train Loss: 30.9811 batch_loss: 220.427017
train Loss: 31.3574 batch_loss: 289.013489
train Loss: 31.8302 batch_loss: 363.068054
train Loss: 32.3832 batch_loss: 424.718353
train Loss: 32.8043 batch_loss: 323.405609
train Loss: 33.2521 batch_loss: 343.934967
train Loss: 33.8218 batch_loss: 437.514648
train Loss: 34.1627 batch_loss: 261.840912
train Loss: 34.5101 batch_loss: 266.756989
train Loss: 34.8489 batch_loss: 260.188293
train Loss: 35.3049 batch_loss: 350.223267
train Loss: 35.4592 batch_loss: 118.510124
train Loss: 36.0136 batch_loss: 425.758026
train Loss: 36.2126 batch_loss: 152.851990
train Loss: 36.4174 batch_loss: 157.284241
train Loss: 36.8505 batch_loss: 332.628479
train Loss: 37.3240 batch_loss: 363.628967
train Loss: 37.6341 batch_loss: 238.178085
train Loss: 38.2717 batch_loss: 489.646820
train Loss: 38.6389 batch_loss: 282.037750
train Loss: 39.0823 batch_loss: 340.528107
train Loss: 39.3261 batch_loss: 187.229218
train Loss: 39.6386 batch_loss: 240.048996
train Loss: 40.0857 batch_loss: 343.345520
train Loss: 40.4758 batch_loss: 299.569946
train Loss: 40.8632 batch_loss: 297.522308
train Loss: 41.1036 batch_loss: 184.676941
train Loss: 41.3258 batch_loss: 170.626160
train Loss: 41.7258 batch_loss: 307.186401
train Loss: 42.4125 batch_loss: 527.414917
train Loss: 42.9419 batch_loss: 406.523834
train Loss: 43.2554 batch_loss: 240.841217
train Loss: 43.4575 batch_loss: 155.208786
train Loss: 43.8304 batch_loss: 286.351837
train Loss: 44.2988 batch_loss: 359.733429
train Loss: 44.4854 batch_loss: 143.307556
train Loss: 44.9974 batch_loss: 393.233856
train Loss: 45.3768 batch_loss: 291.384613
train Loss: 45.5862 batch_loss: 160.788406
train Loss: 46.0700 batch_loss: 371.594940
train Loss: 46.3966 batch_loss: 250.763779
train Loss: 46.7126 batch_loss: 242.735580
train Loss: 47.1208 batch_loss: 313.465179
train Loss: 47.4610 batch_loss: 261.297821
train Loss: 47.8126 batch_loss: 270.062469
train Loss: 48.1194 batch_loss: 235.566788
train Loss: 48.4598 batch_loss: 261.446564
train Loss: 48.7892 batch_loss: 253.007462
train Loss: 49.0860 batch_loss: 227.918228
train Loss: 49.5179 batch_loss: 331.718628
train Loss: 49.8297 batch_loss: 239.438477
train Loss: 50.2750 batch_loss: 341.979401
train Loss: 50.9244 batch_loss: 498.784119
train Loss: 51.3821 batch_loss: 351.468475
train Loss: 52.0144 batch_loss: 485.619476
train Loss: 52.2931 batch_loss: 214.014099
train Loss: 52.8356 batch_loss: 416.666412
train Loss: 53.3566 batch_loss: 400.167175
train Loss: 53.6813 batch_loss: 249.314560
train Loss: 54.3996 batch_loss: 551.707886
train Loss: 54.8554 batch_loss: 349.986053
train Loss: 55.3150 batch_loss: 353.011383
train Loss: 55.8578 batch_loss: 416.833130
train Loss: 56.2797 batch_loss: 324.069672
train Loss: 56.6111 batch_loss: 254.467361
train Loss: 57.2648 batch_loss: 502.085632
train Loss: 57.6514 batch_loss: 296.857574
train Loss: 58.1329 batch_loss: 369.855469
train Loss: 58.5238 batch_loss: 300.213379
train Loss: 59.0595 batch_loss: 411.364716
train Loss: 59.5102 batch_loss: 346.140961
train Loss: 59.9397 batch_loss: 329.886261
train Loss: 60.4371 batch_loss: 382.017609
train Loss: 60.6882 batch_loss: 192.808258
train Loss: 61.0756 batch_loss: 297.507629
train Loss: 61.4220 batch_loss: 266.065277
train Loss: 61.9505 batch_loss: 405.917023
train Loss: 62.4984 batch_loss: 420.723053
train Loss: 62.8050 batch_loss: 235.535645
train Loss: 63.3983 batch_loss: 455.608002
train Loss: 63.6688 batch_loss: 207.766129
train Loss: 64.1010 batch_loss: 331.906433
train Loss: 64.6291 batch_loss: 405.561584
train Loss: 65.1254 batch_loss: 381.152405
train Loss: 65.4134 batch_loss: 221.202850
train Loss: 65.7540 batch_loss: 261.626099
train Loss: 66.1095 batch_loss: 273.008606
train Loss: 66.5855 batch_loss: 365.550598
train Loss: 67.0897 batch_loss: 387.264130
train Loss: 67.6402 batch_loss: 422.760559
train Loss: 67.9044 batch_loss: 202.892990
train Loss: 68.0772 batch_loss: 132.730011
train Loss: 68.2988 batch_loss: 170.210388
train Loss: 68.5831 batch_loss: 218.307129
train Loss: 68.9892 batch_loss: 311.902039
train Loss: 69.4204 batch_loss: 331.120697
train Loss: 69.8618 batch_loss: 339.049255
train Loss: 70.2074 batch_loss: 265.364136
train Loss: 70.5008 batch_loss: 225.388870
train Loss: 70.9557 batch_loss: 349.363159
train Loss: 71.1934 batch_loss: 182.481934
train Loss: 71.5573 batch_loss: 279.516937
train Loss: 71.9743 batch_loss: 320.288177
train Loss: 72.4741 batch_loss: 383.848297
train Loss: 72.7417 batch_loss: 205.485840
train Loss: 73.1651 batch_loss: 325.200287
train Loss: 73.7133 batch_loss: 420.992371
train Loss: 74.2242 batch_loss: 392.356049
train Loss: 74.5635 batch_loss: 260.621460
train Loss: 74.9057 batch_loss: 262.751740
train Loss: 75.2982 batch_loss: 301.447327
train Loss: 76.0888 batch_loss: 607.229309
train Loss: 76.5072 batch_loss: 321.274109
train Loss: 76.7883 batch_loss: 215.874039
train Loss: 77.2486 batch_loss: 353.572571
train Loss: 77.6030 batch_loss: 272.186157
train Loss: 78.1077 batch_loss: 387.574615
train Loss: 78.4353 batch_loss: 251.619370
train Loss: 78.8245 batch_loss: 298.917419
train Loss: 79.1355 batch_loss: 238.790207
train Loss: 79.5043 batch_loss: 283.226135
train Loss: 79.7901 batch_loss: 219.502518
train Loss: 80.1845 batch_loss: 302.948914
train Loss: 80.8152 batch_loss: 484.352814
train Loss: 81.3638 batch_loss: 421.309631
train Loss: 81.7467 batch_loss: 294.076996
train Loss: 82.2037 batch_loss: 351.020111
train Loss: 82.4162 batch_loss: 163.196289
train Loss: 82.6485 batch_loss: 178.342636
train Loss: 82.8904 batch_loss: 185.800690
train Loss: 83.3177 batch_loss: 328.167450
train Loss: 83.7367 batch_loss: 321.794006
train Loss: 84.0724 batch_loss: 257.830627
train Loss: 84.3389 batch_loss: 204.638763
train Loss: 84.4451 batch_loss: 81.564796
train Loss: 84.8766 batch_loss: 331.430603
train Loss: 85.3368 batch_loss: 353.391022
train Loss: 85.8725 batch_loss: 411.474426
train Loss: 86.1676 batch_loss: 226.605927
train Loss: 86.6207 batch_loss: 347.978851
train Loss: 87.1168 batch_loss: 381.030090
train Loss: 87.3495 batch_loss: 178.701370
train Loss: 87.7813 batch_loss: 331.644653
train Loss: 88.3414 batch_loss: 430.105286
train Loss: 88.7383 batch_loss: 304.877350
train Loss: 89.0116 batch_loss: 209.827682
train Loss: 89.3732 batch_loss: 277.745972
train Loss: 89.5228 batch_loss: 114.919182
train Loss: 89.9108 batch_loss: 297.913544
train Loss: 90.3431 batch_loss: 332.035614
train Loss: 90.7117 batch_loss: 283.117279
train Loss: 91.1960 batch_loss: 371.941681
train Loss: 91.7418 batch_loss: 419.183929
train Loss: 92.0123 batch_loss: 207.703522
train Loss: 92.3794 batch_loss: 281.964417
train Loss: 92.6948 batch_loss: 242.187454
train Loss: 92.9256 batch_loss: 177.254425
train Loss: 93.2697 batch_loss: 264.279022
train Loss: 93.6958 batch_loss: 327.231018
train Loss: 94.1734 batch_loss: 366.829285
train Loss: 94.4076 batch_loss: 179.835983
train Loss: 94.9877 batch_loss: 445.550720
train Loss: 95.5949 batch_loss: 466.305511
train Loss: 96.0999 batch_loss: 387.859894
train Loss: 96.5578 batch_loss: 351.652405
train Loss: 96.9378 batch_loss: 291.840424
train Loss: 97.3563 batch_loss: 321.445435
train Loss: 97.7459 batch_loss: 299.194702
train Loss: 98.2032 batch_loss: 351.186859
train Loss: 98.7935 batch_loss: 453.374329
^[[A^[[A^[[A^[[Atrain Loss: 99.1487 batch_loss: 272.744263
train Loss: 99.5748 batch_loss: 327.268219
train Loss: 99.9452 batch_loss: 284.490051
train Loss: 100.3150 batch_loss: 284.010468
train Loss: 100.8200 batch_loss: 387.795685
train Loss: 101.0270 batch_loss: 159.028839
train Loss: 101.3468 batch_loss: 245.588882
train Loss: 101.6761 batch_loss: 252.920868
train Loss: 102.0941 batch_loss: 321.019318
train Loss: 102.3023 batch_loss: 159.894058
Loss on the test images: 390.34689 
Epoch 6/299
----------
trainloader ready!
testloader ready!
train Loss: 0.3022 batch_loss: 232.125275
train Loss: 0.7741 batch_loss: 362.399963
train Loss: 1.2374 batch_loss: 355.829376
train Loss: 1.4929 batch_loss: 196.190521
train Loss: 1.8323 batch_loss: 260.635254
train Loss: 2.1021 batch_loss: 207.210999
train Loss: 2.6473 batch_loss: 418.770630
train Loss: 2.8620 batch_loss: 164.875061
train Loss: 3.3896 batch_loss: 405.188934
train Loss: 3.8404 batch_loss: 346.196930
train Loss: 4.2315 batch_loss: 300.346558
train Loss: 4.7123 batch_loss: 369.277985
train Loss: 4.9860 batch_loss: 210.182938
train Loss: 5.3396 batch_loss: 271.601532
train Loss: 5.7078 batch_loss: 282.768036
train Loss: 6.1511 batch_loss: 340.443481
train Loss: 6.6477 batch_loss: 381.374512
train Loss: 7.0908 batch_loss: 340.330902
train Loss: 7.4023 batch_loss: 239.241730
train Loss: 7.6840 batch_loss: 216.344772
train Loss: 8.1065 batch_loss: 324.482086
train Loss: 8.4251 batch_loss: 244.674301
train Loss: 8.8663 batch_loss: 338.847717
train Loss: 9.3413 batch_loss: 364.789734
train Loss: 9.6580 batch_loss: 243.187988
train Loss: 9.9072 batch_loss: 191.427338
train Loss: 10.2402 batch_loss: 255.693527
train Loss: 10.8582 batch_loss: 474.638275
train Loss: 11.0849 batch_loss: 174.162247
train Loss: 11.5200 batch_loss: 334.110535
train Loss: 12.0465 batch_loss: 404.360626
train Loss: 12.5041 batch_loss: 351.403046
train Loss: 13.0405 batch_loss: 411.969452
train Loss: 13.3068 batch_loss: 204.575928
train Loss: 13.7904 batch_loss: 371.341248
train Loss: 14.1722 batch_loss: 293.216339
train Loss: 14.6361 batch_loss: 356.317780
train Loss: 15.1349 batch_loss: 383.054718
train Loss: 15.5185 batch_loss: 294.621246
train Loss: 16.0435 batch_loss: 403.228973
train Loss: 16.4612 batch_loss: 320.728485
train Loss: 16.8732 batch_loss: 316.450104
train Loss: 17.4409 batch_loss: 435.969086
train Loss: 17.9487 batch_loss: 389.983215
train Loss: 18.2866 batch_loss: 259.518799
train Loss: 18.6515 batch_loss: 280.281586
train Loss: 19.0358 batch_loss: 295.103973
train Loss: 19.4472 batch_loss: 316.012970
train Loss: 19.8707 batch_loss: 325.232819
train Loss: 20.3304 batch_loss: 352.989380
train Loss: 20.9101 batch_loss: 445.264496
train Loss: 21.4342 batch_loss: 402.485931
train Loss: 21.7320 batch_loss: 228.682938
train Loss: 21.9961 batch_loss: 202.883408
train Loss: 22.3261 batch_loss: 253.425827
train Loss: 22.5347 batch_loss: 160.204697
train Loss: 22.9169 batch_loss: 293.522003
train Loss: 23.2589 batch_loss: 262.630676
train Loss: 23.7945 batch_loss: 411.367065
train Loss: 24.2028 batch_loss: 313.568848
train Loss: 24.5047 batch_loss: 231.884766
train Loss: 24.9011 batch_loss: 304.426666
train Loss: 25.2550 batch_loss: 271.788361
train Loss: 25.3645 batch_loss: 84.089348
train Loss: 25.7374 batch_loss: 286.424866
train Loss: 26.1023 batch_loss: 280.209808
train Loss: 26.3028 batch_loss: 154.001755
train Loss: 26.5234 batch_loss: 169.402496
train Loss: 26.7613 batch_loss: 182.677826
train Loss: 27.4270 batch_loss: 511.296936
train Loss: 27.8446 batch_loss: 320.674103
train Loss: 28.1802 batch_loss: 257.737366
train Loss: 28.9281 batch_loss: 574.425598
train Loss: 29.1868 batch_loss: 198.659698
train Loss: 29.7603 batch_loss: 440.447205
train Loss: 29.9624 batch_loss: 155.205719
train Loss: 30.3410 batch_loss: 290.789062
train Loss: 30.7128 batch_loss: 285.544281
train Loss: 31.2129 batch_loss: 384.080444
train Loss: 31.6702 batch_loss: 351.238342
train Loss: 32.0722 batch_loss: 308.681671
train Loss: 32.3322 batch_loss: 199.666245
train Loss: 32.6902 batch_loss: 274.969452
train Loss: 32.9861 batch_loss: 227.293442
train Loss: 33.3663 batch_loss: 291.977722
train Loss: 33.7547 batch_loss: 298.266266
train Loss: 34.1386 batch_loss: 294.857452
train Loss: 34.4008 batch_loss: 201.323792
train Loss: 34.6517 batch_loss: 192.682144
train Loss: 35.2292 batch_loss: 443.535278
train Loss: 35.5640 batch_loss: 257.155792
train Loss: 36.0459 batch_loss: 370.091400
train Loss: 36.4236 batch_loss: 290.079315
train Loss: 36.7489 batch_loss: 249.833328
train Loss: 37.2401 batch_loss: 377.271545
train Loss: 37.6189 batch_loss: 290.854218
train Loss: 38.0559 batch_loss: 335.667511
train Loss: 38.4514 batch_loss: 303.731506
train Loss: 38.9185 batch_loss: 358.695496
train Loss: 39.4123 batch_loss: 379.270966
train Loss: 39.9623 batch_loss: 422.407990
train Loss: 40.3438 batch_loss: 292.972717
train Loss: 40.5307 batch_loss: 143.544174
train Loss: 40.7471 batch_loss: 166.212616
train Loss: 41.1808 batch_loss: 333.045776
train Loss: 41.3884 batch_loss: 159.431061
train Loss: 41.6476 batch_loss: 199.083145
train Loss: 42.1237 batch_loss: 365.639221
train Loss: 42.7120 batch_loss: 451.840637
train Loss: 42.9150 batch_loss: 155.887207
train Loss: 43.3218 batch_loss: 312.439362
train Loss: 43.5973 batch_loss: 211.583023
train Loss: 44.1696 batch_loss: 439.516876
train Loss: 44.5213 batch_loss: 270.099426
train Loss: 44.9494 batch_loss: 328.816132
train Loss: 45.2873 batch_loss: 259.475220
train Loss: 45.6171 batch_loss: 253.315887
train Loss: 46.2082 batch_loss: 453.897339
train Loss: 46.6469 batch_loss: 336.937439
train Loss: 47.0993 batch_loss: 347.457001
train Loss: 47.3877 batch_loss: 221.526825
train Loss: 48.0292 batch_loss: 492.605774
train Loss: 48.3108 batch_loss: 216.277802
train Loss: 48.7451 batch_loss: 333.593872
train Loss: 49.0376 batch_loss: 224.622360
train Loss: 49.2484 batch_loss: 161.858612
train Loss: 49.6468 batch_loss: 306.037537
train Loss: 50.0201 batch_loss: 286.653442
train Loss: 50.2143 batch_loss: 149.112961
train Loss: 50.6055 batch_loss: 300.504211
train Loss: 50.9175 batch_loss: 239.575165
train Loss: 51.3368 batch_loss: 322.065765
train Loss: 51.6289 batch_loss: 224.299637
train Loss: 52.0203 batch_loss: 300.573242
train Loss: 52.5158 batch_loss: 380.597961
train Loss: 52.8511 batch_loss: 257.509399
train Loss: 53.1434 batch_loss: 224.430206
train Loss: 53.7137 batch_loss: 438.014679
train Loss: 54.0992 batch_loss: 296.069275
train Loss: 54.4738 batch_loss: 287.678009
train Loss: 54.6994 batch_loss: 173.298096
train Loss: 55.3852 batch_loss: 526.687866
train Loss: 55.6159 batch_loss: 177.187759
train Loss: 55.9246 batch_loss: 237.023697
train Loss: 56.3519 batch_loss: 328.181427
train Loss: 56.6667 batch_loss: 241.776138
train Loss: 56.9346 batch_loss: 205.733398
train Loss: 57.4094 batch_loss: 364.696960
train Loss: 57.6485 batch_loss: 183.635422
train Loss: 57.8162 batch_loss: 128.761139
train Loss: 58.3265 batch_loss: 391.934967
train Loss: 58.5276 batch_loss: 154.438919
train Loss: 59.0086 batch_loss: 369.349731
train Loss: 59.3782 batch_loss: 283.900848
train Loss: 59.7862 batch_loss: 313.368286
train Loss: 60.2310 batch_loss: 341.581146
train Loss: 60.5311 batch_loss: 230.447281
train Loss: 60.9662 batch_loss: 334.195770
train Loss: 61.4756 batch_loss: 391.201965
train Loss: 61.7466 batch_loss: 208.125565
train Loss: 62.3507 batch_loss: 463.968903
train Loss: 62.4393 batch_loss: 68.024666
train Loss: 62.8999 batch_loss: 353.708588
train Loss: 63.4169 batch_loss: 397.066681
train Loss: 63.9134 batch_loss: 381.360931
train Loss: 64.4205 batch_loss: 389.412170
train Loss: 64.8176 batch_loss: 304.976105
train Loss: 65.3996 batch_loss: 446.989899
train Loss: 65.5038 batch_loss: 80.056595
train Loss: 65.8117 batch_loss: 236.446793
train Loss: 66.1707 batch_loss: 275.707825
train Loss: 66.5716 batch_loss: 307.853455
train Loss: 67.2007 batch_loss: 483.191528
train Loss: 67.6021 batch_loss: 308.232239
train Loss: 67.9275 batch_loss: 249.914703
train Loss: 68.3385 batch_loss: 315.638794
train Loss: 68.7285 batch_loss: 299.553406
train Loss: 68.9352 batch_loss: 158.724808
train Loss: 69.3847 batch_loss: 345.201447
train Loss: 69.9957 batch_loss: 469.254761
train Loss: 70.0640 batch_loss: 52.504143
train Loss: 70.2801 batch_loss: 165.905930
train Loss: 70.4526 batch_loss: 132.502228
train Loss: 70.8205 batch_loss: 282.525391
train Loss: 71.2530 batch_loss: 332.201447
train Loss: 71.5767 batch_loss: 248.593994
train Loss: 71.9485 batch_loss: 285.571228
train Loss: 72.4232 batch_loss: 364.564453
train Loss: 72.8446 batch_loss: 323.634125
train Loss: 73.3158 batch_loss: 361.881561
train Loss: 73.8057 batch_loss: 376.222870
^[[A^[[A^[[A^[[A^[[B^[[B^[[B^[[Btrain Loss: 74.1873 batch_loss: 293.096558
train Loss: 74.4898 batch_loss: 232.262680
train Loss: 74.8974 batch_loss: 313.028778
train Loss: 75.1865 batch_loss: 222.046448
train Loss: 75.4013 batch_loss: 164.985443
train Loss: 75.7352 batch_loss: 256.415222
train Loss: 76.0510 batch_loss: 242.582855
train Loss: 76.4104 batch_loss: 275.964325
train Loss: 76.9358 batch_loss: 403.497467
train Loss: 77.4969 batch_loss: 430.965485
train Loss: 78.0788 batch_loss: 446.908020
train Loss: 78.4823 batch_loss: 309.893250
train Loss: 78.8043 batch_loss: 247.290100
train Loss: 79.4011 batch_loss: 458.325317
train Loss: 79.9432 batch_loss: 416.344513
train Loss: 80.3698 batch_loss: 327.634430
train Loss: 80.9180 batch_loss: 421.023041
train Loss: 81.3403 batch_loss: 324.294342
train Loss: 81.8626 batch_loss: 401.163788
train Loss: 82.0582 batch_loss: 150.225983
train Loss: 82.5804 batch_loss: 400.979889
train Loss: 83.0085 batch_loss: 328.795746
train Loss: 83.3211 batch_loss: 240.113205
train Loss: 83.6855 batch_loss: 279.824158
train Loss: 84.2330 batch_loss: 420.468536
train Loss: 84.5863 batch_loss: 271.367523
train Loss: 84.8363 batch_loss: 192.025452
train Loss: 85.0294 batch_loss: 148.262833
train Loss: 85.5905 batch_loss: 430.920959
train Loss: 85.9681 batch_loss: 289.990784
train Loss: 86.4242 batch_loss: 350.317444
train Loss: 86.9036 batch_loss: 368.131439
train Loss: 87.4128 batch_loss: 391.095886
train Loss: 87.8327 batch_loss: 322.518829
train Loss: 88.1204 batch_loss: 220.942566
train Loss: 88.6457 batch_loss: 403.423370
train Loss: 88.9063 batch_loss: 200.164490
train Loss: 89.4966 batch_loss: 453.341736
train Loss: 89.7225 batch_loss: 173.465790
train Loss: 90.1950 batch_loss: 362.892395
train Loss: 90.6680 batch_loss: 363.219910
train Loss: 91.2897 batch_loss: 477.512207
train Loss: 91.8166 batch_loss: 404.653381
train Loss: 92.1166 batch_loss: 230.376953
train Loss: 92.4551 batch_loss: 260.009613
train Loss: 92.8095 batch_loss: 272.173279
train Loss: 93.2675 batch_loss: 351.756226
train Loss: 93.7967 batch_loss: 406.355133
train Loss: 94.1513 batch_loss: 272.335632
train Loss: 94.6709 batch_loss: 399.104889
train Loss: 95.0498 batch_loss: 290.987701
train Loss: 95.5829 batch_loss: 409.388092
train Loss: 95.9192 batch_loss: 258.278046
train Loss: 96.2391 batch_loss: 245.683395
train Loss: 96.6472 batch_loss: 313.459320
train Loss: 97.1252 batch_loss: 367.096497
train Loss: 97.5122 batch_loss: 297.197266
train Loss: 97.8358 batch_loss: 248.560379
train Loss: 98.0193 batch_loss: 140.868195
train Loss: 98.3809 batch_loss: 277.757904
train Loss: 98.7492 batch_loss: 282.840332
train Loss: 99.3064 batch_loss: 427.908142
train Loss: 99.6327 batch_loss: 250.632233
train Loss: 99.8747 batch_loss: 185.871231
train Loss: 100.2953 batch_loss: 323.013336
Loss on the test images: 379.92725 
Epoch 7/299
----------
trainloader ready!
testloader ready!
train Loss: 0.4804 batch_loss: 368.976044
train Loss: 0.8436 batch_loss: 278.914703
train Loss: 1.1593 batch_loss: 242.488419
train Loss: 1.3849 batch_loss: 173.201126
train Loss: 1.7894 batch_loss: 310.645966
train Loss: 2.0488 batch_loss: 199.257355
train Loss: 2.3803 batch_loss: 254.598618
train Loss: 2.6203 batch_loss: 184.319366
train Loss: 2.9797 batch_loss: 276.045349
train Loss: 3.2814 batch_loss: 231.678253
train Loss: 3.6193 batch_loss: 259.526031
train Loss: 3.9748 batch_loss: 272.975128
train Loss: 4.3135 batch_loss: 260.149750
train Loss: 4.8161 batch_loss: 386.008789
train Loss: 5.1388 batch_loss: 247.794601
train Loss: 5.6180 batch_loss: 368.078949
train Loss: 5.8153 batch_loss: 151.504639
train Loss: 6.1348 batch_loss: 245.396835
train Loss: 6.5717 batch_loss: 335.527710
train Loss: 7.0309 batch_loss: 352.638794
train Loss: 7.4889 batch_loss: 351.717590
train Loss: 8.0856 batch_loss: 458.292145
train Loss: 8.5139 batch_loss: 328.926361
train Loss: 9.1093 batch_loss: 457.316833
train Loss: 9.6634 batch_loss: 425.518585
train Loss: 10.1055 batch_loss: 339.532623
train Loss: 10.4078 batch_loss: 232.175629
train Loss: 10.7842 batch_loss: 289.024231
train Loss: 11.0575 batch_loss: 209.954941
train Loss: 11.4113 batch_loss: 271.680145
train Loss: 11.7981 batch_loss: 297.060425
train Loss: 12.0835 batch_loss: 219.218948
train Loss: 12.3032 batch_loss: 168.684525
train Loss: 12.8278 batch_loss: 402.893158
train Loss: 13.1660 batch_loss: 259.786285
train Loss: 13.4866 batch_loss: 246.179703
train Loss: 13.8649 batch_loss: 290.545380
train Loss: 13.9605 batch_loss: 73.451485
train Loss: 14.2734 batch_loss: 240.303574
train Loss: 14.8908 batch_loss: 474.119781
train Loss: 15.2253 batch_loss: 256.946075
train Loss: 15.7499 batch_loss: 402.881622
train Loss: 16.2422 batch_loss: 378.082550
train Loss: 16.9063 batch_loss: 510.007538
train Loss: 17.1021 batch_loss: 150.387253
train Loss: 17.4961 batch_loss: 302.560455
train Loss: 17.8537 batch_loss: 274.636169
train Loss: 18.0574 batch_loss: 156.470779
train Loss: 18.4347 batch_loss: 289.760223
train Loss: 18.8883 batch_loss: 348.407928
train Loss: 19.2167 batch_loss: 252.192688
train Loss: 19.5554 batch_loss: 260.080444
train Loss: 19.8012 batch_loss: 188.820175
train Loss: 20.3380 batch_loss: 412.220520
train Loss: 20.7758 batch_loss: 336.246216
train Loss: 21.1436 batch_loss: 282.464630
train Loss: 21.5742 batch_loss: 330.684448
train Loss: 22.1015 batch_loss: 405.019165
train Loss: 22.3916 batch_loss: 222.744965
train Loss: 22.8038 batch_loss: 316.622284
train Loss: 23.2533 batch_loss: 345.179474
train Loss: 23.7074 batch_loss: 348.757935
train Loss: 24.0396 batch_loss: 255.121872
train Loss: 24.3940 batch_loss: 272.189850
train Loss: 24.8745 batch_loss: 369.055298
train Loss: 25.2099 batch_loss: 257.580536
train Loss: 25.7766 batch_loss: 435.231476
train Loss: 26.2064 batch_loss: 330.060486
train Loss: 26.7533 batch_loss: 420.050140
train Loss: 27.1285 batch_loss: 288.103546
train Loss: 27.3511 batch_loss: 170.954758
train Loss: 27.5644 batch_loss: 163.795242
train Loss: 27.8883 batch_loss: 248.766769
train Loss: 28.3874 batch_loss: 383.321686
train Loss: 28.9178 batch_loss: 407.392456
train Loss: 29.3784 batch_loss: 353.722778
train Loss: 29.8462 batch_loss: 359.260742
train Loss: 30.3115 batch_loss: 357.318359
train Loss: 30.6589 batch_loss: 266.835632
train Loss: 30.8512 batch_loss: 147.641434
train Loss: 31.2806 batch_loss: 329.796265
train Loss: 31.5322 batch_loss: 193.281311
train Loss: 31.7767 batch_loss: 187.735947
train Loss: 32.2520 batch_loss: 365.027679
train Loss: 32.6949 batch_loss: 340.129089
train Loss: 33.0565 batch_loss: 277.736176
train Loss: 33.4493 batch_loss: 301.649200
train Loss: 33.7777 batch_loss: 252.210892
train Loss: 34.2423 batch_loss: 356.848297
train Loss: 34.7256 batch_loss: 371.156311
train Loss: 34.9794 batch_loss: 194.935074
train Loss: 35.5176 batch_loss: 413.349091
train Loss: 35.7103 batch_loss: 147.991013
train Loss: 36.1097 batch_loss: 306.744659
train Loss: 36.4122 batch_loss: 232.290726
train Loss: 36.8372 batch_loss: 326.370148
train Loss: 37.2717 batch_loss: 333.732422
train Loss: 37.5520 batch_loss: 215.266174
train Loss: 37.8554 batch_loss: 233.026367
train Loss: 38.3693 batch_loss: 394.641785
train Loss: 38.8549 batch_loss: 372.943542
train Loss: 39.2443 batch_loss: 299.086273
train Loss: 39.7877 batch_loss: 417.288269
train Loss: 40.1759 batch_loss: 298.178436
train Loss: 40.6447 batch_loss: 360.030731
train Loss: 40.9224 batch_loss: 213.294662
train Loss: 41.4183 batch_loss: 380.862579
train Loss: 42.0025 batch_loss: 448.607574
train Loss: 42.3295 batch_loss: 251.130768
train Loss: 42.7600 batch_loss: 330.671234
train Loss: 43.0141 batch_loss: 195.097168
train Loss: 43.3415 batch_loss: 251.444962
train Loss: 43.8388 batch_loss: 381.921417
train Loss: 44.2819 batch_loss: 340.337891
train Loss: 44.5098 batch_loss: 175.031342
train Loss: 44.9243 batch_loss: 318.347534
train Loss: 45.3816 batch_loss: 351.174103
train Loss: 45.7892 batch_loss: 313.090942
train Loss: 46.1472 batch_loss: 274.939117
train Loss: 46.5342 batch_loss: 297.220490
train Loss: 46.9726 batch_loss: 336.666992
train Loss: 47.2794 batch_loss: 235.588211
train Loss: 47.7888 batch_loss: 391.230927
train Loss: 48.1308 batch_loss: 262.702728
train Loss: 48.4796 batch_loss: 267.829712
train Loss: 48.8042 batch_loss: 249.266571
train Loss: 49.1172 batch_loss: 240.393555
train Loss: 49.4019 batch_loss: 218.704453
train Loss: 49.7814 batch_loss: 291.450531
train Loss: 50.2808 batch_loss: 383.532227
train Loss: 50.5301 batch_loss: 191.462296
train Loss: 50.9074 batch_loss: 289.750458
train Loss: 51.2646 batch_loss: 274.312561
train Loss: 51.5526 batch_loss: 221.212997
train Loss: 51.9058 batch_loss: 271.243805
train Loss: 52.0964 batch_loss: 146.409378
train Loss: 52.2002 batch_loss: 79.716537
train Loss: 52.7114 batch_loss: 392.571350
train Loss: 52.8697 batch_loss: 121.581512
train Loss: 53.2679 batch_loss: 305.815491
train Loss: 53.5635 batch_loss: 227.053574
train Loss: 53.8858 batch_loss: 247.521423
train Loss: 54.3036 batch_loss: 320.840302
train Loss: 54.6826 batch_loss: 291.063110
train Loss: 55.2384 batch_loss: 426.896820
train Loss: 55.5898 batch_loss: 269.842194
train Loss: 55.9211 batch_loss: 254.456757
train Loss: 56.3812 batch_loss: 353.367889
train Loss: 56.6840 batch_loss: 232.495621
train Loss: 57.0478 batch_loss: 279.433777
train Loss: 57.2754 batch_loss: 174.773514
train Loss: 57.7177 batch_loss: 339.685089
train Loss: 58.1640 batch_loss: 342.813995
train Loss: 58.5703 batch_loss: 311.975037
train Loss: 58.9756 batch_loss: 311.271606
train Loss: 59.2997 batch_loss: 248.915619
train Loss: 59.6652 batch_loss: 280.723724
train Loss: 60.0718 batch_loss: 312.278137
train Loss: 60.3550 batch_loss: 217.509750
train Loss: 60.8130 batch_loss: 351.744720
train Loss: 61.1073 batch_loss: 226.007462
train Loss: 61.3493 batch_loss: 185.870148
train Loss: 61.7860 batch_loss: 335.384918
train Loss: 62.0448 batch_loss: 198.741608
train Loss: 62.2205 batch_loss: 134.946472
train Loss: 62.5164 batch_loss: 227.205475
train Loss: 63.0206 batch_loss: 387.222015
train Loss: 63.2774 batch_loss: 197.270737
train Loss: 63.4397 batch_loss: 124.610008
train Loss: 63.9630 batch_loss: 401.936737
train Loss: 64.2863 batch_loss: 248.259933
train Loss: 64.7770 batch_loss: 376.871216
train Loss: 65.0561 batch_loss: 214.343719
train Loss: 65.3537 batch_loss: 228.553543
train Loss: 65.6148 batch_loss: 200.538559
train Loss: 65.8900 batch_loss: 211.386139
train Loss: 66.2693 batch_loss: 291.245392
train Loss: 66.8256 batch_loss: 427.255920
train Loss: 67.1270 batch_loss: 231.514618
train Loss: 67.5853 batch_loss: 351.929413
train Loss: 67.7638 batch_loss: 137.098114
train Loss: 68.2036 batch_loss: 337.732544
train Loss: 68.3926 batch_loss: 145.187408
train Loss: 68.8020 batch_loss: 314.444489
train Loss: 69.1319 batch_loss: 253.345566
train Loss: 69.4970 batch_loss: 280.370148
train Loss: 69.9160 batch_loss: 321.820038
train Loss: 70.5050 batch_loss: 452.316986
train Loss: 70.7787 batch_loss: 210.261307
train Loss: 71.1600 batch_loss: 292.788239
train Loss: 71.4581 batch_loss: 228.941071
train Loss: 71.5740 batch_loss: 89.000221
train Loss: 71.8414 batch_loss: 205.363007
train Loss: 72.3817 batch_loss: 414.946136
train Loss: 72.7465 batch_loss: 280.208923
train Loss: 73.1750 batch_loss: 329.112183
train Loss: 73.5446 batch_loss: 283.790375
train Loss: 74.0802 batch_loss: 411.331970
train Loss: 74.3658 batch_loss: 219.391922
train Loss: 74.8213 batch_loss: 349.775238
train Loss: 75.2046 batch_loss: 294.399689
train Loss: 75.6887 batch_loss: 371.795624
train Loss: 76.0173 batch_loss: 252.338120
train Loss: 76.5168 batch_loss: 383.607819
train Loss: 76.8794 batch_loss: 278.521942
train Loss: 77.1636 batch_loss: 218.289276
train Loss: 77.5170 batch_loss: 271.371826
train Loss: 77.7565 batch_loss: 183.912781
train Loss: 78.2919 batch_loss: 411.192963
train Loss: 78.7246 batch_loss: 332.308929
train Loss: 79.2610 batch_loss: 412.014496
train Loss: 79.5634 batch_loss: 232.241837
train Loss: 79.8529 batch_loss: 222.328873
train Loss: 80.3210 batch_loss: 359.452728
train Loss: 80.5670 batch_loss: 188.943024
train Loss: 80.9701 batch_loss: 309.585510
train Loss: 81.3845 batch_loss: 318.297028
train Loss: 81.8274 batch_loss: 340.075836
train Loss: 82.5171 batch_loss: 529.719055
train Loss: 82.8728 batch_loss: 273.187164
train Loss: 83.1520 batch_loss: 214.454941
train Loss: 83.6269 batch_loss: 364.703766
train Loss: 83.8983 batch_loss: 208.426239
train Loss: 84.3947 batch_loss: 381.218750
train Loss: 84.7854 batch_loss: 300.057098
train Loss: 85.1421 batch_loss: 273.984711
train Loss: 85.5913 batch_loss: 344.940704
train Loss: 85.8885 batch_loss: 228.288498
train Loss: 86.1926 batch_loss: 233.530411
train Loss: 86.3932 batch_loss: 154.038284
train Loss: 86.7223 batch_loss: 252.735214
train Loss: 86.9540 batch_loss: 178.016418
train Loss: 87.3901 batch_loss: 334.879761
train Loss: 87.7994 batch_loss: 314.386536
train Loss: 88.0584 batch_loss: 198.878937
train Loss: 88.4376 batch_loss: 291.186523
train Loss: 88.5289 batch_loss: 70.169014
train Loss: 88.8994 batch_loss: 284.536255
train Loss: 89.3904 batch_loss: 377.118958
train Loss: 89.7765 batch_loss: 296.515503
train Loss: 90.1793 batch_loss: 309.359985
train Loss: 90.3973 batch_loss: 167.423172
train Loss: 90.9377 batch_loss: 414.971741
train Loss: 91.3285 batch_loss: 300.132996
train Loss: 91.8239 batch_loss: 380.500061
^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[Atrain Loss: 92.0522 batch_loss: 175.291946
train Loss: 92.2211 batch_loss: 129.742981
train Loss: 92.4841 batch_loss: 201.994675
train Loss: 92.9807 batch_loss: 381.365295
train Loss: 93.3198 batch_loss: 260.449402
^CTraceback (most recent call last):
  File "train.py", line 214, in <module>
    image_size = 200)
  File "train.py", line 114, in train_model
    loss.backward()
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/tensor.py", line 102, in backward
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/multiprocessing/queues.py", line 240, in _feed
    send_bytes(obj)
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/usr/local/lib/python3.6/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/rliu/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 90, in backward
  File "/usr/local/lib/python3.6/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/local/lib/python3.6/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
krliu@dm:~/github/ansim\[rliu@dm ansim]$ exit
exit

Script done on Tue 16 Apr 2019 09:51:07 PM EDT
