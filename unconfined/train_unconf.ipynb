{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from ansim_dataset_unconf import ansimDataset, create_circular_mask\n",
    "from ConvLSTM_unconf import MtConvLSTM\n",
    "import random\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/rliu/ansim/data/unconfined_cropped/'\n",
    "img_list_csv = '/home/rliu/github/ansim/unconfined/img_list.csv'\n",
    "train_csv = '/home/rliu/github/ansim/unconfined/train_unconf.csv'\n",
    "test_csv = '/home/rliu/github/ansim/unconfined/test_unconf.csv'\n",
    "output_path = '/home/rliu/ansim/models/dataset3/very_first.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ansimDataset(img_list_csv = img_list_csv, seq_csv = train_csv, root_dir = img_path, step=10, random_rotate = True, transform=None, rand_range=10)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                             batch_size=8, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "\n",
    "testset = ansimDataset(img_list_csv = img_list_csv, seq_csv = test_csv, root_dir = img_path, step=10, random_rotate = False, transform=None)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                             batch_size=8, shuffle=False,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = pd.read_csv(img_list_csv,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rliu/ansim/data/data/JPEGImages/114571.jpg'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(img_path, img_list.iloc[114570, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/home/rliu/ansim/data/data/JPEGImages/112893.jpg\")\n",
    "image = image.convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(encoder, decoder, criterion, optimizer, scheduler, num_epochs=25):\n",
    "#     since = time.time()\n",
    "\n",
    "#     best_encoder_wts = encoder.state_dict()\n",
    "#     best_decoder_wts = decoder.state_dict()\n",
    "#     best_acc = 0.0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "#         print('-' * 10)\n",
    "\n",
    "#         # Each epoch has a training phase\n",
    "#         scheduler.step()\n",
    "#         encoder.train(True)  # Set model to training mode\n",
    "#         decoder.train(True)  # Set model to training mode\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "\n",
    "#         # Iterate over data.\n",
    "#         trainset = ansimDataset(img_list_csv = img_list_csv, seq_csv = train_csv, root_dir = img_path, step=20, random_rotate = True, mask = mask, transform=None)\n",
    "#         trainloader = torch.utils.data.DataLoader(trainset,\n",
    "#                                                      batch_size=1, shuffle=True,\n",
    "#                                                      num_workers=4)\n",
    "\n",
    "#         print(\"trainloader ready!\")\n",
    "#         testset = ansimDataset(img_list_csv = img_list_csv, seq_csv = test_csv, root_dir = img_path, step=20, random_rotate = True, mask = mask, transform=None)\n",
    "#         testloader = torch.utils.data.DataLoader(testset,\n",
    "#                                                      batch_size=1, shuffle=True,\n",
    "#                                                      num_workers=4)\n",
    "#         print(\"testloader ready!\")\n",
    "        \n",
    "#         for data in trainloader:\n",
    "#             # get the inputs\n",
    "#             data_split = torch.split(data, 10, dim=1)\n",
    "#             inputs = data_split[0]\n",
    "#             target = data_split[1]\n",
    "# #            print(inputs)\n",
    "#             # wrap them in Variable\n",
    "#             if use_gpu:\n",
    "# #                inputs = Variable(inputs.cuda())\n",
    "# #                labels = Variable(labels.cuda())\n",
    "# #                inputs = torch.nn.DataParallel(inputs, device_ids=[0, 1]).cuda()\n",
    "# #                labels = torch.nn.DataParallel(labels, device_ids=[0, 1]).cuda()\n",
    "#                 inputs, target = inputs.to(device), target.to(device)\n",
    "# #                print(inputs)\n",
    "#             else:\n",
    "#                 inputs, target = Variable(inputs), Variable(target)\n",
    "\n",
    "#             # zero the parameter gradients\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             output, h, c, states = encoder(inputs)\n",
    "#             output_last = output[0][0].double()\n",
    "#             h1,h2,h3,h4,h5 = states[0][0],states[1][0],states[2][0],states[3][0],states[4][0]\n",
    "#             c1,c2,c3,c4,c5 = states[0][1],states[1][1],states[2][1],states[3][1],states[4][1]\n",
    "#             states_cat = torch.cat((h1,h2,h3,h4,h5,c1,c2,c3,c4,c5), dim=1, out=None)\n",
    "#             x = decoder.activateConv(states_cat)\n",
    "#             input_d = [x, states]\n",
    "#             output_d, h_d, c_d, states_d = decoder(input_d)\n",
    "#             predicted = torch.cat(output_d, dim=0, out=None).double()\n",
    "            \n",
    "            \n",
    "#             loss = criterion(predicted, target)\n",
    "#             # forward\n",
    "# #            outputs = model(inputs)\n",
    "# #            _, preds = torch.max(outputs.data, 1)\n",
    "# #            loss = criterion(outputs, labels)\n",
    "\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # statistics\n",
    "#             iter_loss = loss.item()\n",
    "#             running_loss += loss.item()    \n",
    "#             epoch_loss = running_loss / len(trainset)\n",
    "            \n",
    "#             print('{} Loss: {:.4f} batch_loss: {:d}'.format(\n",
    "#                 \"train\", epoch_loss, iter_loss))\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for data in testloader:\n",
    "#                 data_split = torch.split(data, 10, dim=1)\n",
    "#                 inputs = data_split[0]\n",
    "#                 target = data_split[1]\n",
    "                \n",
    "#                 if use_gpu:\n",
    "#                     inputs, target = inputs.to(device), target.to(device)\n",
    "#                 else:\n",
    "#                     inputs, target = Variable(inputs), Variable(target)\n",
    "\n",
    "                    \n",
    "#                 output, h, c, states = encoder(inputs)\n",
    "#                 output_last = output[0][0].double()\n",
    "#                 h1,h2,h3,h4,h5 = states[0][0],states[1][0],states[2][0],states[3][0],states[4][0]\n",
    "#                 c1,c2,c3,c4,c5 = states[0][1],states[1][1],states[2][1],states[3][1],states[4][1]\n",
    "#                 states_cat = torch.cat((h1,h2,h3,h4,h5,c1,c2,c3,c4,c5), dim=1, out=None)\n",
    "#                 x = decoder.activateConv(states_cat)\n",
    "#                 input_d = [x, states]\n",
    "#                 output_d, h_d, c_d, states_d = decoder(input_d)\n",
    "#                 predicted = torch.cat(output_d, dim=0, out=None).double()\n",
    "            \n",
    "#                 loss_test = criterion(predicted, target)\n",
    "#                 iter_loss_test = loss_test.item()\n",
    "#                 running_loss_test += loss_test.item()    \n",
    "#                 epoch_loss_test = running_loss_test / len(testset)\n",
    "\n",
    "#         print('Loss on the test images: %.5f %%' % (\n",
    "#             epoch_loss_test))\n",
    "        \n",
    "\n",
    "#     time_elapsed = time.time() - since\n",
    "#     print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "#         time_elapsed // 60, time_elapsed % 60))\n",
    "#     print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "#     # load best model weights\n",
    "#     encoder.load_state_dict(best_encoder_wts)\n",
    "#     decoder.load_state_dict(best_decoder_wts)\n",
    "#     return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, batch_size = 4, step_size = 10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training phase\n",
    "        scheduler.step()\n",
    "        model.train(True)  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "\n",
    "        # Iterate over data.\n",
    "        trainset = ansimDataset(img_list_csv = img_list_csv, seq_csv = test_csv, root_dir = img_path, step=10, random_rotate = True, transform=None, image_size = 128, rand_range=10)\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True,\n",
    "                                                     num_workers=1)\n",
    "\n",
    "        print(\"trainloader ready!\")\n",
    "        testset = ansimDataset(img_list_csv = img_list_csv, seq_csv = test_csv, root_dir = img_path, step=10, random_rotate = False, transform=None, image_size = 128, rand_range=0)\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False,\n",
    "                                                     num_workers=1)\n",
    "        print(\"testloader ready!\")\n",
    "        \n",
    "        for data in trainloader:\n",
    "            # get the inputs\n",
    "            data_split = torch.split(data, int(data.shape[1]/2), dim=1)\n",
    "            inputs = data_split[0]\n",
    "            target = data_split[1]\n",
    "#            print(inputs)\n",
    "            # wrap them in Variable\n",
    "            if use_gpu:\n",
    "                inputs, target = inputs.to(device), target.to(device)\n",
    "            else:\n",
    "                inputs, target = Variable(inputs), Variable(target)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "#             output, h, c, states = encoder(inputs)\n",
    "#             output_last = output[0][0].double()\n",
    "#             h1,h2,h3,h4,h5 = states[0][0],states[1][0],states[2][0],states[3][0],states[4][0]\n",
    "#             c1,c2,c3,c4,c5 = states[0][1],states[1][1],states[2][1],states[3][1],states[4][1]\n",
    "#             states_cat = torch.cat((h1,h2,h3,h4,h5,c1,c2,c3,c4,c5), dim=1, out=None)\n",
    "#             x = decoder.activateConv(states_cat)\n",
    "#             input_d = [x, states]\n",
    "#             output_d, h_d, c_d, states_d = decoder(input_d)\n",
    "#             predicted = torch.cat(output_d, dim=0, out=None).double()\n",
    "            \n",
    "            _, _, _, predicted = model(inputs)\n",
    "            \n",
    "#             m = nn.Sigmoid()\n",
    "#             loss = criterion(m(predicted), m(target))\n",
    "            # forward\n",
    "#            outputs = model(inputs)\n",
    "#            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(predicted, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            iter_loss = loss.item()\n",
    "            running_loss += loss.item()    \n",
    "            epoch_loss = running_loss / len(trainset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} batch_loss: {:f}'.format(\n",
    "                \"train\", epoch_loss, iter_loss))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_loss_test = 0.0\n",
    "            for data in testloader:\n",
    "                data_split = torch.split(data, int(data.shape[1]/2), dim=1)\n",
    "                inputs = data_split[0]\n",
    "                target = data_split[1]\n",
    "                \n",
    "                \n",
    "                if use_gpu:\n",
    "                    inputs, target = inputs.to(device), target.to(device)\n",
    "                else:\n",
    "                    inputs, target = Variable(inputs), Variable(target)\n",
    "\n",
    "                    \n",
    "#                 output, h, c, states = encoder(inputs)\n",
    "#                 output_last = output[0][0].double()\n",
    "#                 h1,h2,h3,h4,h5 = states[0][0],states[1][0],states[2][0],states[3][0],states[4][0]\n",
    "#                 c1,c2,c3,c4,c5 = states[0][1],states[1][1],states[2][1],states[3][1],states[4][1]\n",
    "#                 states_cat = torch.cat((h1,h2,h3,h4,h5,c1,c2,c3,c4,c5), dim=1, out=None)\n",
    "#                 x = decoder.activateConv(states_cat)\n",
    "#                 input_d = [x, states]\n",
    "#                 output_d, h_d, c_d, states_d = decoder(input_d)\n",
    "#                 predicted = torch.cat(output_d, dim=0, out=None).double()\n",
    "\n",
    "                _, _, _, predicted = model(inputs)\n",
    "                \n",
    "#                 m = nn.Sigmoid()\n",
    "#                 loss_test = criterion(m(predicted), m(target))\n",
    "                loss_test = criterion(predicted, target)\n",
    "    \n",
    "                iter_loss_test = loss_test.item()\n",
    "                running_loss_test += loss_test.item()    \n",
    "                epoch_loss_test = running_loss_test / len(testset)\n",
    "\n",
    "        print('Loss on the test images: %.5f ' % (\n",
    "            epoch_loss_test))\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "train Loss: 129.5743 batch_loss: 23323.371094\n",
      "train Loss: 268.7171 batch_loss: 25045.708984\n",
      "train Loss: 431.5089 batch_loss: 29302.521484\n",
      "train Loss: 568.6107 batch_loss: 24678.328125\n",
      "train Loss: 638.9578 batch_loss: 12662.476562\n",
      "train Loss: 732.9921 batch_loss: 16926.167969\n",
      "train Loss: 828.9702 batch_loss: 17276.064453\n",
      "train Loss: 921.4092 batch_loss: 16639.019531\n",
      "train Loss: 1067.4052 batch_loss: 26279.285156\n",
      "train Loss: 1159.3100 batch_loss: 16542.865234\n",
      "train Loss: 1226.7843 batch_loss: 12145.374023\n",
      "train Loss: 1323.6583 batch_loss: 17437.304688\n",
      "train Loss: 1388.8048 batch_loss: 11726.372070\n",
      "train Loss: 1479.5061 batch_loss: 16326.240234\n",
      "train Loss: 1583.4307 batch_loss: 18706.427734\n",
      "train Loss: 1754.5836 batch_loss: 30807.519531\n",
      "train Loss: 1868.4319 batch_loss: 20492.693359\n",
      "train Loss: 1963.6807 batch_loss: 17144.779297\n",
      "train Loss: 2024.5729 batch_loss: 10960.605469\n",
      "train Loss: 2101.2278 batch_loss: 13797.880859\n",
      "train Loss: 2200.1744 batch_loss: 17810.378906\n",
      "train Loss: 2259.4030 batch_loss: 10661.158203\n",
      "train Loss: 2357.6724 batch_loss: 17688.490234\n",
      "train Loss: 2482.5751 batch_loss: 22482.476562\n",
      "train Loss: 2608.7072 batch_loss: 22703.789062\n",
      "train Loss: 2768.1005 batch_loss: 28690.792969\n",
      "train Loss: 2814.5172 batch_loss: 8355.009766\n",
      "train Loss: 2972.1895 batch_loss: 28381.011719\n",
      "train Loss: 3041.0793 batch_loss: 12400.159180\n",
      "train Loss: 3198.5702 batch_loss: 28348.355469\n",
      "train Loss: 3242.7461 batch_loss: 7951.675781\n",
      "train Loss: 3287.9410 batch_loss: 8135.076660\n",
      "train Loss: 3339.4351 batch_loss: 9268.945312\n",
      "train Loss: 3438.4447 batch_loss: 17821.718750\n",
      "train Loss: 3536.3561 batch_loss: 17624.052734\n",
      "train Loss: 3577.7069 batch_loss: 7443.145996\n",
      "train Loss: 3644.7018 batch_loss: 12059.088867\n",
      "train Loss: 3685.9053 batch_loss: 7416.614258\n",
      "train Loss: 3796.7667 batch_loss: 19955.056641\n",
      "train Loss: 3939.4786 batch_loss: 25688.150391\n",
      "train Loss: 4033.9544 batch_loss: 17005.644531\n",
      "train Loss: 4144.7905 batch_loss: 19950.496094\n",
      "train Loss: 4184.6556 batch_loss: 7175.713867\n",
      "train Loss: 4295.7112 batch_loss: 19990.015625\n",
      "train Loss: 4384.2376 batch_loss: 15934.751953\n",
      "train Loss: 4447.6725 batch_loss: 11418.273438\n",
      "train Loss: 4491.6394 batch_loss: 7914.045410\n",
      "train Loss: 4527.6575 batch_loss: 6483.259277\n",
      "train Loss: 4632.1196 batch_loss: 18803.171875\n",
      "train Loss: 4710.2344 batch_loss: 14060.671875\n",
      "train Loss: 4811.0081 batch_loss: 18139.253906\n",
      "train Loss: 4948.0539 batch_loss: 24668.259766\n",
      "train Loss: 5078.0787 batch_loss: 23404.457031\n",
      "train Loss: 5136.2950 batch_loss: 10478.924805\n",
      "train Loss: 5194.0480 batch_loss: 10395.552734\n",
      "train Loss: 5267.7066 batch_loss: 13258.536133\n",
      "train Loss: 5396.5727 batch_loss: 23195.898438\n",
      "train Loss: 5449.2021 batch_loss: 9473.302734\n",
      "train Loss: 5480.7262 batch_loss: 5674.333496\n",
      "train Loss: 5537.7693 batch_loss: 10267.755859\n",
      "train Loss: 5568.9836 batch_loss: 5618.579102\n",
      "train Loss: 5645.2803 batch_loss: 13733.403320\n",
      "train Loss: 5697.0523 batch_loss: 9318.953125\n",
      "train Loss: 5821.8003 batch_loss: 22454.640625\n",
      "train Loss: 5875.2076 batch_loss: 9613.316406\n",
      "train Loss: 5941.8993 batch_loss: 12004.504883\n",
      "train Loss: 6063.1089 batch_loss: 21817.740234\n",
      "train Loss: 6124.6007 batch_loss: 11068.521484\n",
      "train Loss: 6158.5965 batch_loss: 6119.239258\n",
      "train Loss: 6215.8829 batch_loss: 10311.543945\n",
      "train Loss: 6301.9929 batch_loss: 15499.802734\n",
      "train Loss: 6372.5581 batch_loss: 12701.747070\n",
      "train Loss: 6435.2682 batch_loss: 11287.806641\n",
      "train Loss: 6482.7694 batch_loss: 8550.215820\n",
      "train Loss: 6552.4439 batch_loss: 12541.419922\n",
      "train Loss: 6608.8966 batch_loss: 10161.481445\n",
      "train Loss: 6659.5287 batch_loss: 9113.774414\n",
      "train Loss: 6721.0605 batch_loss: 11075.731445\n",
      "train Loss: 6773.9585 batch_loss: 9521.643555\n",
      "train Loss: 6819.7673 batch_loss: 8245.573242\n",
      "train Loss: 6881.0658 batch_loss: 11033.729492\n",
      "train Loss: 6988.8842 batch_loss: 19407.320312\n",
      "train Loss: 7039.7212 batch_loss: 9150.654297\n",
      "train Loss: 7062.1141 batch_loss: 4030.721191\n",
      "train Loss: 7105.7393 batch_loss: 7852.536133\n",
      "train Loss: 7132.8006 batch_loss: 4871.036133\n",
      "train Loss: 7176.6415 batch_loss: 7891.360352\n",
      "train Loss: 7197.9518 batch_loss: 3835.856201\n",
      "train Loss: 7236.3178 batch_loss: 6905.875000\n",
      "train Loss: 7261.6458 batch_loss: 4559.039062\n",
      "train Loss: 7361.7374 batch_loss: 18016.486328\n",
      "train Loss: 7398.9856 batch_loss: 6704.686035\n",
      "train Loss: 7434.6765 batch_loss: 6424.364258\n",
      "train Loss: 7508.5755 batch_loss: 13301.807617\n",
      "train Loss: 7566.7042 batch_loss: 10463.166992\n",
      "train Loss: 7609.1014 batch_loss: 7631.502930\n",
      "train Loss: 7667.2218 batch_loss: 10461.666016\n",
      "train Loss: 7707.2225 batch_loss: 7200.131348\n",
      "train Loss: 7751.0360 batch_loss: 7886.431152\n",
      "train Loss: 7848.7217 batch_loss: 17583.429688\n",
      "train Loss: 7891.4749 batch_loss: 7695.571289\n",
      "train Loss: 7957.9424 batch_loss: 11964.142578\n",
      "train Loss: 7975.3187 batch_loss: 3127.744141\n",
      "train Loss: 8021.9112 batch_loss: 8386.648438\n",
      "train Loss: 8042.5867 batch_loss: 3721.585449\n",
      "train Loss: 8086.9583 batch_loss: 7986.893555\n",
      "train Loss: 8138.6536 batch_loss: 9305.148438\n",
      "train Loss: 8158.0639 batch_loss: 3493.858643\n",
      "train Loss: 8208.9622 batch_loss: 9161.685547\n",
      "train Loss: 8239.3990 batch_loss: 5478.624023\n",
      "train Loss: 8328.2502 batch_loss: 15993.215820\n",
      "train Loss: 8359.3759 batch_loss: 5602.627441\n",
      "train Loss: 8388.8687 batch_loss: 5308.701660\n",
      "train Loss: 8449.9774 batch_loss: 10999.566406\n",
      "train Loss: 8479.0591 batch_loss: 5234.713867\n",
      "train Loss: 8525.8884 batch_loss: 8429.273438\n",
      "train Loss: 8542.4167 batch_loss: 2975.089355\n",
      "train Loss: 8568.8109 batch_loss: 4750.955566\n",
      "train Loss: 8597.9695 batch_loss: 5248.555664\n",
      "train Loss: 8636.3271 batch_loss: 6904.373535\n",
      "train Loss: 8662.7680 batch_loss: 4759.358398\n",
      "train Loss: 8694.2140 batch_loss: 5660.277344\n",
      "train Loss: 8773.4134 batch_loss: 14255.895508\n",
      "train Loss: 8813.6031 batch_loss: 7234.132812\n",
      "train Loss: 8871.4080 batch_loss: 10404.894531\n",
      "train Loss: 8886.5672 batch_loss: 2728.642578\n",
      "train Loss: 8963.9657 batch_loss: 13931.732422\n",
      "train Loss: 8992.9188 batch_loss: 5211.565430\n",
      "train Loss: 9003.6761 batch_loss: 1936.310913\n",
      "train Loss: 9038.9604 batch_loss: 6351.168945\n",
      "train Loss: 9049.0599 batch_loss: 1817.920166\n",
      "train Loss: 9102.2223 batch_loss: 9569.236328\n",
      "train Loss: 9135.1214 batch_loss: 5921.834473\n",
      "train Loss: 9144.5881 batch_loss: 1703.993408\n",
      "train Loss: 9157.4980 batch_loss: 2323.790527\n",
      "train Loss: 9180.9308 batch_loss: 4217.907227\n",
      "train Loss: 9192.9085 batch_loss: 2155.978760\n",
      "train Loss: 9243.2617 batch_loss: 9063.573242\n",
      "train Loss: 9270.1880 batch_loss: 4846.748535\n",
      "train Loss: 9306.9423 batch_loss: 6615.757812\n",
      "train Loss: 9344.2676 batch_loss: 6718.562500\n",
      "train Loss: 9363.0030 batch_loss: 3372.374268\n",
      "train Loss: 9391.7172 batch_loss: 5168.559570\n",
      "train Loss: 9410.8876 batch_loss: 3450.660889\n",
      "train Loss: 9429.5757 batch_loss: 3363.867188\n",
      "train Loss: 9474.0577 batch_loss: 8006.750977\n",
      "train Loss: 9481.5398 batch_loss: 1346.786133\n",
      "train Loss: 9503.1470 batch_loss: 3889.285156\n",
      "train Loss: 9512.8210 batch_loss: 1741.334717\n",
      "train Loss: 9540.0660 batch_loss: 4904.098633\n",
      "train Loss: 9567.6301 batch_loss: 4961.526367\n",
      "train Loss: 9611.0446 batch_loss: 7814.607910\n",
      "train Loss: 9641.1366 batch_loss: 5416.568848\n",
      "train Loss: 9657.0499 batch_loss: 2864.388184\n",
      "train Loss: 9663.3907 batch_loss: 1141.342773\n",
      "train Loss: 9680.4581 batch_loss: 3072.142090\n",
      "train Loss: 9687.1304 batch_loss: 1201.015991\n",
      "train Loss: 9704.2774 batch_loss: 3086.453857\n",
      "train Loss: 9765.8348 batch_loss: 11080.333008\n",
      "train Loss: 9773.8767 batch_loss: 1447.541138\n",
      "train Loss: 9793.3593 batch_loss: 3506.860840\n",
      "train Loss: 9799.1554 batch_loss: 1043.309082\n",
      "train Loss: 9816.1671 batch_loss: 3062.097168\n",
      "train Loss: 9853.1586 batch_loss: 6658.477539\n",
      "train Loss: 9880.1278 batch_loss: 4854.456055\n",
      "train Loss: 9887.7164 batch_loss: 1365.947021\n",
      "train Loss: 9910.9774 batch_loss: 4186.969727\n",
      "train Loss: 9918.0506 batch_loss: 1273.184570\n",
      "train Loss: 9943.7486 batch_loss: 4625.641113\n",
      "train Loss: 9998.3733 batch_loss: 9832.448242\n",
      "train Loss: 10051.7467 batch_loss: 9607.210938\n",
      "train Loss: 10088.2927 batch_loss: 6578.271973\n",
      "train Loss: 10140.7409 batch_loss: 9440.684570\n",
      "train Loss: 10146.9252 batch_loss: 1113.176392\n",
      "train Loss: 10172.9284 batch_loss: 4680.578125\n",
      "train Loss: 10188.1143 batch_loss: 2733.456299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 10203.5891 batch_loss: 2785.458740\n",
      "train Loss: 10215.1835 batch_loss: 2086.995361\n",
      "train Loss: 10228.5885 batch_loss: 2412.901123\n",
      "train Loss: 10242.7579 batch_loss: 2550.486816\n",
      "Loss on the test images: 3424.14242 \n",
      "Epoch 1/9\n",
      "----------\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "train Loss: 23.0630 batch_loss: 4151.342285\n",
      "train Loss: 33.8237 batch_loss: 1936.918701\n",
      "train Loss: 39.2681 batch_loss: 979.990417\n",
      "train Loss: 51.1958 batch_loss: 2146.992920\n",
      "train Loss: 81.9032 batch_loss: 5527.324707\n",
      "train Loss: 100.5045 batch_loss: 3348.239746\n",
      "train Loss: 115.5514 batch_loss: 2708.449951\n",
      "train Loss: 147.5361 batch_loss: 5757.231445\n",
      "train Loss: 152.7874 batch_loss: 945.240906\n",
      "train Loss: 157.5952 batch_loss: 865.401855\n",
      "train Loss: 167.8228 batch_loss: 1840.971436\n",
      "train Loss: 200.7730 batch_loss: 5931.031738\n",
      "train Loss: 214.4202 batch_loss: 2456.498779\n",
      "train Loss: 219.6804 batch_loss: 946.843750\n",
      "train Loss: 230.5404 batch_loss: 1954.798096\n",
      "train Loss: 261.6949 batch_loss: 5607.811523\n",
      "train Loss: 272.5439 batch_loss: 1952.818970\n",
      "train Loss: 277.6338 batch_loss: 916.173950\n",
      "train Loss: 308.9600 batch_loss: 5638.714844\n",
      "train Loss: 313.0213 batch_loss: 731.035706\n",
      "train Loss: 331.2438 batch_loss: 3280.059326\n",
      "train Loss: 350.2278 batch_loss: 3417.107910\n",
      "train Loss: 361.6654 batch_loss: 2058.776123\n",
      "train Loss: 365.7500 batch_loss: 735.225952\n",
      "train Loss: 370.9087 batch_loss: 928.569641\n",
      "train Loss: 375.9598 batch_loss: 909.197754\n",
      "train Loss: 390.5305 batch_loss: 2622.728027\n",
      "train Loss: 410.4494 batch_loss: 3585.397217\n",
      "train Loss: 425.8697 batch_loss: 2775.655029\n",
      "train Loss: 444.7318 batch_loss: 3395.173340\n",
      "train Loss: 493.2366 batch_loss: 8730.861328\n",
      "train Loss: 503.3772 batch_loss: 1825.310181\n",
      "train Loss: 514.9661 batch_loss: 2085.998535\n",
      "train Loss: 564.5075 batch_loss: 8917.466797\n",
      "train Loss: 612.8057 batch_loss: 8693.661133\n",
      "train Loss: 660.7159 batch_loss: 8623.837891\n",
      "train Loss: 672.1589 batch_loss: 2059.751709\n",
      "train Loss: 685.4706 batch_loss: 2396.094482\n",
      "train Loss: 703.0339 batch_loss: 3161.397217\n",
      "train Loss: 713.1924 batch_loss: 1828.536133\n",
      "train Loss: 717.2668 batch_loss: 733.385071\n",
      "train Loss: 739.0533 batch_loss: 3921.566406\n",
      "train Loss: 744.5856 batch_loss: 995.811157\n",
      "train Loss: 749.5816 batch_loss: 899.295776\n",
      "train Loss: 754.7014 batch_loss: 921.550293\n",
      "train Loss: 786.0295 batch_loss: 5639.071777\n",
      "train Loss: 797.6317 batch_loss: 2088.395020\n",
      "train Loss: 801.3672 batch_loss: 672.390320\n",
      "train Loss: 815.8516 batch_loss: 2607.180420\n",
      "train Loss: 863.5988 batch_loss: 8594.506836\n",
      "train Loss: 892.9451 batch_loss: 5282.328125\n",
      "train Loss: 914.6871 batch_loss: 3913.566895\n",
      "train Loss: 934.9522 batch_loss: 3647.708252\n",
      "train Loss: 957.6866 batch_loss: 4092.190674\n",
      "train Loss: 1004.9630 batch_loss: 8509.747070\n"
     ]
    }
   ],
   "source": [
    "# transfer learning resnet18\n",
    "step_size = 10\n",
    "model = MtConvLSTM(input_size=(128,128),\n",
    "                 input_dim=1,\n",
    "                 hidden_dim=[[16,32,64],[16,32,64],[32,64,128],[32,64,128,128]],\n",
    "                 kernel_size=[[3,3,3],[5,3,3],[5,5,5],[7,5,5,5]],\n",
    "                 num_layers=[3,3,3,4],\n",
    "                 predict_steps=5,\n",
    "                 batch_first=True,\n",
    "                 num_scale=4,\n",
    "                 bias=True,\n",
    "                 return_all_layers=True)\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "#     encoder = torch.nn.DataParallel(encoder)\n",
    "#     decoder = torch.nn.DataParallel(decoder)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=1, gamma=0.1)\n",
    "\n",
    "# train model\n",
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, batch_size = 1, step_size = 10, num_epochs=10)\n",
    "torch.save(model, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset = ansimDataset(img_list_csv = img_list_csv, seq_csv = test_csv, root_dir = img_path, step=step_size, random_rotate = True, mask = mask, transform=None)\n",
    "# testloader = torch.utils.data.DataLoader(testset,\n",
    "#                                              batch_size=1, shuffle=True,\n",
    "#                                              num_workers=1)\n",
    "# dataiter = iter(testloader)\n",
    "# data = dataiter.next()\n",
    "# data_split = torch.split(data, int(data.shape[1]/2), dim=1)\n",
    "# inputs = data_split[0]\n",
    "# target = data_split[1]\n",
    "# outputs = model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "input = Variable(torch.randn(3, 1, 512, 64, 32)).cuda()\n",
    "a = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 512, 64, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
